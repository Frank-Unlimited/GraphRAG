{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>Deepseekä¼ä¸šçº§Agenté¡¹ç›®å¼€å‘å®æˆ˜</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center>Part 3. Microsoft GraphRAG è‡ªå®šä¹‰æ¥å…¥å›¾æ•°æ®åº“ Neo4j</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;`Microsoft GraphRAG` çš„æ ¸å¿ƒæ¦‚å¿µåœ¨äºå°†`Konwledge Graph` å­˜å‚¨çš„æ•°æ®ä¸å¤§è¯­è¨€æ¨¡å‹ç»“åˆï¼Œé€šè¿‡æŸ¥è¯¢å›¾æ•°æ®åº“æ¥å¢å¼ºæ¨¡å‹çš„å›ç­”è´¨é‡ã€‚ç»è¿‡å‰ä¸¤èŠ‚è¯¾ç¨‹å¯¹`Microsoft GraphRAG`æ„å»ºç´¢å¼•è¿‡ç¨‹çš„è¯¦è§£ï¼Œæˆ‘ä»¬å·²ç»å€ŸåŠ©å¤§æ¨¡å‹ç»“åˆæç¤ºå·¥ç¨‹ä»éç»“æ„åŒ–æ–‡æœ¬ä¸­æå–å‡ºå®ä½“å’Œå…³ç³»ï¼Œå…¶å®è¿™å°±è¶³å¤Ÿæ”¯æ’‘æˆ‘ä»¬æ„å»ºåŸºäºæœ¬åœ°æ–‡æ¡£çš„å®Œæ•´çŸ¥è¯†å›¾è°±äº†ã€‚\n",
    "\n",
    "&emsp;&emsp;å› æ­¤ï¼Œæœ¬èŠ‚è¯¾ï¼Œæˆ‘ä»¬å°±è¯¦ç»†çš„ä»‹ç»ä¸€ä¸‹å¦‚æœå°†`Microsoft GraphRAG`æ„å»ºçš„ç´¢å¼•æ–‡ä»¶å­˜å‚¨è‡³æœ¬åœ°çš„å›¾æ•°æ®åº“ä¸­è¿›è¡Œå¯è§†åŒ–çš„å±•ç¤ºï¼Œä»¥ä¾¿ç”¨äºæ¥ä¸‹æ¥çš„`GraphRAG Query`é˜¶æ®µã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://muyu20241105.oss-cn-beijing.aliyuncs.com/images/202503041644948.png\" width=80%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;é¦–å…ˆï¼Œæˆ‘ä»¬éœ€è¦åœ¨æœ¬åœ°æ­å»ºä¸€ä¸ªå›¾æ•°æ®åº“æ¥å­˜å‚¨çŸ¥è¯†ç»“æ„ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp; Neo4j æ˜¯ä¸€ä¸ªå¼€æºçš„ `NoSQL` å›¾æ•°æ®åº“ï¼Œå®ƒä½¿ç”¨å›¾æ¥è¡¨ç¤ºå’Œå­˜å‚¨æ•°æ®ã€‚åœ¨ `DB-Engines` æ’åä¸­æ ¹æ®æ•°æ®åº“ç®¡ç†ç³»ç»Ÿçš„å—æ¬¢è¿ç¨‹åº¦å¯¹å…¶è¿›è¡Œæ’åä¸­ï¼Œ`Graph DBMS` æ¦œå•ä¸­ `Neo4j` æ’åç¬¬ä¸€ã€‚æŸ¥è¯¢é“¾æ¥ä¸ºï¼š[Graph DBMS æ’å](https://db-engines.com/en/ranking/graph+dbms?source=post_page-----1cb68f1ac2---------------------------------------)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://muyu20241105.oss-cn-beijing.aliyuncs.com/images/202503121518292.png\" width=60%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;åœ¨æ€»ä½“æ’åä¸­ï¼Œ`Neo4j` ä½åˆ—ç¬¬åä¹ï¼Œåœ¨æŠ€æœ¯å¸‚åœºä¸Šå æœ‰å¾ˆå¤§çš„ç©ºé—´ã€‚å…¶å¼€æºåœ°å€ä¸ºï¼š[Neo4j å¼€æºåœ°å€](https://github.com/neo4j/neo4j)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://muyu20241105.oss-cn-beijing.aliyuncs.com/images/202503121522873.png\" width=60%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;`Neo4j` çš„å®‰è£…æ–¹æ³•éå¸¸å¤šï¼Œæ¯”å¦‚`Docker`å®‰è£…ï¼Œ `Neo4j Desktop` å®‰è£…ï¼Œ`æºç `å®‰è£…ä»¥åŠåœ¨çº¿é€‚ç”¨ç­‰æ–¹å¼ã€‚æœ€ç®€å•çš„æ–¹å¼è‚¯å®šæ˜¯ä½¿ç”¨`Neo4j Desktop` å®‰è£…ï¼Œåªéœ€è¦ä¸‹è½½å®‰è£…åŒ…ï¼Œè§£å‹åä¾¿å¯ä»¥æ­£å¸¸è¿è¡Œã€‚ä¸‹è½½å®‰è£…åŒ…çš„åœ°å€å¦‚ä¸Šå›¾æ‰€ç¤ºï¼Œåœ¨`Neo4j`çš„`GitHub`åœ°å€ä¸­æ‰¾åˆ°`Download`æŒ‰é’®ï¼Œä¸‹è½½`.exe`å®‰è£…åŒ…ï¼ˆæ¯”å¦‚`Windows`ç³»ç»Ÿï¼‰ï¼Œæ‰§è¡Œå‚»ç“œå¼å®‰è£…ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://muyu20241105.oss-cn-beijing.aliyuncs.com/images/202503121530623.png\" width=60%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;è¿™ç§å®‰è£…æ–¹å¼åŠå…¶ç®€å•ï¼Œå› ä¸ºä¸éœ€è¦æˆ‘ä»¬é…ç½®ä»»ä½•ç¯å¢ƒå˜é‡ï¼Œåªéœ€è¦è§£å‹åä¾¿å¯è¿è¡Œã€‚ä½†æ˜¯å…¶æˆåŠŸç‡å¹¶ä¸æ˜¯ç‰¹åˆ«é«˜ï¼Œå› ä¸ºç”µè„‘ç¯å¢ƒçš„å·®å¼‚ï¼Œå¯èƒ½ä¼šå¯¼è‡´å®‰è£…åå‡ºç°å„ç§æœªçŸ¥çš„é—®é¢˜ï¼Œæ¯”å¦‚æ‰“å¼€åæŠ¥é”™ã€é—ªé€€ã€ç‚¹å‡»æ²¡æœ‰ä»»ä½•ååº”ç­‰æƒ…å†µã€‚å› æ­¤ï¼Œæˆ‘ä»¬è¿™é‡Œç»™å¤§å®¶è®²è§£ä¸€ç§æœ€ç¨³å®šçš„æ–¹å¼ï¼šæºç å®‰è£…ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬å°±åŸºäº`Win`ç³»ç»Ÿæ¥ç»™å¤§å®¶è¯¦ç»†è®²è§£æºç å®‰è£…`Neo4j`çš„å®Œæ•´æµç¨‹ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Windows æºç å®‰è£… Neo4j"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;é¦–å…ˆï¼Œè¿˜æ˜¯å¯ä»¥é€šè¿‡`GitHub`åœ°å€ä¸­çš„`Download`æŒ‰é’®è¿›å…¥åˆ°`Neo4j`çš„å®˜æ–¹åœ°å€ï¼Œä¹Ÿå¯ä»¥ç‚¹å‡»è¯¥é“¾æ¥ç›´æ¥è¿›å…¥ï¼šhttps://neo4j.com/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;åœ¨æœ€ä¸Šæ–¹å¯¼èˆªæ æ‰¾åˆ°`Products`ï¼Œç‚¹å‡»`Deployment Center`ï¼Œè¿›å…¥åˆ°`Neo4j`çš„æºç ä¸‹è½½é¡µé¢ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://muyu20241105.oss-cn-beijing.aliyuncs.com/images/202503121518268.png\" width=60%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;åœ¨`Neo4j`çš„æºç ä¸‹è½½é¡µé¢ä¸­ï¼Œéœ€è¦é€‰æ‹©`COMMUNITY`ç‰ˆæœ¬ï¼Œ(ç¤¾åŒºç‰ˆï¼Œå³å…è´¹ç‰ˆ)ï¼Œç„¶åé€‰æ‹©`Windows`ç‰ˆæœ¬ï¼Œå¹¶ä¸”æŒ‡å®šä»¥ä»€ä¹ˆæ–¹å¼ä¸‹è½½ï¼Œæ¯”å¦‚`tar`åŒ…ï¼Œ`unzip`åŒ…ï¼Œ`Source Code`ï¼Œé€‰æ‹©ç»“æŸåï¼Œç‚¹å‡»`Download`æŒ‰é’®ï¼Œä¸‹è½½æºç åŒ…ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://muyu20241105.oss-cn-beijing.aliyuncs.com/images/202503121518269.png\" width=60%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;å¦‚æœç½‘ç»œæ­£å¸¸ï¼Œä¼šè‡ªåŠ¨å¼¹å‡ºçª—å£ï¼Œå¯ä»¥é€‰æ‹©ä¸‹è½½è‡³æœ¬åœ°çš„è·¯å¾„ã€‚å¦‚ä¸‹æ‰€ç¤ºï¼š"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://muyu20241105.oss-cn-beijing.aliyuncs.com/images/202503121518270.png\" width=60%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;æœ€åï¼Œä¸‹è½½å®Œæˆåï¼Œå°†`tar` æˆ–è€… `zip` åŒ…è§£å‹åï¼Œä¾¿å¯ä»¥å¾—åˆ°`Neo4j`çš„æºç åŒ…ã€‚å¦‚ä¸‹æ‰€ç¤ºï¼š"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://muyu20241105.oss-cn-beijing.aliyuncs.com/images/202503121518271.png\" width=60%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;è‡³æ­¤ï¼Œ`Neo4j`çš„æºç åŒ…ä¾¿ä¸‹è½½å®Œæˆäº†ï¼Œå…¶å®ä¹Ÿå¹¶ä¸å¤æ‚ã€‚ä½†æ˜¯åœ¨è¿è¡Œå’Œå¯åŠ¨`Neo4j`æœåŠ¡ä¹‹å‰ï¼Œæˆ‘ä»¬éœ€è¦å…ˆé…ç½®ä¸€ä¸‹`Neo4j`çš„ç¯å¢ƒå˜é‡ã€‚é…ç½®æ–¹æ³•å°±æ˜¯å¸¸è§„çš„`Windows`ç¯å¢ƒå˜é‡é…ç½®ï¼Œé¦–å…ˆå³é”®ç‚¹å‡»`æ­¤ç”µè„‘`ï¼Œé€‰æ‹©`å±æ€§`ï¼Œç„¶åç‚¹å‡»`é«˜çº§ç³»ç»Ÿè®¾ç½®`ï¼š"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://muyu20241105.oss-cn-beijing.aliyuncs.com/images/202503121518272.png\" width=60%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;åœ¨`ç³»ç»Ÿå±æ€§`çª—å£ä¸­ï¼Œç‚¹å‡»`ç¯å¢ƒå˜é‡`æŒ‰é’®ï¼Œè¿›å…¥åˆ°`ç¯å¢ƒå˜é‡`çª—å£ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://muyu20241105.oss-cn-beijing.aliyuncs.com/images/202503121518273.png\" width=60%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;åœ¨ç³»ç»Ÿå˜é‡ä¸­ï¼Œç‚¹å‡»`æ–°å»º`æŒ‰é’®ï¼š"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://muyu20241105.oss-cn-beijing.aliyuncs.com/images/202503121518274.png\" width=60%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;åœ¨`æ–°å»º`çª—å£ä¸­ï¼Œè¾“å…¥å˜é‡å`NEO4J_HOME`ï¼Œå˜é‡å€¼ä¸º`Neo4j`çš„å®‰è£…è·¯å¾„ï¼Œæ¯”å¦‚æˆ‘åˆšæ‰è§£å‹çš„æ–‡ä»¶è·¯å¾„å°±æ˜¯`D:\\neo4k-community-2024.02.0-windows`ï¼Œç„¶åç‚¹å‡»`ç¡®å®š`æŒ‰é’®ï¼š"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://muyu20241105.oss-cn-beijing.aliyuncs.com/images/202503121518275.png\" width=60%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;é…ç½®å¥½`NEO4J_HOME`ç¯å¢ƒå˜é‡åï¼Œæˆ‘ä»¬è¿˜éœ€è¦é…ç½®`Path`ç¯å¢ƒå˜é‡ã€‚åœ¨`ç³»ç»Ÿå˜é‡`ä¸­ï¼Œç‚¹å‡»`Path`å˜é‡ï¼Œç„¶åç‚¹å‡»`ç¼–è¾‘`æŒ‰é’®:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://muyu20241105.oss-cn-beijing.aliyuncs.com/images/202503121518276.png\" width=60%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;åœ¨`Path`å˜é‡ä¸­ï¼Œç‚¹å‡»`æ–°å»º`æŒ‰é’®ï¼Œç„¶åè¾“å…¥`%NEO4J_HOME%\\bin`ï¼Œç„¶åç‚¹å‡»`ç¡®å®š`æŒ‰é’®ï¼š"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://muyu20241105.oss-cn-beijing.aliyuncs.com/images/202503121518278.png\" width=60%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;é…ç½®å¥½`Path`ç¯å¢ƒå˜é‡åï¼Œ`Neo4j`æœåŠ¡å°±é…ç½®å¥½äº†ã€‚ä½†åœ¨å¯åŠ¨ä¹‹å‰ï¼Œæˆ‘ä»¬è¿˜éœ€è¦æ£€æŸ¥ä¸€ä¸‹å½“å‰ç³»ç»Ÿæ˜¯å¦å­˜åœ¨`Java`ç¯å¢ƒï¼Œä»¥åŠ`Java`ç‰ˆæœ¬æ˜¯å¦æ»¡è¶³è¦æ±‚ã€‚é¦–å…ˆéœ€è¦æ˜ç¡®çš„æ˜¯ï¼Œ`Neo4j`æœåŠ¡ä¾èµ–äº`Java`ç¯å¢ƒï¼ŒåŒæ—¶å¯¹`Java`ç‰ˆæœ¬ä¹Ÿæœ‰ä¸€å®šçš„è¦æ±‚ï¼Œè¦æ±‚`Java`ç‰ˆæœ¬æ˜¯`OpenJDK`çš„`21`ç‰ˆæœ¬ã€‚å®˜æ–¹è¯´æ˜ï¼šhttps://neo4j.com/docs/operations-manual/current/installation/windows/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://muyu20241105.oss-cn-beijing.aliyuncs.com/images/202503121558112.png\" width=60%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;æ£€æŸ¥å½“å‰ç³»ç»Ÿ`Java`ç¯å¢ƒæ˜¯å¦å­˜åœ¨ï¼Œä»¥åŠ`Java`ç‰ˆæœ¬æ˜¯å¦æ»¡è¶³è¦æ±‚çš„å‘½ä»¤å¦‚ä¸‹æ‰€ç¤ºï¼šåœ¨`cmd`å‘½ä»¤è¡Œä¸­è¾“å…¥`java -version`ï¼Œç„¶åå›è½¦ï¼Œå¦‚æœå‡ºç°`Java`ç‰ˆæœ¬ä¿¡æ¯ï¼Œåˆ™è¯´æ˜`Java`ç¯å¢ƒå­˜åœ¨ï¼Œå¹¶ä¸”ç‰ˆæœ¬æ»¡è¶³è¦æ±‚ã€‚å¦‚æœå‡ºç°`Java`ç¯å¢ƒä¸å­˜åœ¨ï¼Œæˆ–è€…ç‰ˆæœ¬ä¸æ»¡è¶³è¦æ±‚ï¼Œåˆ™éœ€è¦å…ˆå®‰è£…`Java`ç¯å¢ƒã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://muyu20241105.oss-cn-beijing.aliyuncs.com/images/202503121518286.png\" width=60%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;å¦‚æœ`Java`ç¯å¢ƒå­˜åœ¨ï¼Œå¹¶ä¸”ç‰ˆæœ¬æ»¡è¶³è¦æ±‚ï¼Œåˆ™å¯ä»¥è·³è¿‡æ¥ä¸‹æ¥`Java`ç¯å¢ƒçš„å®‰è£…ï¼Œç›´æ¥å¯åŠ¨`Neo4j`æœåŠ¡ã€‚å¦‚æœ`Java`ç¯å¢ƒä¸å­˜åœ¨ï¼Œæˆ–è€…ç‰ˆæœ¬ä¸æ»¡è¶³è¦æ±‚ï¼Œåˆ™éœ€è¦å…ˆå®‰è£…`Java`ç¯å¢ƒã€‚å…·ä½“çš„æ–¹æ³•ä¸ºï¼šé¦–å…ˆè¿›å…¥`Oracle`å®˜ç½‘ï¼Œç‚¹å‡»`Java`ï¼Œç„¶åç‚¹å‡»`Java SE`ï¼Œè¿›å…¥åˆ°`Java`çš„ä¸‹è½½é¡µé¢ã€‚ åœ°å€ï¼šhttps://www.oracle.com/java/technologies/downloads/?er=221886#java21"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://muyu20241105.oss-cn-beijing.aliyuncs.com/images/202503121606257.png\" width=60%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;ä¸‹è½½è‡³æœ¬åœ°å¹¶æ‰§è¡Œ`.exe` çš„å®‰è£…å³å¯ï¼Œè¿™é‡Œä¸åœ¨èµ˜è¿°ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://muyu20241105.oss-cn-beijing.aliyuncs.com/images/202503121518282.png\" width=60%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;åŒæ ·ï¼Œå®‰è£…å®Œæˆä»¥åï¼Œä¹Ÿéœ€è¦é…ç½®`JAVA_HOME`ç¯å¢ƒå˜é‡ã€‚åœ¨`ç³»ç»Ÿå˜é‡`ä¸­ï¼Œç‚¹å‡»`æ–°å»º`æŒ‰é’®ï¼Œç„¶åè¾“å…¥`JAVA_HOME`ï¼Œå˜é‡å€¼ä¸º`Java`çš„å®‰è£…è·¯å¾„ï¼Œæ¯”å¦‚æˆ‘åˆšæ‰å®‰è£…çš„`Java`è·¯å¾„æ˜¯`C:\\Program Files\\Java\\jdk-21`ï¼Œç„¶åç‚¹å‡»`ç¡®å®š`æŒ‰é’®ï¼š"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://muyu20241105.oss-cn-beijing.aliyuncs.com/images/202503121611802.png\" width=80%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;é…ç½®å¥½`JAVA_HOME`ç¯å¢ƒå˜é‡åï¼Œæˆ‘ä»¬è¿˜éœ€è¦é…ç½®`Path`ç¯å¢ƒå˜é‡ã€‚åœ¨`ç³»ç»Ÿå˜é‡`ä¸­ï¼Œç‚¹å‡»`Path`å˜é‡ï¼Œç„¶åç‚¹å‡»`ç¼–è¾‘`æŒ‰é’®ï¼š"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://muyu20241105.oss-cn-beijing.aliyuncs.com/images/202503121518285.png\" width=60%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;å…¨éƒ¨é…ç½®å¥½ä»¥åï¼Œåœ¨`cmd`å‘½ä»¤è¡Œä¸­è¾“å…¥`java -version`ï¼Œç„¶åå›è½¦ï¼Œå¦‚æœå‡ºç°`Java`ç‰ˆæœ¬ä¿¡æ¯ï¼Œåˆ™è¯´æ˜`java`ç¯å¢ƒé…ç½®æˆåŠŸã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://muyu20241105.oss-cn-beijing.aliyuncs.com/images/202503121518286.png\" width=60%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;è‡³æ­¤ï¼Œé…ç½®å¥½äº†`Neo4j`æœåŠ¡çš„ç¯å¢ƒï¼ŒåŒæ—¶å…¶ä¾èµ–çš„`Java`ç¯å¢ƒä¹Ÿé…ç½®å¥½äº†ã€‚æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬å°±å¯ä»¥å¯åŠ¨`Neo4j`æœåŠ¡äº†ã€‚åœ¨`cmd`å‘½ä»¤è¡Œä¸­è¾“å…¥`neo4j windows-service install`ï¼Œç„¶åå›è½¦ï¼Œå¦‚æœå‡ºç°`Neo4j`æœåŠ¡å®‰è£…æˆåŠŸçš„ä¿¡æ¯ï¼Œåˆ™è¯´æ˜`Neo4j`æœåŠ¡å®‰è£…æˆåŠŸã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://muyu20241105.oss-cn-beijing.aliyuncs.com/images/202503121518287.png\" width=60%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;å®‰è£…æˆåŠŸåï¼Œåœ¨`cmd`å‘½ä»¤è¡Œä¸­è¾“å…¥`neo4j.bat console`ï¼Œç„¶åå›è½¦ï¼Œå¦‚æœå‡ºç°`Neo4j`æœåŠ¡å¯åŠ¨æˆåŠŸçš„ä¿¡æ¯ï¼Œåˆ™è¯´æ˜`Neo4j`æœåŠ¡å¯åŠ¨æˆåŠŸã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://muyu20241105.oss-cn-beijing.aliyuncs.com/images/202503121518288.png\" width=80%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;å¯åŠ¨åä¼šçœ‹åˆ°ä¸¤ä¸ªè¿æ¥åœ°å€ï¼Œä¸€ä¸ªæ˜¯`Bolt:localhost:7474`ï¼Œä¸€ä¸ªæ˜¯`HTTP:localhost:7474`ï¼Œå…¶ä¸­`Bolt`æ˜¯`Neo4j`çš„`Bolt`åè®®è¿æ¥åœ°å€ï¼Œ`HTTP`æ˜¯`Neo4j`çš„`HTTP`åè®®è¿æ¥åœ°å€ã€‚æˆ‘ä»¬å¯ä»¥é€šè¿‡`localhost:7474`è®¿é—®`Neo4j`çš„`Web`ç•Œé¢ï¼Œå¦‚ä¸‹æ‰€ç¤ºï¼š"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;é¦–æ¬¡ç™»å½•çš„é»˜è®¤è´¦å·æ˜¯`neo4j`ï¼Œå¯†ç æ˜¯`neo4j`ã€‚è¾“å…¥åç‚¹å‡»`connect`æŒ‰é’®ï¼Œå³å¯è¿›å…¥åˆ°`Neo4j`çš„`Web`ç•Œé¢ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://muyu20241105.oss-cn-beijing.aliyuncs.com/images/202503121518289.png\" width=80%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;åŒæ—¶ï¼Œé¦–æ¬¡ç™»å½•æˆåŠŸåä¼šæç¤ºä¿®æ”¹å¯†ç ï¼Œæ­¤æ—¶æˆ‘ä»¬ç‚¹å‡»`Change Password`æŒ‰é’®ï¼Œç„¶åè¾“å…¥æ–°çš„å¯†ç ï¼Œç‚¹å‡»`Save`æŒ‰é’®ï¼Œå³å¯ä¿®æ”¹å¯†ç ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://muyu20241105.oss-cn-beijing.aliyuncs.com/images/202503121518290.png\" width=80%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;è‡³æ­¤ï¼Œ`Neo4j`æœåŠ¡ä¾¿åœ¨æœ¬åœ°å®‰è£…æˆåŠŸå¹¶é¡ºåˆ©äº†ï¼Œæ¥ä¸‹æ¥å°±å¯ä»¥å¼€å§‹ä½¿ç”¨`Neo4j`æœåŠ¡äº†ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Python è¿æ¥ Neo4j"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;`Neo4j` ä¸ `Python`ã€`JavaScript`ã€`Java` å’Œ `.Net` ç­‰åº“éƒ½åšäº†é›†æˆï¼Œå› æ­¤åªè¦å®‰è£…äº†å¯¹åº”çš„åº“ï¼Œå°±å¯ä»¥è¿æ¥`Neo4j`æœåŠ¡ã€‚åœ¨`Python`ä¸­ï¼Œå¯ä»¥ç›´æ¥é€šè¿‡`pip` å®‰è£…`neo4j`åŒ…æ¥è¿æ¥`Neo4j`æœåŠ¡ã€‚æ‰§è¡Œå¦‚ä¸‹å‘½ä»¤ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: neo4j in /Users/fengguihuan/miniconda3/envs/hhc_base/lib/python3.10/site-packages (6.0.3)\n",
      "Requirement already satisfied: pytz in /Users/fengguihuan/miniconda3/envs/hhc_base/lib/python3.10/site-packages (from neo4j) (2025.1)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;ä»`neo4j`åŒ…ä¸­å¯¼å…¥`GraphDatabase`ç±»ï¼Œç„¶åè®¾ç½®`Neo4j`çš„è¿æ¥åœ°å€ã€ç”¨æˆ·åã€å¯†ç å’Œæ•°æ®åº“åç§°ï¼Œç„¶ååˆ›å»º`driver`å¯¹è±¡ï¼Œæœ€åé€šè¿‡`driver`å¯¹è±¡è¿æ¥`Neo4j`æœåŠ¡ã€‚æ‰§è¡Œå¦‚ä¸‹ä»£ç ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from neo4j import GraphDatabase\n",
    "\n",
    "\n",
    "# NEO4J_URI=\"bolt://localhost\"\n",
    "# NEO4J_USERNAME=\"neo4j\"\n",
    "# NEO4J_PASSWORD=\"Han9510!\"  # è¿™é‡Œæ›¿æ¢æˆè‡ªå·±è®¾ç½®çš„å¯†ç \n",
    "# NEO4J_DATABASE=\"neo4j\"         # ç¤¾åŒºç‰ˆä»…èƒ½ä½¿ç”¨é»˜è®¤çš„neo4jæ•°æ®åº“ï¼Œä¸æ”¯æŒåˆ›å»ºå…¶ä»–æ•°æ®åº“\n",
    "\n",
    "# driver = GraphDatabase.driver(\n",
    "#     NEO4J_URI, \n",
    "#     auth=(NEO4J_USERNAME, NEO4J_PASSWORD)\n",
    "#     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;å¯ä»¥å¿«é€Ÿåšä¸€ä¸ªè¿æ¥æµ‹è¯•ï¼Œæ‰§è¡Œå¦‚ä¸‹ä»£ç ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# driver = GraphDatabase.driver(\n",
    "#     NEO4J_URI, \n",
    "#     auth=(NEO4J_USERNAME, NEO4J_PASSWORD)\n",
    "#     )\n",
    "\n",
    "# def test_connection():\n",
    "#     # åœ¨è¿™é‡Œåˆ›å»ºä¼šè¯\n",
    "#     with driver.session() as session:\n",
    "#         session.run(\"MATCH (n) RETURN n LIMIT 1\")\n",
    "\n",
    "# try:\n",
    "#     test_connection()\n",
    "#     print(\"è¿æ¥æˆåŠŸï¼\")\n",
    "# except Exception as e:\n",
    "#     print(\"è¿æ¥å¤±è´¥:\", e)\n",
    "# finally:\n",
    "#     driver.close()  # ç¡®ä¿åœ¨æ‰€æœ‰æ“ä½œå®Œæˆåå†å…³é—­é©±åŠ¨ç¨‹åº"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;å¦‚æœè¿”å›ç»“æœä¸º`è¿æ¥æˆåŠŸï¼`ï¼Œåˆ™è¯´æ˜`Neo4j`æœåŠ¡ä¸€åˆ‡æ­£å¸¸ï¼Œä¾¿å¯ä»¥è¿›å…¥ä¸‹é¢çš„å®è·µã€‚å¦åˆ™éœ€è¦è¿›ä¸€æ­¥æ£€æŸ¥`Neo4j`æœåŠ¡æ˜¯å¦æ­£å¸¸å¯åŠ¨ï¼Œä»¥åŠ`Neo4j`çš„è¿æ¥åœ°å€ã€ç”¨æˆ·åã€å¯†ç å’Œæ•°æ®åº“åç§°æ˜¯å¦æ­£ç¡®ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. çŸ¥è¯†å›¾è°±å¿«é€Ÿå…¥é—¨"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;çŸ¥è¯†å›¾è°±å»ºç«‹åœ¨å›¾è®ºçš„åŸºç¡€ä¸Šï¼Œè€Œå›¾æ˜¯ç”¨äºå¯¹å¯¹è±¡ä¹‹é—´çš„æˆå¯¹å…³ç³»è¿›è¡Œå»ºæ¨¡çš„ç»“æ„ã€‚å›¾ä¸»è¦ç”±ä¸¤ä¸ªä¸»è¦å…ƒç´ ç»„æˆï¼š<font color=\"red\">èŠ‚ç‚¹</font>å’Œ<font color=\"red\">å…³ç³»</font>ã€‚å…¶ä¸­ï¼š\n",
    "\n",
    "- èŠ‚ç‚¹ä»£è¡¨å•ä¸ªå¯¹è±¡æˆ–å®ä½“ï¼Œç±»ä¼¼äºä¼ ç»Ÿæ•°æ®åº“ä¸­çš„è®°å½•ã€‚è¿™äº›å®ä½“å¯ä»¥æ˜¯ä»»ä½•äººã€å…¬å¸æˆ–åœ°ç‚¹ã€‚\n",
    "- èŠ‚ç‚¹é€šè¿‡æ ‡ç­¾è¿›è¡Œåˆ†ç±»ï¼Œæ–¹ä¾¿æ ¹æ®èŠ‚ç‚¹çš„è§’è‰²è¿›è¡Œåˆ†ç±»å’ŒæŸ¥è¯¢ï¼Œä¾‹å¦‚â€œå®¢æˆ·â€æˆ–â€œäº§å“â€ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;`Neo4j` æ˜¯å­˜å‚¨çŸ¥è¯†å›¾è°±çš„å…¶ä¸­ä¸€ç§å›¾æ•°æ®åº“ï¼Œå®ƒæ”¯æŒèŠ‚ç‚¹å’Œå…³ç³»çš„å­˜å‚¨ï¼ŒåŒæ—¶ï¼Œé€šè¿‡`Cypher`æŸ¥è¯¢è¯­è¨€è¿›è¡Œå›¾è°±çš„åˆ›å»ºã€æŸ¥è¯¢å’Œåˆ†æï¼Œå³ `Cypher` æ˜¯ `Neo4j` ä¸­ç”¨äºäº¤äº’å’Œæ“ä½œå›¾è°±çš„æŸ¥è¯¢è¯­è¨€ã€‚å…¶å½¢å¼åŠå¦‚ä¸‹ï¼š"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://muyu20241105.oss-cn-beijing.aliyuncs.com/images/202503131043957.png\" width=80%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;è€Œå…³äº`Cypher`æŸ¥è¯¢è¯­è¨€çš„è¯¦ç»†ä»‹ç»ï¼Œå¯ä»¥å‚è€ƒ`Neo4j`çš„å®˜æ–¹æ–‡æ¡£ï¼š[Cypher Core concepts](https://neo4j.com/docs/cypher-manual/current/queries/concepts/)è¿›è¡Œå­¦ä¹ ã€‚æˆ‘ä»¬è¿™é‡Œä¸å¯¹åŸºç¡€å†…å®¹å±•å¼€è¯¦ç»†çš„ä»‹ç»ã€‚æœ¬èŠ‚è¯¾çš„é‡ç‚¹æ˜¯å€ŸåŠ©`Neo4j` çš„ `Python` é›†æˆï¼Œç»™å¤§å®¶ä»‹ç»ç”¨äºæ¥ä¸‹æ¥`Microsoft GraphRAG` ç´¢å¼•æ–‡ä»¶æ¥å…¥è¿‡ç¨‹æ—¶å¿…å¤‡çš„ç›¸å…³æ¦‚å¿µã€‚ä¸»è¦æœ‰ä»¥ä¸‹å‡ ç‚¹ï¼š"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **èŠ‚ç‚¹ï¼Œå¯ä»¥æ˜¯`Person`ã€`Organization`ã€`Product`ã€`Location`ç­‰å®ä½“ç±»å‹ï¼Œæ¯ä¸ªèŠ‚ç‚¹å¯ä»¥æœ‰å¤šä¸ªå±æ€§ï¼Œä¾‹å¦‚`name`ã€`age`ã€`gender`ç­‰ï¼ŒåŒæ—¶<font color=\"red\">å±æ€§æ˜¯ä»¥é”®å€¼å¯¹å½¢å¼å­˜å‚¨çš„</font>ã€‚**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from neo4j import GraphDatabase\n",
    "\n",
    "\n",
    "# NEO4J_URI=\"bolt://localhost\"\n",
    "# NEO4J_USERNAME=\"neo4j\"\n",
    "# NEO4J_PASSWORD=\"Han9510!\"  # è¿™é‡Œæ›¿æ¢æˆè‡ªå·±è®¾ç½®çš„å¯†ç \n",
    "# NEO4J_DATABASE=\"neo4j\"         # ç¤¾åŒºç‰ˆä»…èƒ½ä½¿ç”¨é»˜è®¤çš„neo4jæ•°æ®åº“ï¼Œä¸æ”¯æŒåˆ›å»ºå…¶ä»–æ•°æ®åº“\n",
    "\n",
    "# driver = GraphDatabase.driver(\n",
    "#     NEO4J_URI, \n",
    "#     auth=(NEO4J_USERNAME, NEO4J_PASSWORD)\n",
    "#     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;é€šè¿‡`CREATE`è¯­å¥å¯ä»¥åˆ›å»ºèŠ‚ç‚¹ï¼ŒåŒæ—¶å¯ä»¥ä¸ºèŠ‚ç‚¹æ·»åŠ å±æ€§ï¼Œè¯­æ³•å½¢å¼æ˜¯ï¼š\n",
    "\n",
    "```python \n",
    "    CREATE (node_name:node_type {property_name: property_value, ...})\n",
    "```\n",
    "\n",
    "&emsp;&emsp;å…¶ä¸­ï¼Œ`node_name` è¿™æ˜¯ä¸€ä¸ªå˜é‡åï¼Œç”¨äºå¼•ç”¨åˆ›å»ºçš„èŠ‚ç‚¹ï¼Œ`node_type` æ˜¯èŠ‚ç‚¹çš„æ ‡ç­¾ï¼Œè¡¨ç¤ºèŠ‚ç‚¹çš„ç±»å‹ï¼Œ`property_name` æ˜¯å±æ€§çš„åç§°ï¼Œ`property_value` æ˜¯å±æ€§çš„å€¼ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# with driver.session() as session:\n",
    "#     # æ·»åŠ å¤šä¸ªèŠ‚ç‚¹ï¼šPerson\n",
    "#     session.run(\"\"\"\n",
    "#         CREATE (p1:Person {name: 'muyu', age: 30, city: 'beijing'}),\n",
    "#                (p2:Person {name: 'zhangsan', age: 23, city: 'shanghai'})\n",
    "#     \"\"\")\n",
    "    \n",
    "#     # æ·»åŠ å¤šä¸ªèŠ‚ç‚¹ï¼šCompany\n",
    "#     session.run(\"\"\"\n",
    "#         CREATE (c1:Company {name: 'Fufan', industry: 'Technology', location: 'beijing'}),\n",
    "#                (c2:Company {name: 'Beyond', industry: 'Education', location: 'beijing'})\n",
    "#     \"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from neo4j import GraphDatabase\n",
    "\n",
    "# # 1. é…ç½®Neo4jè¿æ¥ä¿¡æ¯ï¼ˆæ›¿æ¢ä¸ºä½ çš„å®é™…é…ç½®ï¼‰\n",
    "# NEO4J_URI = \"bolt://localhost:7474\"\n",
    "# NEO4J_USER = \"neo4j\"\n",
    "# NEO4J_PASSWORD = \"Han9510!\"\n",
    "\n",
    "# # 2. åˆå§‹åŒ–é©±åŠ¨å¹¶åˆ é™¤æ‰€æœ‰å†…å®¹\n",
    "# def clear_neo4j_database():\n",
    "#     # åˆ›å»ºé©±åŠ¨å®ä¾‹\n",
    "#     driver = GraphDatabase.driver(NEO4J_URI, auth=(NEO4J_USER, NEO4J_PASSWORD))\n",
    "    \n",
    "#     try:\n",
    "#         with driver.session() as session:\n",
    "#             # æ­¥éª¤1ï¼šåˆ é™¤æ‰€æœ‰èŠ‚ç‚¹å’Œå…³ç³»ï¼ˆæ ¸å¿ƒæ“ä½œï¼‰\n",
    "#             # DETACH DELETE ä¼šåŒæ—¶åˆ é™¤èŠ‚ç‚¹åŠå…¶å…³è”çš„æ‰€æœ‰å…³ç³»\n",
    "#             session.run(\"MATCH (n) DETACH DELETE n\")\n",
    "            \n",
    "#             # æ­¥éª¤2ï¼šåˆ é™¤æ‰€æœ‰ç´¢å¼•ï¼ˆå¯é€‰ï¼Œè‹¥éœ€å½»åº•æ¸…ç©ºï¼‰\n",
    "#             # è·å–æ‰€æœ‰ç´¢å¼•å¹¶åˆ é™¤\n",
    "#             indexes = session.run(\"SHOW INDEXES YIELD name WHERE name IS NOT NULL\").data()\n",
    "#             for idx in indexes:\n",
    "#                 session.run(f\"DROP INDEX {idx['name']}\")\n",
    "            \n",
    "#             # æ­¥éª¤3ï¼šåˆ é™¤æ‰€æœ‰çº¦æŸï¼ˆå¯é€‰ï¼Œè‹¥éœ€å½»åº•æ¸…ç©ºï¼‰\n",
    "#             # è·å–æ‰€æœ‰çº¦æŸå¹¶åˆ é™¤\n",
    "#             constraints = session.run(\"SHOW CONSTRAINTS YIELD name WHERE name IS NOT NULL\").data()\n",
    "#             for cons in constraints:\n",
    "#                 session.run(f\"DROP CONSTRAINT {cons['name']}\")\n",
    "            \n",
    "#             print(\"âœ… Neo4jæ•°æ®åº“å·²å®Œå…¨æ¸…ç©ºï¼ˆèŠ‚ç‚¹ã€å…³ç³»ã€ç´¢å¼•ã€çº¦æŸå‡å·²åˆ é™¤ï¼‰\")\n",
    "    \n",
    "#     except Exception as e:\n",
    "#         print(f\"âŒ åˆ é™¤å¤±è´¥ï¼š{str(e)}\")\n",
    "    \n",
    "#     finally:\n",
    "#         # å…³é—­é©±åŠ¨è¿æ¥\n",
    "#         driver.close()\n",
    "\n",
    "# # 3. æ‰§è¡Œåˆ é™¤æ“ä½œ\n",
    "# if __name__ == \"__main__\":\n",
    "#     clear_neo4j_database()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;å¦‚ä¸Šä»£ç æ‰€ç¤ºï¼šç±»ä¼¼ `p1` è¿™ç§çš„ç”Ÿå‘½å‘¨æœŸä»…ä»…æ˜¯å±€éƒ¨ä½œç”¨åŸŸï¼šå˜é‡çš„ä½œç”¨åŸŸé€šå¸¸æ˜¯å±€éƒ¨çš„ï¼Œä»…åœ¨åˆ›å»ºå®ƒçš„æŸ¥è¯¢ä¸­æœ‰æ•ˆã€‚ä¸€æ—¦æŸ¥è¯¢æ‰§è¡Œå®Œæ¯•ï¼Œå˜é‡å°±ä¸å†å­˜åœ¨ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://muyu20241105.oss-cn-beijing.aliyuncs.com/images/202503131057101.png\" width=80%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;è¿™é‡Œé¢çš„`Person` å’Œ `Company` æ˜¯èŠ‚ç‚¹çš„æ ‡ç­¾ï¼Œ`name`ã€`age`ã€`city` æ˜¯èŠ‚ç‚¹çš„å±æ€§ï¼Œ`muyu`ã€`zhangsan`ã€`beijing` æ˜¯èŠ‚ç‚¹çš„å±æ€§å€¼ã€‚ å…¶ä¸­ï¼š\n",
    "\n",
    "- é€šè¿‡`CREATE`è¯­å¥åˆ›å»ºèŠ‚ç‚¹æ—¶ï¼Œå¦‚æœè¯¥æ ‡ç­¾ä¸å­˜åœ¨ï¼Œåˆ™åˆ›å»ºè¯¥æ ‡ç­¾ï¼Œå¦åˆ™ä¸åˆ›å»ºã€‚\n",
    "- ä¸€ä¸ªæ ‡ç­¾ä¸‹å¯ä»¥æœ‰å¤šä¸ªèŠ‚ç‚¹ï¼Œä¸€ä¸ªèŠ‚ç‚¹ä¹Ÿå¯ä»¥æœ‰å¤šä¸ªæ ‡ç­¾ã€‚æ¯”å¦‚`Person` æ ‡ç­¾ä¸‹å¯ä»¥æœ‰`muyu` å’Œ `zhangsan` ä¸¤ä¸ªèŠ‚ç‚¹ï¼Œ åŒæ—¶`muyu` å’Œ `zhangsan` ä¹Ÿå¯ä»¥æœ‰å¤šä¸ªæ ‡ç­¾ï¼Œæ¯”å¦‚åŒæ—¶æ˜¯ `Person` å’Œ `Student`ã€‚\n",
    "- ä¸€ä¸ªèŠ‚ç‚¹å¯ä»¥æœ‰å¤šä¸ªå±æ€§ï¼Œæ¯”å¦‚`muyu` èŠ‚ç‚¹å¯ä»¥æœ‰`name`ã€`age`ã€`city` ä¸‰ä¸ªå±æ€§ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;æ¯”å¦‚æˆ‘ä»¬ç°åœ¨å°†`muyu` å’Œ `zhangsan` å¢åŠ åˆ° `Student` æ ‡ç­¾ä¸‹çš„èŠ‚ç‚¹ï¼ŒåŒæ—¶ä»–ä»¬ä¹Ÿæ˜¯ `Person` æ ‡ç­¾ä¸‹çš„èŠ‚ç‚¹ã€‚å› æ­¤æˆ‘ä»¬é€šè¿‡å¦‚ä¸‹`Cypher`è¯­å¥è¿›è¡Œåˆ›å»ºï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;è¿™é‡Œéœ€è¦äº†è§£çš„çŸ¥è¯†ç‚¹æ˜¯ï¼š`MATCH` è¯­å¥ç”¨äºåœ¨å›¾è°±ä¸­æŸ¥æ‰¾èŠ‚ç‚¹ï¼Œ`SET` è¯­å¥ç”¨äºä¸ºèŠ‚ç‚¹æ·»åŠ æ ‡ç­¾ï¼Œ`RETURN` è¯­å¥ç”¨äºè¿”å›æ·»åŠ æ ‡ç­¾åçš„èŠ‚ç‚¹ã€‚æ‰§è¡Œååœ¨`Neo4j`çš„æµè§ˆå™¨ä¸­å¯ä»¥çœ‹åˆ°ï¼š`muyu` å’Œ `zhangsan` åŒæ—¶æ˜¯ `Person` å’Œ `Student` æ ‡ç­¾ä¸‹çš„èŠ‚ç‚¹ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://muyu20241105.oss-cn-beijing.aliyuncs.com/images/202503131118642.png\" width=80%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;åŒæ—¶ï¼Œæˆ‘ä»¬ä¹Ÿå¯ä»¥æ›´æ–°èŠ‚ç‚¹çš„å±æ€§ï¼Œæ¯”å¦‚å°†`muyu` çš„`age` å±æ€§æ›´æ–°ä¸º`31`ï¼Œé€šè¿‡å¦‚ä¸‹`Cypher`è¯­å¥è¿›è¡Œæ›´æ–°ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with driver.session() as session:\n",
    "#     session.run(\"\"\"\n",
    "#         MATCH (p:Person {name: 'muyu'})\n",
    "#         SET p.age = 31\n",
    "#         RETURN p\n",
    "#     \"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;æ‰§è¡Œååœ¨`Neo4j`çš„æµè§ˆå™¨ä¸­å¯ä»¥çœ‹åˆ°ï¼š`muyu` çš„`age` å±æ€§è¢«æ›´æ–°ä¸º`31`ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://muyu20241105.oss-cn-beijing.aliyuncs.com/images/202503131121413.png\" width=80%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- å…³ç³»ï¼šå…³ç³»æ˜¯è¿æ¥èŠ‚ç‚¹çš„è¾¹ï¼Œç”¨äºè¡¨ç¤ºèŠ‚ç‚¹ä¹‹é—´çš„å…³è”ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;å…³ç³»ç”±ä¸¤ä¸ªä¸»è¦å…ƒç´ ç»„æˆï¼š\n",
    "  - å…³ç³»ç±»å‹ï¼šè¡¨ç¤ºå…³ç³»çš„åç§°ï¼Œä¾‹å¦‚â€œæœ‹å‹â€æˆ–â€œåŒäº‹â€ã€‚\n",
    "  - å…³ç³»æ–¹å‘ï¼šè¡¨ç¤ºå…³ç³»çš„æ–¹å‘ï¼Œä¾‹å¦‚â€œä»Aåˆ°Bâ€æˆ–â€œä»Båˆ°Aâ€ã€‚\n",
    "\n",
    "&emsp;&emsp;å…³ç³»ç±»å‹å’Œå…³ç³»æ–¹å‘æ˜¯å…³ç³»çš„é‡è¦ç»„æˆéƒ¨åˆ†ï¼Œç”¨äºæè¿°èŠ‚ç‚¹ä¹‹é—´çš„å…³è”ã€‚å…³ç³»ç±»å‹å¯ä»¥æ˜¯ä»»ä½•å­—ç¬¦ä¸²ï¼Œè€Œå…³ç³»æ–¹å‘å¯ä»¥æ˜¯â€œæ­£å‘â€æˆ–â€œåå‘â€ã€‚å…¶è¯­æ³•å½¢å¼å¦‚ä¸‹ï¼š\n",
    "\n",
    "```python\n",
    "    CREATE (node_name)-[:relation_type]->(related_node_name)\n",
    "```\n",
    "\n",
    "&emsp;&emsp;å…¶ä¸­ï¼Œ`node_name` æ˜¯èŠ‚ç‚¹çš„åç§°ï¼Œ`relation_type` æ˜¯å…³ç³»çš„ç±»å‹ï¼Œ`related_node_name` æ˜¯ç›¸å…³èŠ‚ç‚¹çš„åç§°"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;è¿™é‡Œæˆ‘ä»¬ä»¥`muyu` å’Œ `zhangsan` ä¸ºä¾‹ï¼Œåˆ›å»º`company` å’Œ `person` ä¹‹é—´çš„å…³ç³»ï¼Œé€šè¿‡å¦‚ä¸‹`Cypher`è¯­å¥è¿›è¡Œåˆ›å»ºï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with driver.session() as session:\n",
    "#     # åˆ›å»ºmuyuä¸Fufanå…¬å¸ä¹‹é—´çš„EMPLOYED_BYå…³ç³»\n",
    "#     session.run(\"\"\"\n",
    "#         MATCH (p:Person {name: 'muyu'})\n",
    "#         MATCH (c:Company {name: 'Fufan'})\n",
    "#         CREATE (p)-[:EMPLOYED_BY]->(c)\n",
    "#     \"\"\")\n",
    "    \n",
    "#     # åˆ›å»ºzhangsanä¸Beyondå…¬å¸ä¹‹é—´çš„LIVES_INå…³ç³»\n",
    "#     session.run(\"\"\"\n",
    "#         MATCH (p:Person {name: 'zhangsan'})\n",
    "#         MATCH (c:Company {name: 'Beyond'})\n",
    "#         CREATE (p)-[:EMPLOYED_BY]->(c)\n",
    "#     \"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;éœ€è¦ä½¿ç”¨`MATCH`è¯­å¥å…ˆæ‰¾åˆ°ç›¸åº”çš„èŠ‚ç‚¹ï¼Œç„¶åå†åˆ›å»ºå®ƒä»¬ä¹‹é—´çš„å…³ç³»ã€‚æ‰§è¡Œä»£ç åï¼Œåˆ™å¯ä»¥åœ¨`Neo4j`çš„æµè§ˆå™¨ä¸­çœ‹åˆ°ï¼š`muyu` å’Œ `zhangsan` ä¸`Fufan` å’Œ `Beyond` å…¬å¸ä¹‹é—´å»ºç«‹äº†`EMPLOYED_BY` å…³ç³»ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://muyu20241105.oss-cn-beijing.aliyuncs.com/images/202503131127430.png\" width=80%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;ä»¥ä¸Šæ˜¯é€šè¿‡èŠ‚ç‚¹ã€å±æ€§ã€æ ‡ç­¾ã€å…³ç³»å››ä¸ªæ¦‚å¿µçš„è§’åº¦ï¼Œç»™å¤§å®¶ä»‹ç»äº†`Neo4j` ä¸­å›¾è°±çš„åˆ›å»ºã€æ›´æ–°å’ŒæŸ¥è¯¢ã€‚è¿™æ ·çš„å›¾è°±å…¶å®å°±å·²ç»å…·å¤‡äº†çŸ¥è¯†å›¾è°±çš„é›å½¢ï¼Œå³ï¼š\n",
    "\n",
    "- èŠ‚ç‚¹ï¼šè¡¨ç¤ºå®ä½“ï¼Œä¾‹å¦‚äººã€å…¬å¸ã€åœ°ç‚¹ç­‰ã€‚\n",
    "- å±æ€§ï¼šè¡¨ç¤ºå®ä½“çš„ç‰¹å¾ï¼Œä¾‹å¦‚å§“åã€å¹´é¾„ã€åŸå¸‚ç­‰ã€‚\n",
    "- æ ‡ç­¾ï¼šè¡¨ç¤ºå®ä½“çš„ç±»å‹ï¼Œä¾‹å¦‚`Person`ã€`Company`ã€`Student`ç­‰ã€‚\n",
    "- å…³ç³»ï¼šè¡¨ç¤ºå®ä½“ä¹‹é—´çš„å…³ç³»ï¼Œä¾‹å¦‚`EMPLOYED_BY`ç­‰ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;æˆ‘ä»¬æ˜¯å¯ä»¥åŸºäºè¿™æ ·çš„å›¾è°±å¼€å§‹è¿›è¡Œç®€å•åˆ°å¤æ‚çš„æŸ¥è¯¢çš„ï¼Œæ¯”å¦‚å¦‚ä¸‹çš„ä¸€äº›ç¤ºä¾‹ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def neo4j_query_examples(driver, query_type, params=None):\n",
    "#     \"\"\"\n",
    "#     æ‰§è¡Œå„ç§Neo4jæŸ¥è¯¢ç¤ºä¾‹\n",
    "    \n",
    "#     å‚æ•°:\n",
    "#     - driver: Neo4jé©±åŠ¨å®ä¾‹\n",
    "#     - query_type: æŸ¥è¯¢ç±»å‹ï¼Œå¯é€‰å€¼åŒ…æ‹¬:\n",
    "#         'all_persons', 'all_companies', 'filter_by_city', 'all_relationships',\n",
    "#         'specific_relationship', 'node_relationships', 'path_query', 'aggregation',\n",
    "#         'group_by', 'colleagues', 'complex_query', 'param_query', 'subgraph', 'community'\n",
    "#     - params: æŸ¥è¯¢å‚æ•°å­—å…¸ï¼Œæ ¹æ®æŸ¥è¯¢ç±»å‹ä¸åŒè€Œä¸åŒ\n",
    "    \n",
    "#     è¿”å›:\n",
    "#     - æŸ¥è¯¢ç»“æœåˆ—è¡¨\n",
    "#     \"\"\"\n",
    "#     if params is None:\n",
    "#         params = {}\n",
    "    \n",
    "#     results = []\n",
    "    \n",
    "#     with driver.session() as session:\n",
    "#         if query_type == 'all_persons':\n",
    "#             # æŸ¥è¯¢æ‰€æœ‰PersonèŠ‚ç‚¹\n",
    "#             result = session.run(\"\"\"\n",
    "#                 MATCH (p:Person)\n",
    "#                 RETURN p.name AS name, p.age AS age, p.city AS city\n",
    "#             \"\"\")\n",
    "            \n",
    "#             print(\"æ‰€æœ‰PersonèŠ‚ç‚¹:\")\n",
    "#             for record in result:\n",
    "#                 print(f\"å§“å: {record['name']}, å¹´é¾„: {record['age']}, åŸå¸‚: {record['city']}\")\n",
    "#                 results.append({\n",
    "#                     'name': record['name'],\n",
    "#                     'age': record['age'],\n",
    "#                     'city': record['city']\n",
    "#                 })\n",
    "        \n",
    "#         elif query_type == 'all_companies':\n",
    "#             # æŸ¥è¯¢æ‰€æœ‰CompanyèŠ‚ç‚¹\n",
    "#             result = session.run(\"\"\"\n",
    "#                 MATCH (c:Company)\n",
    "#                 RETURN c.name AS name, c.industry AS industry, c.location AS location\n",
    "#             \"\"\")\n",
    "            \n",
    "#             print(\"æ‰€æœ‰CompanyèŠ‚ç‚¹:\")\n",
    "#             for record in result:\n",
    "#                 print(f\"å…¬å¸: {record['name']}, è¡Œä¸š: {record['industry']}, ä½ç½®: {record['location']}\")\n",
    "#                 results.append({\n",
    "#                     'name': record['name'],\n",
    "#                     'industry': record['industry'],\n",
    "#                     'location': record['location']\n",
    "#                 })\n",
    "        \n",
    "#         elif query_type == 'filter_by_city':\n",
    "#             # æŒ‰åŸå¸‚è¿‡æ»¤PersonèŠ‚ç‚¹\n",
    "#             city = params.get('city', 'beijing')\n",
    "#             result = session.run(\"\"\"\n",
    "#                 MATCH (p:Person)\n",
    "#                 WHERE p.city = $city\n",
    "#                 RETURN p.name AS name, p.age AS age\n",
    "#             \"\"\", {'city': city})\n",
    "            \n",
    "#             print(f\"{city}çš„äººå‘˜:\")\n",
    "#             for record in result:\n",
    "#                 print(f\"å§“å: {record['name']}, å¹´é¾„: {record['age']}\")\n",
    "#                 results.append({\n",
    "#                     'name': record['name'],\n",
    "#                     'age': record['age']\n",
    "#                 })\n",
    "        \n",
    "#         elif query_type == 'all_relationships':\n",
    "#             # æŸ¥è¯¢æ‰€æœ‰å…³ç³»\n",
    "#             result = session.run(\"\"\"\n",
    "#                 MATCH (p:Person)-[r]->(c:Company)\n",
    "#                 RETURN p.name AS person, type(r) AS relationship, c.name AS company\n",
    "#             \"\"\")\n",
    "            \n",
    "#             print(\"æ‰€æœ‰äººå‘˜ä¸å…¬å¸çš„å…³ç³»:\")\n",
    "#             for record in result:\n",
    "#                 print(f\"{record['person']} {record['relationship']} {record['company']}\")\n",
    "#                 results.append({\n",
    "#                     'person': record['person'],\n",
    "#                     'relationship': record['relationship'],\n",
    "#                     'company': record['company']\n",
    "#                 })\n",
    "        \n",
    "#         elif query_type == 'specific_relationship':\n",
    "#             # æŸ¥è¯¢ç‰¹å®šç±»å‹çš„å…³ç³»\n",
    "#             rel_type = params.get('rel_type', 'EMPLOYED_BY')\n",
    "#             result = session.run(f\"\"\"\n",
    "#                 MATCH (p:Person)-[:{rel_type}]->(c:Company)\n",
    "#                 RETURN p.name AS person, c.name AS company\n",
    "#             \"\"\")\n",
    "            \n",
    "#             print(f\"{rel_type}å…³ç³»:\")\n",
    "#             for record in result:\n",
    "#                 print(f\"{record['person']} ä¸ {record['company']} æœ‰{rel_type}å…³ç³»\")\n",
    "#                 results.append({\n",
    "#                     'person': record['person'],\n",
    "#                     'company': record['company']\n",
    "#                 })\n",
    "        \n",
    "#         elif query_type == 'node_relationships':\n",
    "#             # æŸ¥è¯¢ç‰¹å®šèŠ‚ç‚¹çš„å…³ç³»\n",
    "#             person_name = params.get('person_name', 'muyu')\n",
    "#             result = session.run(\"\"\"\n",
    "#                 MATCH (p:Person {name: $name})-[r]->(c)\n",
    "#                 RETURN type(r) AS relationship, c.name AS connected_to, labels(c) AS node_type\n",
    "#             \"\"\", {'name': person_name})\n",
    "            \n",
    "#             print(f\"{person_name}çš„æ‰€æœ‰å…³ç³»:\")\n",
    "#             for record in result:\n",
    "#                 print(f\"å…³ç³»ç±»å‹: {record['relationship']}, è¿æ¥åˆ°: {record['connected_to']}, èŠ‚ç‚¹ç±»å‹: {record['node_type']}\")\n",
    "#                 results.append({\n",
    "#                     'relationship': record['relationship'],\n",
    "#                     'connected_to': record['connected_to'],\n",
    "#                     'node_type': record['node_type']\n",
    "#                 })\n",
    "              \n",
    "#         elif query_type == 'aggregation':\n",
    "#             # èšåˆæŸ¥è¯¢\n",
    "#             result = session.run(\"\"\"\n",
    "#                 MATCH (p:Person)-[:EMPLOYED_BY]->(c:Company)\n",
    "#                 RETURN c.name AS company, count(p) AS employee_count, avg(p.age) AS avg_age\n",
    "#             \"\"\")\n",
    "            \n",
    "#             print(\"å…¬å¸å‘˜å·¥ç»Ÿè®¡:\")\n",
    "#             for record in result:\n",
    "#                 print(f\"å…¬å¸: {record['company']}, å‘˜å·¥æ•°: {record['employee_count']}, å¹³å‡å¹´é¾„: {round(record['avg_age'], 1)}\")\n",
    "#                 results.append({\n",
    "#                     'company': record['company'],\n",
    "#                     'employee_count': record['employee_count'],\n",
    "#                     'avg_age': record['avg_age']\n",
    "#                 })\n",
    "        \n",
    "#         elif query_type == 'group_by':\n",
    "#             # æ¡ä»¶åˆ†ç»„æŸ¥è¯¢\n",
    "#             result = session.run(\"\"\"\n",
    "#                 MATCH (p:Person)\n",
    "#                 RETURN p.city AS city, count(p) AS person_count,\n",
    "#                        collect(p.name) AS names\n",
    "#                 ORDER BY person_count DESC\n",
    "#             \"\"\")\n",
    "            \n",
    "#             print(\"æŒ‰åŸå¸‚åˆ†ç»„çš„äººå‘˜ç»Ÿè®¡:\")\n",
    "#             for record in result:\n",
    "#                 print(f\"åŸå¸‚: {record['city']}, äººæ•°: {record['person_count']}, å§“å: {record['names']}\")\n",
    "#                 results.append({\n",
    "#                     'city': record['city'],\n",
    "#                     'person_count': record['person_count'],\n",
    "#                     'names': record['names']\n",
    "#                 })\n",
    "        \n",
    "        \n",
    "#         elif query_type == 'complex_query':\n",
    "#             # å¤šæ¡ä»¶å¤åˆæŸ¥è¯¢\n",
    "#             min_age = params.get('min_age', 25)\n",
    "#             location = params.get('location', 'beijing')\n",
    "#             result = session.run(\"\"\"\n",
    "#                 MATCH (p:Person)-[r]->(c:Company)\n",
    "#                 WHERE p.age > $min_age AND c.location = $location\n",
    "#                 AND (type(r) = 'EMPLOYED_BY' OR type(r) = 'INVESTED_IN')\n",
    "#                 RETURN p.name AS person, p.age AS age, \n",
    "#                        type(r) AS relationship, c.name AS company\n",
    "#                 ORDER BY p.age DESC\n",
    "#             \"\"\", {'min_age': min_age, 'location': location})\n",
    "            \n",
    "#             print(f\"{min_age}å²ä»¥ä¸Šä¸”ä¸{location}å…¬å¸æœ‰é›‡ä½£æˆ–æŠ•èµ„å…³ç³»çš„äºº:\")\n",
    "#             for record in result:\n",
    "#                 print(f\"{record['person']} ({record['age']}å²) {record['relationship']} {record['company']}\")\n",
    "#                 results.append({\n",
    "#                     'person': record['person'],\n",
    "#                     'age': record['age'],\n",
    "#                     'relationship': record['relationship'],\n",
    "#                     'company': record['company']\n",
    "#                 })\n",
    "        \n",
    "#         elif query_type == 'param_query':\n",
    "#             # å‚æ•°åŒ–æŸ¥è¯¢\n",
    "#             query_params = {\n",
    "#                 'min_age': params.get('min_age', 25),\n",
    "#                 'location': params.get('location', 'beijing'),\n",
    "#                 'relationship_types': params.get('relationship_types', [\"EMPLOYED_BY\", \"INVESTED_IN\"])\n",
    "#             }\n",
    "            \n",
    "#             result = session.run(\"\"\"\n",
    "#                 MATCH (p:Person)-[r]->(c:Company)\n",
    "#                 WHERE p.age > $min_age AND c.location = $location\n",
    "#                 AND type(r) IN $relationship_types\n",
    "#                 RETURN p.name AS person, type(r) AS relationship, c.name AS company\n",
    "#             \"\"\", query_params)\n",
    "            \n",
    "#             print(f\"å‚æ•°åŒ–æŸ¥è¯¢ç»“æœ (å¹´é¾„ > {query_params['min_age']}, ä½ç½®: {query_params['location']}):\")\n",
    "#             for record in result:\n",
    "#                 print(f\"{record['person']} {record['relationship']} {record['company']}\")\n",
    "#                 results.append({\n",
    "#                     'person': record['person'],\n",
    "#                     'relationship': record['relationship'],\n",
    "#                     'company': record['company']\n",
    "#                 })\n",
    "        \n",
    "#         else:\n",
    "#             print(f\"æœªçŸ¥çš„æŸ¥è¯¢ç±»å‹: {query_type}\")\n",
    "#             results.append({\"error\": f\"æœªçŸ¥çš„æŸ¥è¯¢ç±»å‹: {query_type}\"})\n",
    "    \n",
    "#     return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from neo4j import GraphDatabase\n",
    "\n",
    "# NEO4J_URI=\"bolt://localhost\"\n",
    "# NEO4J_USERNAME=\"neo4j\"\n",
    "# NEO4J_PASSWORD=\"Han9510!\"  # è¿™é‡Œæ›¿æ¢æˆè‡ªå·±è®¾ç½®çš„å¯†ç \n",
    "# NEO4J_DATABASE=\"neo4j\"         # ç¤¾åŒºç‰ˆä»…èƒ½ä½¿ç”¨é»˜è®¤çš„neo4jæ•°æ®åº“ï¼Œä¸æ”¯æŒåˆ›å»ºå…¶ä»–æ•°æ®åº“\n",
    "\n",
    "# driver = GraphDatabase.driver(\n",
    "#     NEO4J_URI, \n",
    "#     auth=(NEO4J_USERNAME, NEO4J_PASSWORD)\n",
    "#     )\n",
    "\n",
    "# try:\n",
    "#     # æŸ¥è¯¢æ‰€æœ‰PersonèŠ‚ç‚¹\n",
    "#     neo4j_query_examples(driver, 'all_persons')\n",
    "    \n",
    "#     # æŸ¥è¯¢åŒ—äº¬çš„äººå‘˜\n",
    "#     neo4j_query_examples(driver, 'filter_by_city', {'city': 'beijing'})\n",
    "    \n",
    "#     # æŸ¥è¯¢muyuçš„æ‰€æœ‰å…³ç³»\n",
    "#     neo4j_query_examples(driver, 'node_relationships', {'person_name': 'muyu'})\n",
    "    \n",
    "#     # æ‰§è¡Œå¤æ‚æŸ¥è¯¢\n",
    "#     neo4j_query_examples(driver, 'complex_query', {\n",
    "#         'min_age': 20,\n",
    "#         'location': 'beijing'\n",
    "#     })    \n",
    "    \n",
    "# finally:\n",
    "#     # å…³é—­é©±åŠ¨\n",
    "#     driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;è‡³æ­¤ï¼Œæˆ‘ä»¬å·²ç»å®Œæˆäº†`Neo4j`çš„è¿æ¥ï¼Œå¹¶æŒæ¡äº†åŸºç¡€çš„`Cypher`è¯­å¥ï¼Œæ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬å°†ä»‹ç»å¦‚ä½•å°†`Microsoft GraphRAG`ç”Ÿæˆçš„å„ä¸ª`.parquet`æ–‡ä»¶å¯¼å…¥åˆ°`Neo4j`çš„å›¾æ•°æ®åº“ä¸­ï¼Œæ„å»ºæ›´åŠ å¤æ‚å’Œä¸°å¯Œçš„çŸ¥è¯†å›¾è°±ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Microsoft GraphRAG å¯¼å…¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ç¬¬1æ¬¡å°è¯•ï¼šNeo4jè¿æ¥æˆåŠŸï¼\n",
      "ğŸ“Œ æœªå‘ç°ä»»ä½•çº¦æŸ\n",
      "ğŸ“Œ æœªå‘ç°ä»»ä½•ç‹¬ç«‹ç´¢å¼•\n",
      "\n",
      "ğŸ“Œ æ•°æ®åˆ é™¤ç»“æœï¼š\n",
      "   - å·²åˆ é™¤èŠ‚ç‚¹ï¼š0\n",
      "   - å·²åˆ é™¤å…³ç³»ï¼š0\n",
      "\n",
      "ğŸ‰ Neo4jæ•°æ®åº“å·²å®Œå…¨æ¸…ç©ºï¼\n"
     ]
    }
   ],
   "source": [
    "from neo4j import GraphDatabase, exceptions\n",
    "import time\n",
    "\n",
    "# ========== æ›¿æ¢ä¸ºä½ çš„çœŸå®é…ç½®ï¼ˆå…³é—­è®¤è¯åæ— éœ€å¯†ç ï¼‰ ==========\n",
    "# æ ¸å¿ƒä¿®å¤ï¼šBoltç«¯å£é»˜è®¤æ˜¯7687ï¼Œè€Œé7474ï¼ˆ7474æ˜¯HTTPç«¯å£ï¼‰\n",
    "NEO4J_URI = \"bolt://localhost:7687\"\n",
    "NEO4J_USER = \"neo4j\"  # å…³é—­è®¤è¯æ—¶å¯ç•™ç©ºï¼Œå¼€å¯åå¡«neo4j\n",
    "NEO4J_PASSWORD = \"Han9510!\"  # å…³é—­è®¤è¯æ—¶å¡«ç©ºï¼Œå¼€å¯åå¡«é‡ç½®çš„å¯†ç \n",
    "RETRY_TIMES = 3\n",
    "RETRY_DELAY = 5\n",
    "# ======================================\n",
    "\n",
    "def connect_neo4j():\n",
    "    \"\"\"åˆ›å»ºNeo4jé©±åŠ¨å¹¶éªŒè¯è¿æ¥ï¼ˆå¸¦é‡è¯•ï¼‰\"\"\"\n",
    "    driver = None\n",
    "    for i in range(RETRY_TIMES):\n",
    "        try:\n",
    "            # å…³é—­è®¤è¯æ—¶ï¼Œä¸ä¼ å…¥authå‚æ•°ï¼›å¼€å¯è®¤è¯æ—¶ä¼ å…¥(USER, PASSWORD)\n",
    "            if NEO4J_PASSWORD.strip() == \"\":\n",
    "                driver = GraphDatabase.driver(NEO4J_URI, connection_timeout=30)\n",
    "            else:\n",
    "                driver = GraphDatabase.driver(\n",
    "                    NEO4J_URI,\n",
    "                    auth=(NEO4J_USER, NEO4J_PASSWORD),\n",
    "                    connection_timeout=30\n",
    "                )\n",
    "            # éªŒè¯è¿æ¥\n",
    "            driver.verify_connectivity()\n",
    "            print(f\"âœ… ç¬¬{i+1}æ¬¡å°è¯•ï¼šNeo4jè¿æ¥æˆåŠŸï¼\")\n",
    "            return driver\n",
    "        # ä¿®å¤ï¼šç§»é™¤ä¸å­˜åœ¨çš„AuthenticationRateLimitï¼Œæ›¿æ¢ä¸ºé€šç”¨çš„è®¤è¯å¼‚å¸¸\n",
    "        except exceptions.AuthError:\n",
    "            print(f\"âŒ ç¬¬{i+1}æ¬¡å°è¯•ï¼šç”¨æˆ·å/å¯†ç é”™è¯¯ï¼\")\n",
    "            break  # è®¤è¯é”™è¯¯æ— éœ€é‡è¯•ï¼Œç›´æ¥é€€å‡º\n",
    "        except exceptions.ServiceUnavailable as e:\n",
    "            print(f\"âŒ ç¬¬{i+1}æ¬¡å°è¯•ï¼šNeo4jæœåŠ¡æœªå¯åŠ¨æˆ–ç«¯å£é”™è¯¯ï¼é”™è¯¯ä¿¡æ¯ï¼š{str(e)}\")\n",
    "            # æœåŠ¡ä¸å¯ç”¨å¯é‡è¯•ï¼ˆæ¯”å¦‚ç«¯å£ä¸´æ—¶å ç”¨ï¼‰\n",
    "            if i < RETRY_TIMES - 1:\n",
    "                time.sleep(RETRY_DELAY)\n",
    "            else:\n",
    "                break  # æœ€åä¸€æ¬¡é‡è¯•å¤±è´¥ï¼Œé€€å‡º\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ ç¬¬{i+1}æ¬¡å°è¯•ï¼šè¿æ¥å¤±è´¥ï¼š{str(e)}\")\n",
    "            time.sleep(RETRY_DELAY)\n",
    "    return None\n",
    "\n",
    "def clear_neo4j_database():\n",
    "    # 1. å»ºç«‹è¿æ¥\n",
    "    driver = connect_neo4j()\n",
    "    if not driver:\n",
    "        print(\"âŒ Neo4jè¿æ¥å¤±è´¥ï¼Œç»ˆæ­¢æ¸…ç©ºæ“ä½œï¼\")\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        with driver.session() as session:\n",
    "            # æ­¥éª¤1ï¼šåˆ é™¤æ‰€æœ‰çº¦æŸ\n",
    "            constraints = session.run(\"\"\"\n",
    "                SHOW CONSTRAINTS YIELD name, type, entityType, labelsOrTypes, properties\n",
    "                WHERE name IS NOT NULL  // ä»…ä¿ç•™æœ‰åç§°çš„çº¦æŸ\n",
    "            \"\"\").data()\n",
    "\n",
    "            if constraints:\n",
    "                print(f\"ğŸ“Œ å‘ç°{len(constraints)}ä¸ªçº¦æŸï¼Œå¼€å§‹åˆ é™¤...\")\n",
    "                cons_count = 0\n",
    "                for cons in constraints:\n",
    "                    cons_name = cons['name']\n",
    "                    try:\n",
    "                        # ä¿®å¤ï¼šçº¦æŸåç§°å¯èƒ½åŒ…å«ç‰¹æ®Šå­—ç¬¦ï¼Œä½¿ç”¨å‚æ•°åŒ–æ›´å®‰å…¨ï¼ˆå¯é€‰ï¼‰\n",
    "                        session.run(f\"DROP CONSTRAINT {cons_name}\")\n",
    "                        print(f\"âœ… å·²åˆ é™¤çº¦æŸï¼š{cons_name}\")\n",
    "                        cons_count += 1\n",
    "                    except Exception as e:\n",
    "                        print(f\"âš ï¸ åˆ é™¤çº¦æŸ{cons_name}å¤±è´¥ï¼š{str(e)}\")\n",
    "                print(f\"ğŸ“Œ çº¦æŸåˆ é™¤å®Œæˆï¼šæˆåŠŸ{cons_count}ä¸ªï¼Œå¤±è´¥{len(constraints)-cons_count}ä¸ª\")\n",
    "            else:\n",
    "                print(\"ğŸ“Œ æœªå‘ç°ä»»ä½•çº¦æŸ\")\n",
    "\n",
    "            # æ­¥éª¤2ï¼šåˆ é™¤æ‰€æœ‰ç‹¬ç«‹ç´¢å¼•ï¼ˆæ’é™¤çº¦æŸå…³è”çš„ç´¢å¼•ï¼‰\n",
    "            indexes = session.run(\"\"\"\n",
    "                SHOW INDEXES YIELD name, type\n",
    "                WHERE name IS NOT NULL AND type <> 'CONSTRAINT'  // æ’é™¤çº¦æŸå…³è”çš„ç´¢å¼•\n",
    "            \"\"\").data()\n",
    "\n",
    "            if indexes:\n",
    "                print(f\"\\nğŸ“Œ å‘ç°{len(indexes)}ä¸ªç´¢å¼•ï¼Œå¼€å§‹åˆ é™¤...\")\n",
    "                idx_count = 0\n",
    "                for idx in indexes:\n",
    "                    idx_name = idx['name']\n",
    "                    try:\n",
    "                        session.run(f\"DROP INDEX {idx_name}\")\n",
    "                        print(f\"âœ… å·²åˆ é™¤ç´¢å¼•ï¼š{idx_name}\")\n",
    "                        idx_count += 1\n",
    "                    except Exception as e:\n",
    "                        print(f\"âš ï¸ åˆ é™¤ç´¢å¼•{idx_name}å¤±è´¥ï¼š{str(e)}\")\n",
    "                print(f\"ğŸ“Œ ç´¢å¼•åˆ é™¤å®Œæˆï¼šæˆåŠŸ{idx_count}ä¸ªï¼Œå¤±è´¥{len(indexes)-idx_count}ä¸ª\")\n",
    "            else:\n",
    "                print(\"ğŸ“Œ æœªå‘ç°ä»»ä½•ç‹¬ç«‹ç´¢å¼•\")\n",
    "\n",
    "            # æ­¥éª¤3ï¼šåˆ é™¤æ‰€æœ‰èŠ‚ç‚¹å’Œå…³ç³»\n",
    "            result = session.run(\"MATCH (n) DETACH DELETE n\")\n",
    "            counters = result.consume().counters\n",
    "            print(f\"\\nğŸ“Œ æ•°æ®åˆ é™¤ç»“æœï¼š\")\n",
    "            print(f\"   - å·²åˆ é™¤èŠ‚ç‚¹ï¼š{counters.nodes_deleted}\")\n",
    "            print(f\"   - å·²åˆ é™¤å…³ç³»ï¼š{counters.relationships_deleted}\")\n",
    "            print(\"\\nğŸ‰ Neo4jæ•°æ®åº“å·²å®Œå…¨æ¸…ç©ºï¼\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"\\nâŒ æ¸…ç©ºæ•°æ®åº“å¤±è´¥ï¼š{str(e)}\")\n",
    "    finally:\n",
    "        if driver:\n",
    "            driver.close()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    clear_neo4j_database()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;åœ¨ä¸ŠèŠ‚è¯¾ä¸­ï¼Œæˆ‘ä»¬è¯¦ç»†çš„ä»‹ç»äº†`Microsoft GraphRAG`æä¾›çš„ä¸¤ç§æ–¹æ³•å°†æœ¬åœ°çš„éç»“æ„åŒ–æ•°æ®æ„å»ºçŸ¥è¯†å›¾è°±ç´¢å¼•çš„å®Œæ•´æµç¨‹åŠåº•å±‚çš„å®ç°åŸç†ï¼Œè€Œæ— è®ºæ˜¯é€šè¿‡`Microsoft GraphRAG`çš„`CLI`å·¥å…·ï¼Œè¿˜æ˜¯é€šè¿‡æºç çš„`Poetry`, å…¶ç”Ÿæˆçš„æ–‡ä»¶éƒ½æ˜¯ä¸€æ ·çš„ï¼Œå³åœ¨`output`ç›®å½•ä¸‹ä¼šä¾æ¬¡ç”Ÿæˆï¼š\n",
    "\n",
    "- documents.parquet\n",
    "- text_units.parquet\n",
    "- entities.parquet\n",
    "- relationships.parquet\n",
    "- communities.parquet\n",
    "- community_reports.parquet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;è¿™äº›æ–‡ä»¶ä¸­å­˜å‚¨äº†æ„å»ºçŸ¥è¯†å›¾è°±ç´¢å¼•çš„å…¨éƒ¨æ•°æ®ï¼Œè€Œæœ¬èŠ‚è¯¾æˆ‘ä»¬å°†ä»‹ç»å¦‚ä½•å°†è¿™äº›æ•°æ®å¯¼å…¥åˆ°`Neo4j`çš„å›¾æ•°æ®åº“ä¸­ï¼Œå¹¶è¿›è¡Œå¯è§†åŒ–ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 æ„å»ºæ‰¹é‡å¯¼å…¥å‡½æ•°"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;åœ¨å¼€å§‹é€æ­¥æ„å»ºçŸ¥è¯†å›¾è°±ä¹‹å‰ï¼Œæˆ‘ä»¬éœ€è¦å…ˆæ„å»ºä¸€ä¸ªæ‰¹é‡çš„é€šç”¨å¯¼å…¥å‡½æ•°ï¼Œç”¨äºå°†å„ä¸ª`.parquet`æ–‡ä»¶ä¸­çš„æ•°æ®æ›´é«˜æ•ˆçš„å¯¼å…¥åˆ°`Neo4j`çš„å›¾æ•°æ®åº“ä¸­ã€‚ çŸ¥è¯†å›¾è°±å­˜å‚¨çš„å¾€å¾€æ˜¯éå¸¸å¤§çš„æ•°æ®é‡ï¼ˆæ•°ç™¾ä¸‡åˆ°æ•°äº¿è¡Œçš„é‡çº§ï¼‰ï¼Œæœ‰éå¸¸å¤šçš„å¤æ‚å…³ç³»ï¼Œå› æ­¤åœ¨å®é™…çš„ä½¿ç”¨ä¸­ï¼Œå¾€å¾€éƒ½æ˜¯éœ€è¦ä¸€äº›ä¼˜åŒ–ç­–ç•¥æ¥åšå¤§è§„æ¨¡æ•°æ®çš„ç®¡ç†ï¼Œå¸¸è§çš„ä¼˜åŒ–æ–¹æ¡ˆæ˜¯ï¼š\n",
    "\n",
    "1. ä½¿ç”¨ `Neo4j Admin Import` å¯¼å…¥ï¼Œè¿™æ˜¯æœ€å¿«çš„å¯¼å…¥æ–¹å¼ï¼Œå¯ä»¥æ¯”`Cypher`å¯¼å…¥å¿«`10-100`å€ã€‚\n",
    "2. å¹¶è¡Œå¤„ç†ä¸å¤šçº¿ç¨‹ã€‚\n",
    "3. ä½¿ç”¨`APOC`æ‰¹é‡å¯¼å…¥ã€‚\n",
    "4. æ­é…å…¶ä»–ä¼˜åŒ–ç­–ç•¥ï¼Œæ¯”å¦‚ä¼˜åŒ–`Cypher`è¯­å¥ã€ä¼˜åŒ–æ•°æ®æ ¼å¼ã€æ•°æ®åˆ†åŒºä¸åˆ†å¸ƒå¼å¤„ç†ç­‰ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;åœ¨æœ¬æœŸçš„`GraphRAG`ç³»åˆ—è¯¾ç¨‹ä¸­ï¼Œæˆ‘ä»¬ä¼šç»“åˆä¸åŒçš„åœºæ™¯ä¾æ¬¡ä»‹ç»ä»¥ä¸Šå››ç§å¤§è§„æ¨¡æ•°æ®å¯¼å…¥çš„ä¼˜åŒ–ç­–ç•¥ã€‚æœ¬èŠ‚è¯¾ï¼Œæˆ‘ä»¬é¦–å…ˆä»‹ç»å¦‚ä½•åšå¹¶è¡Œå¤„ç†ä¸å¤šçº¿ç¨‹ã€‚\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;åœ¨å¦‚ä¸‹çš„`parallel_batched_import`å‡½æ•°ä¸­ï¼Œå®ç°çš„æ˜¯ä¸€ä¸ªä½¿ç”¨å¹¶è¡Œæ‰¹é‡å¯¼å…¥æ•°æ®åˆ°`Neo4j`çš„å‡½æ•°ã€‚å®ƒå°†å¤§æ‰¹é‡æ•°æ®åˆ†æˆå¤šä¸ªæ‰¹æ¬¡ï¼Œç„¶åä½¿ç”¨çº¿ç¨‹æ± å¹¶è¡Œå¤„ç†æ¯ä¸ªæ‰¹æ¬¡ï¼Œä»è€Œæé«˜å¯¼å…¥çš„æ•ˆæœã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "import concurrent.futures\n",
    "from neo4j import GraphDatabase\n",
    "\n",
    "\n",
    "def parallel_batched_import(statement, df, batch_size=100, max_workers=8):\n",
    "    \"\"\"\n",
    "    ä½¿ç”¨å¹¶è¡Œå¤„ç†è¿›è¡Œæ‰¹é‡å¯¼å…¥æ•°æ®åˆ°Neo4j\n",
    "    \n",
    "    å‚æ•°:\n",
    "    - statement: CypheræŸ¥è¯¢è¯­å¥ï¼Œä½¿ç”¨valueä½œä¸ºæ¯è¡Œæ•°æ®çš„å¼•ç”¨\n",
    "    - df: è¦å¯¼å…¥çš„DataFrame\n",
    "    - batch_size: æ¯æ‰¹å¤„ç†çš„è¡Œæ•°\n",
    "    - max_workers: å¹¶è¡Œçº¿ç¨‹æ•°\n",
    "    \n",
    "    è¿”å›:\n",
    "    - å¯¼å…¥ç»Ÿè®¡ä¿¡æ¯çš„å­—å…¸\n",
    "    \"\"\"\n",
    "\n",
    "    # 1. åˆå§‹åŒ–ï¼Œè®¡ç®—æ€»è¡Œæ•°ï¼Œæ‰¹æ¬¡æ•°ï¼Œå¹¶è®°å½•å¼€å§‹æ—¶é—´\n",
    "    total = len(df)\n",
    "    batches = (total + batch_size - 1) // batch_size  # å‘ä¸Šå–æ•´\n",
    "    start_time = time.time()\n",
    "    results = []\n",
    "    \n",
    "    print(f\"å¼€å§‹å¹¶è¡Œå¯¼å…¥ {total} è¡Œæ•°æ®ï¼Œåˆ†ä¸º {batches} ä¸ªæ‰¹æ¬¡ï¼Œæ¯æ‰¹ {batch_size} æ¡\")\n",
    "    \n",
    "\n",
    "    # 2. å®šä¹‰æ‰¹å¤„ç†å‡½æ•°\n",
    "    def process_batch(batch_idx):\n",
    "        \"\"\"\n",
    "        æ‰¹å¤„ç†å‡½æ•°ï¼Œç”¨äºå¤„ç†æ¯ä¸ªæ‰¹æ¬¡çš„æ•°æ®\n",
    "        \"\"\"\n",
    "\n",
    "        # 1. è®¡ç®—æ‰¹æ¬¡çš„èµ·å§‹å’Œç»“æŸç´¢å¼•\n",
    "        start = batch_idx * batch_size\n",
    "        end = min(start + batch_size, total)\n",
    "        batch = df.iloc[start:end]\n",
    "        \n",
    "        batch_start_time = time.time()\n",
    "        \n",
    "        try:\n",
    "            with driver.session(database=NEO4J_DATABASE) as session:\n",
    "                # NWIND æ˜¯ Cypher æŸ¥è¯¢è¯­è¨€ä¸­çš„ä¸€ä¸ªå…³é”®å­—ï¼Œç”¨äºå°†ä¸€ä¸ªåˆ—è¡¨å±•å¼€ä¸ºå¤šè¡Œã€‚ $rows æ˜¯ä¸€ä¸ªå‚æ•°ï¼Œè¡¨ç¤ºå°†è¦ä¼ å…¥çš„è¡Œæ•°æ®\n",
    "                # å®Œæ•´æ„æ€æ˜¯ï¼šå°†$rowså‚æ•°ï¼ˆä¸€ä¸ªåˆ—è¡¨ï¼‰ä¸­çš„æ¯ä¸ªå…ƒç´ å±•å¼€ï¼Œæ¯ä¸ªå…ƒç´ è¢«èµ‹å€¼ç»™å˜é‡valueï¼Œ å¯¹æ¯ä¸ªvalueæ‰§è¡Œåç»­çš„Cypherè¯­å¥\n",
    "                #    id   name   age\n",
    "                #    0    å¼ ä¸‰    25\n",
    "                #    1    æå››    30\n",
    "\n",
    "                # è°ƒç”¨.to_dict(\"records\")åï¼Œå¾—åˆ°ï¼š\n",
    "                # [\n",
    "                #     {\"id\": 1, \"name\": \"å¼ ä¸‰\", \"age\": 25},\n",
    "                #     {\"id\": 2, \"name\": \"æå››\", \"age\": 30}\n",
    "                # ]\n",
    "                result = session.run(\n",
    "                    \"UNWIND $rows AS value \" + statement,   \n",
    "                    rows=batch.to_dict(\"records\")\n",
    "                )\n",
    "                summary = result.consume()    # Neo4j ä¸­ç”¨äºå¤„ç†æŸ¥è¯¢ç»“æœçš„ä¸€ä¸ªæ–¹æ³•ã€‚å®ƒçš„ä¸»è¦ä½œç”¨æ˜¯è·å–æŸ¥è¯¢çš„æ‘˜è¦ä¿¡æ¯ï¼ŒåŒ…æ‹¬æ‰§è¡Œç»Ÿè®¡ã€è®¡æ•°å’Œå…¶ä»–ç›¸å…³ä¿¡æ¯\n",
    "                batch_duration = time.time() - batch_start_time\n",
    "                \n",
    "                return {\n",
    "                    \"batch\": batch_idx,\n",
    "                    \"rows\": end - start,\n",
    "                    \"success\": True,\n",
    "                    \"duration\": batch_duration,\n",
    "                    \"counters\": summary.counters   # summary.counters æ˜¯åœ¨æ‰§è¡Œ Cypher æŸ¥è¯¢åè¿”å›çš„ç»Ÿè®¡ä¿¡æ¯\n",
    "                }\n",
    "        except Exception as e:\n",
    "            batch_duration = time.time() - batch_start_time\n",
    "            print(f\"æ‰¹æ¬¡ {batch_idx} (è¡Œ {start}-{end-1}) å¤„ç†å¤±è´¥: {str(e)}\")\n",
    "            \n",
    "            return {\n",
    "                \"batch\": batch_idx,\n",
    "                \"rows\": end - start,\n",
    "                \"success\": False,\n",
    "                \"duration\": batch_duration,\n",
    "                \"error\": str(e)\n",
    "            }\n",
    "    \n",
    "    # ä½¿ç”¨çº¿ç¨‹æ± å¹¶è¡Œå¤„ç†æ‰¹æ¬¡\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        futures = [executor.submit(process_batch, i) for i in range(batches)]\n",
    "        \n",
    "        # å¤„ç†å®Œæˆçš„æ‰¹æ¬¡\n",
    "        for i, future in enumerate(concurrent.futures.as_completed(futures)):\n",
    "            result = future.result()\n",
    "            results.append(result)\n",
    "            \n",
    "            if result[\"success\"]:\n",
    "                print(f\"æ‰¹æ¬¡ {result['batch']} å®Œæˆ: {result['rows']} è¡Œ, è€—æ—¶ {result['duration']:.2f}ç§’\")\n",
    "            else:\n",
    "                print(f\"æ‰¹æ¬¡ {result['batch']} å¤±è´¥: {result['rows']} è¡Œ, è€—æ—¶ {result['duration']:.2f}ç§’, é”™è¯¯: {result.get('error', 'æœªçŸ¥é”™è¯¯')}\")\n",
    "            \n",
    "            # æ˜¾ç¤ºè¿›åº¦\n",
    "            print(f\"è¿›åº¦: {i+1}/{batches} æ‰¹æ¬¡å®Œæˆ ({((i+1)/batches*100):.1f}%)\")\n",
    "    \n",
    "    # ç»Ÿè®¡ç»“æœ\n",
    "    successful_rows = sum(r[\"rows\"] for r in results if r[\"success\"])\n",
    "    failed_rows = sum(r[\"rows\"] for r in results if not r[\"success\"])\n",
    "    \n",
    "    duration = time.time() - start_time\n",
    "    rows_per_second = successful_rows / duration if duration > 0 else 0\n",
    "    \n",
    "    print(f\"å¯¼å…¥å®Œæˆ: æ€»è®¡ {total} è¡Œ, æˆåŠŸ {successful_rows} è¡Œ, å¤±è´¥ {failed_rows} è¡Œ\")\n",
    "    print(f\"æ€»è€—æ—¶: {duration:.2f}ç§’, å¹³å‡é€Ÿåº¦: {rows_per_second:.2f} è¡Œ/ç§’\")\n",
    "    \n",
    "    return {\n",
    "        \"total_rows\": total,\n",
    "        \"successful_rows\": successful_rows,\n",
    "        \"failed_rows\": failed_rows,\n",
    "        \"duration_seconds\": duration,\n",
    "        \"rows_per_second\": rows_per_second,\n",
    "        \"batch_results\": results\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;ç†è§£äº†`parallel_batched_import`å‡½æ•°åï¼Œæˆ‘ä»¬å°±ä¾æ¬¡å°†å®Œæˆ`Microsoft GraphRAG`ç´¢å¼•è¿‡ç¨‹å¾—åˆ°çš„å„ä¸ª`.parquet`æ–‡ä»¶å¯¼å…¥åˆ°`Neo4j`çš„å›¾æ•°æ®åº“ä¸­ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 å¯¼å…¥æ–‡æ¡£"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;`documents.parquet`æ–‡ä»¶ä¸­ä¸»è¦å­˜å‚¨çš„æ˜¯åœ¨æ‰§è¡Œç´¢å¼•ä¹‹å‰ï¼Œæˆ‘ä»¬å­˜æ”¾åœ¨`Input`æ–‡ä»¶å¤¹ä¸‹çš„åŸå§‹çš„éç»“æ„åŒ–æ–‡æ¡£ï¼Œæ¯”å¦‚`.txt`ã€`csv`ç­‰å¤§æ‰¹é‡æ–‡ä»¶ã€‚ç»è¿‡ç´¢å¼•çš„æ„å»ºæµç¨‹åï¼Œä¼šç»è¿‡æ–‡æ¡£åŠ è½½å™¨è§£æå‡ºæ–‡æ¡£ä¸­çš„å…¨éƒ¨å†…å®¹ï¼Œå¹¶ä¸”ä¼šé€šè¿‡åå¤„ç†ï¼Œåœ¨è¿›è¡Œ`text_unit`çš„åˆ‡åˆ†åï¼Œå¡«å……æ¯ä¸ªæ–‡æ¡£å¯¹åº”çš„`text_unit_ids`ã€‚ è¯»å–è¯¥æ–‡ä»¶çš„ä»£ç å¦‚ä¸‹æ‰€ç¤ºï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… æ‰¾åˆ°æ–‡ä»¶: ../data/output/documents.parquet\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tabulate import tabulate\n",
    "import os\n",
    "\n",
    "def find_and_read_parquet(filename='documents.parquet'):\n",
    "    possible_paths = [\n",
    "        f'data/output/{filename}',\n",
    "        f'../data/output/{filename}',\n",
    "        f'../../data/output/{filename}',\n",
    "    ]\n",
    "    \n",
    "    for path in possible_paths:\n",
    "        if os.path.exists(path):\n",
    "            print(f\"âœ… æ‰¾åˆ°æ–‡ä»¶: {path}\")\n",
    "            return pd.read_parquet(path)\n",
    "    \n",
    "    raise FileNotFoundError(f\"æ‰¾ä¸åˆ° {filename}\")\n",
    "\n",
    "df_documents = find_and_read_parquet('documents.parquet')\n",
    "print(tabulate(df_documents.head(), headers='keys', tablefmt='pretty', showindex=False, stralign='left', maxcolwidths=[20, 20, 20, 20, 20]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tabulate import tabulate\n",
    "\n",
    "df_documents = pd.read_parquet('../data/output/documents.parquet')  # æ›¿æ¢ä¸ºå®é™…è·¯å¾„\n",
    "\n",
    "print(tabulate(df_documents, headers='keys', tablefmt='pretty', showindex=False, stralign='left', maxcolwidths=[20, 20, 20, 20, 20]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;å…¶ä¸­å„ä¸ªå­—æ®µçš„å«ä¹‰å¦‚ä¸‹æ‰€ç¤ºï¼š"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<style>\n",
    ".center \n",
    "{\n",
    "  width: auto;\n",
    "  display: table;\n",
    "  margin-left: auto;\n",
    "  margin-right: auto;\n",
    "}\n",
    "</style>\n",
    "\n",
    "<p align=\"center\"><font face=\"é»‘ä½“\" size=4>Document DataFrame å­—æ®µè§£é‡Š</font></p>\n",
    "<div class=\"center\">\n",
    "\n",
    "| å­—æ®µå              | ç±»å‹               | è¯´æ˜                                                         |\n",
    "|---------------------|--------------------|--------------------------------------------------------------|\n",
    "| id                  | å­—ç¬¦ä¸²             | å”¯ä¸€æ ‡è¯†ç¬¦ï¼Œç”¨äºå”¯ä¸€æ ‡è¯†æ¯ä¸ªæ–‡æ¡£ï¼ˆå³å•ä¸ªæ–‡ä»¶ï¼‰ã€‚                           |\n",
    "| human_readable_id   | å­—ç¬¦ä¸²             | å¯è¯»çš„æ ‡è¯†ç¬¦ï¼Œé€šå¸¸ç”¨äºç”¨æˆ·ç•Œé¢æ˜¾ç¤ºï¼Œä¾¿äºç”¨æˆ·ç†è§£å’Œè¯†åˆ«ã€‚   |\n",
    "| title               | å­—ç¬¦ä¸²             | åŠ è½½çš„æ–‡æ¡£å…¶å¯¹åº”çš„æ–‡ä»¶åã€‚                     |\n",
    "| text                | å­—ç¬¦ä¸²             | é€šè¿‡æ–‡æ¡£è§£æå™¨è§£æåˆ°çš„æ–‡æ¡£å…¨éƒ¨å†…å®¹ã€‚                       |\n",
    "| text_unit_ids       | åˆ—è¡¨ï¼ˆå­—ç¬¦ä¸²ï¼‰     | å…³è”çš„æ–‡æœ¬å•å…ƒçš„å”¯ä¸€æ ‡è¯†ç¬¦åˆ—è¡¨ï¼Œæ–‡æœ¬å•å…ƒæ˜¯å°†æ–‡æ¡£åˆ‡åˆ†çš„å—ã€‚ |\n",
    "| creation_date       | æ—¥æœŸæ—¶é—´           | åˆ›å»ºçš„æ—¥æœŸå’Œæ—¶é—´ï¼Œä»¥ UTC æˆ–æœ¬åœ°æ—¶é—´æ ¼å¼è¡¨ç¤ºã€‚ |\n",
    "| metadata            | å­—å…¸ï¼ˆå¯é€‰ï¼‰       | é¢å¤–çš„å…ƒæ•°æ®ï¼ŒåŒ…å«ä¸æ–‡æ¡£ç›¸å…³çš„å…¶ä»–ä¿¡æ¯ï¼Œå¦‚ä½œè€…ã€æ¥æºã€æ ‡ç­¾ç­‰ã€‚æ­¤å­—æ®µå¯ä»¥ä¸ºç©ºã€‚ |\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;åœ¨çŸ¥è¯†å›¾è°±æ„å»ºè¿‡ç¨‹ä¸­ï¼ŒDocumentå®ä½“ä½œä¸ºåŸå§‹ä¿¡æ¯è½½ä½“ï¼Œå…¶å¯¼å…¥ç­–ç•¥å¯ä»¥è€ƒè™‘ä»¥ä¸‹åŸåˆ™ï¼š\n",
    "\n",
    "- **èŠ‚ç‚¹æ ‡è¯†**ï¼šéœ€è¦ä½¿ç”¨`id`å­—æ®µä½œä¸ºDocumentèŠ‚ç‚¹çš„å”¯ä¸€æ ‡è¯†ç¬¦ï¼Œç¡®ä¿å›¾è°±ä¸­çš„æ–‡æ¡£å®ä½“ä¸€è‡´æ€§ã€‚\n",
    "- **çº¦æŸç­–ç•¥**ï¼šå”¯ä¸€æ€§çº¦æŸï¼Œç¡®ä¿æ–‡æ¡£çš„idæ˜¯å”¯ä¸€çš„ã€‚\n",
    "- **å±æ€§é€‰æ‹©**ï¼šæ¯”å¦‚æ ‡é¢˜ï¼Œæ–‡æœ¬å†…å®¹ç­‰ï¼ˆæˆ‘ä»¬ä¸ŠèŠ‚è¯¾è®²è§£äº†å¦‚ä½•è‡ªå®šä¹‰å±æ€§ï¼ˆå³é€šè¿‡ file_partten å’Œ file_filter æ¥å®šä¹‰å‡ºæ›´å¤šçš„åˆ—ï¼‰ï¼‰ï¼Œä½†æ˜¯æ³¨æ„ï¼štext_unit_ids æœ‰å¿…è¦æ·»åŠ å±æ€§å—ï¼Ÿ å¯ä»¥åšï¼Œä½†æ˜¯å¾ˆä½æ•ˆï¼Œå› ä¸ºåé¢å¯ä»¥é€šè¿‡å…³ç³»æ¥è¿æ¥ï¼Œä»è€Œé™ä½æŸ¥è¯¢çš„å¤æ‚åº¦ã€‚ä¸¾ä¸ªä¾‹å­ï¼š\n",
    "    - ä¸€ä¸ªåŒ…å«1000ä¸ªæ–‡æ¡£ï¼Œæ¯ä¸ªæ–‡æ¡£å¹³å‡æœ‰50ä¸ªæ–‡æœ¬å•å…ƒçš„çŸ¥è¯†å›¾è°±ï¼š\n",
    "        - ä½¿ç”¨å…³ç³»ï¼šåˆ›å»º50,000ä¸ªCONTAINSå…³ç³»ï¼Œæ¯ä¸ªå…³ç³»æŒ‡å‘ä¸€ä¸ªTextUnitèŠ‚ç‚¹\n",
    "        - ä½¿ç”¨å±æ€§ï¼šæ¯ä¸ªDocumentèŠ‚ç‚¹åŒ…å«ä¸€ä¸ªå¹³å‡æœ‰50ä¸ªIDçš„åˆ—è¡¨ï¼Œéœ€è¦åœ¨æŸ¥è¯¢æ—¶è¿›è¡Œåˆ—è¡¨å¤„ç†\n",
    "- **æ ‡ç­¾ç­–ç•¥**ï¼šåŸºç¡€æ ‡ç­¾ï¼Œä¸ºæ‰€æœ‰æ–‡æ¡£æ·»åŠ `__Document__`æ ‡ç­¾ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;å› æ­¤ï¼ŒæŠŠä¸Šè¿°çš„ç­–ç•¥è½¬åŒ–æˆä»£ç ã€‚å°±å¦‚ä¸‹æ‰€ç¤ºï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# åˆ›å»ºDocumentèŠ‚ç‚¹\n",
    "def create_document_nodes(df_documents):\n",
    "    # é¦–å…ˆåˆ›å»ºå”¯ä¸€æ€§çº¦æŸ\n",
    "    with driver.session(database=NEO4J_DATABASE) as session:\n",
    "        try:\n",
    "            session.run(\"CREATE CONSTRAINT IF NOT EXISTS FOR (d:__Document__) REQUIRE d.id IS UNIQUE\")\n",
    "        except Exception as e:\n",
    "            print(f\"åˆ›å»ºçº¦æŸæ—¶å‡ºé”™ (å¯èƒ½å·²å­˜åœ¨): {e}\")\n",
    "    \n",
    "    # å¯¼å…¥æ–‡æ¡£\n",
    "    # MERGEä¸ON CREATE SETç»„åˆï¼Œæ˜¯ä¸€ç§æ¡ä»¶æ€§å±æ€§è®¾ç½®æ–¹å¼ï¼šç‰¹ç‚¹æ˜¯ï¼š\n",
    "    # 1. åªåœ¨èŠ‚ç‚¹é¦–æ¬¡åˆ›å»ºæ—¶è®¾ç½®å±æ€§\n",
    "    # 2. å¦‚æœèŠ‚ç‚¹å·²å­˜åœ¨ï¼Œä¸ä¼šä¿®æ”¹ç°æœ‰å±æ€§\n",
    "    # é€‚åˆåˆå§‹å¯¼å…¥åœºæ™¯ï¼Œé¿å…è¦†ç›–å·²æœ‰æ•°æ®\n",
    "    cypher_statement = \"\"\"\n",
    "    MERGE (d:__Document__ {id: value.id})\n",
    "    ON CREATE SET \n",
    "        d.human_readable_id = value.human_readable_id,\n",
    "        d.title = value.title,\n",
    "        d.text = value.text,\n",
    "        d.creation_date = value.creation_date,\n",
    "        d.import_timestamp = timestamp()\n",
    "    \"\"\"\n",
    "    \n",
    "    return parallel_batched_import(cypher_statement, df_documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;æ¥ä¸‹æ¥ï¼Œè¿æ¥åˆ°`Neo4j`æ•°æ®åº“ï¼Œå¹¶è°ƒç”¨`create_document_nodes`å‡½æ•°ï¼Œå¯¼å…¥æ–‡æ¡£ã€‚ä»£ç å¦‚ä¸‹ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NEO4J_URI=\"bolt://localhost\"\n",
    "NEO4J_USERNAME=\"neo4j\"\n",
    "NEO4J_PASSWORD=\"Han9510!\"\n",
    "NEO4J_DATABASE=\"neo4j\"\n",
    "\n",
    "driver = GraphDatabase.driver(\n",
    "    NEO4J_URI, \n",
    "    auth=(NEO4J_USERNAME, NEO4J_PASSWORD)\n",
    "    )\n",
    "\n",
    "# æ‰§è¡Œ document.parquet æ–‡ä»¶çš„å¯¼å…¥\n",
    "create_document_nodes(df_documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;çœ‹åˆ°åˆ›å»ºå®Œæˆåï¼Œåœ¨`localhost:7474`çš„`Neo4j`æµè§ˆå™¨ä¸­ï¼Œå¯ä»¥çœ‹åˆ°`__Document__`æ ‡ç­¾çš„èŠ‚ç‚¹å·²ç»åˆ›å»ºå®Œæˆã€‚å¦‚ä¸‹å›¾æ‰€ç¤ºï¼š"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://muyu20241105.oss-cn-beijing.aliyuncs.com/images/202503121817980.png\" width=80%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;è‡³æ­¤ï¼Œæˆ‘ä»¬å·²ç»å®Œæˆäº†`documents.parquet`æ–‡ä»¶çš„å¯¼å…¥ã€‚æ¥ä¸‹æ¥æ‰§è¡Œ`text_units.parquet`æ–‡ä»¶çš„å¯¼å…¥ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 å¯¼å…¥æ–‡æœ¬å•å…ƒ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;`text_units.parquet`æ–‡ä»¶ä¸­ä¸»è¦å­˜å‚¨çš„æ˜¯å†…å®¹æ˜¯æ ¹æ®`settings.yaml`æ–‡ä»¶ä¸­å®šä¹‰çš„åˆ‡åˆ†ç­–ç•¥ï¼Œå°†`documents.parquet`æ–‡ä»¶ä¸­çš„å†…å®¹åˆ‡åˆ†å‡ºæ¥çš„æ–‡æœ¬å•å…ƒã€‚åŒæ—¶ä¼šé€šè¿‡åå¤„ç†ï¼Œå…³è”åˆ°ç»è¿‡å®ä½“å’Œå…³ç³»æå–`Workflow`åçš„å®ä½“å’Œå…³ç³»ã€‚è¯»å–è¯¥æ–‡ä»¶çš„ä»£ç å¦‚ä¸‹æ‰€ç¤ºï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tabulate import tabulate\n",
    "\n",
    "df_text_units = pd.read_parquet('./data/output/text_units.parquet')  # æ›¿æ¢ä¸ºå®é™…è·¯å¾„\n",
    "# å‡è®¾ df æ˜¯ä½ çš„ DataFrame\n",
    "print(tabulate(df_text_units, headers='keys', tablefmt='pretty', showindex=False, stralign='left', maxcolwidths=[20, 20, 20, 20, 20]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<style>\n",
    ".center \n",
    "{\n",
    "  width: auto;\n",
    "  display: table;\n",
    "  margin-left: auto;\n",
    "  margin-right: auto;\n",
    "}\n",
    "</style>\n",
    "\n",
    "<p align=\"center\"><font face=\"é»‘ä½“\" size=4>text_units DataFrame å­—æ®µè§£é‡Š</font></p>\n",
    "<div class=\"center\">\n",
    "\n",
    "| å­—æ®µå              | ç±»å‹               | è¯´æ˜                                                         |\n",
    "|---------------------|--------------------|--------------------------------------------------------------|\n",
    "| id                  | å­—ç¬¦ä¸²             | å”¯ä¸€æ ‡è¯†ç¬¦ï¼Œç”¨äºå”¯ä¸€æ ‡è¯†æ¯ä¸ªæ–‡æ¡£å—ï¼ˆå³ä»å•ä¸ªæ–‡æ¡£ä¸­åˆ‡åˆ†å‡ºæ¥çš„å®Œæ•´å—ï¼‰ã€‚                          |\n",
    "| human_readable_id   | å­—ç¬¦ä¸²             | å¯è¯»çš„æ ‡è¯†ç¬¦ï¼Œé€šå¸¸ç”¨äºç”¨æˆ·ç•Œé¢æ˜¾ç¤ºï¼Œä¾¿äºç”¨æˆ·ç†è§£å’Œè¯†åˆ«ã€‚   |\n",
    "| text                | å­—ç¬¦ä¸²             | è¯¥æ–‡æœ¬å—ä¸­çš„å†…å®¹                       |\n",
    "| n_tokens            | æ•´æ•°               | æŒ‰ç…§åˆ‡åˆ†ç­–ç•¥åˆ‡åˆ†å‡ºæ¥çš„æœ€ç»ˆæ–‡æœ¬é•¿åº¦ã€‚                         |\n",
    "| document_ids        | åˆ—è¡¨ï¼ˆå­—ç¬¦ä¸²ï¼‰     | å…³è”çš„æ–‡æ¡£çš„å”¯ä¸€æ ‡è¯†ç¬¦åˆ—è¡¨ï¼Œç”¨äºå°†æ–‡æœ¬å—ä¸documentä¸­çš„æ–‡æ¡£idå…³è”ã€‚   |\n",
    "| entity_ids          | åˆ—è¡¨ï¼ˆå­—ç¬¦ä¸²ï¼‰     | å…³è”çš„å®ä½“çš„å”¯ä¸€æ ‡è¯†ç¬¦åˆ—è¡¨ï¼Œè¡¨ç¤ºè¯¥æ–‡æœ¬å—ä¸­éƒ½æå–å‡ºæ¥äº†å“ªäº›å®ä½“ã€‚       |\n",
    "| relationship_ids    | åˆ—è¡¨ï¼ˆå­—ç¬¦ä¸²ï¼‰     | å…³è”çš„å…³ç³»çš„å”¯ä¸€æ ‡è¯†ç¬¦åˆ—è¡¨ï¼Œè¡¨ç¤ºè¯¥æ–‡æœ¬å—ä¸­éƒ½æå–å‡ºæ¥äº†å“ªäº›å…³ç³»ã€‚       |\n",
    "| covariate_ids       | åˆ—è¡¨ï¼ˆå­—ç¬¦ä¸²ï¼‰     | å…³è”çš„åå˜é‡çš„å”¯ä¸€æ ‡è¯†ç¬¦åˆ—è¡¨ï¼Œç”¨äºç»Ÿè®¡åˆ†ææˆ–å»ºæ¨¡ã€‚   |\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;åœ¨çŸ¥è¯†å›¾è°±æ„å»ºè¿‡ç¨‹ä¸­ï¼ŒTextUnitå®ä½“ä½œä¸ºæ–‡æœ¬åˆ‡åˆ†åçš„äº§ç‰©ï¼Œå…¶å¯¼å…¥ç­–ç•¥å¯ä»¥è€ƒè™‘ä»¥ä¸‹åŸåˆ™ï¼š\n",
    "\n",
    "- **èŠ‚ç‚¹æ ‡è¯†**ï¼šéœ€è¦ä½¿ç”¨`id`å­—æ®µä½œä¸ºTextUnitèŠ‚ç‚¹çš„å”¯ä¸€æ ‡è¯†ç¬¦ï¼Œç¡®ä¿å›¾è°±ä¸­æ–‡æ¡£å—å®ä½“ä¸€è‡´æ€§ã€‚\n",
    "- **çº¦æŸç­–ç•¥**ï¼šå”¯ä¸€æ€§çº¦æŸï¼Œç¡®ä¿æ–‡æœ¬å—çš„idæ˜¯å”¯ä¸€çš„ã€‚\n",
    "- **å±æ€§é€‰æ‹©**ï¼šæ¯”å¦‚æ–‡æœ¬å†…å®¹ï¼Œæ–‡æœ¬é•¿åº¦ç­‰ï¼Œæ ¹æ®éœ€æ±‚é€‰æ‹©ã€‚\n",
    "- **å…³ç³»ç­–ç•¥**ï¼šåˆ›å»º`PART_OF`å…³ç³»ï¼Œå°†TextUnitèŠ‚ç‚¹ä¸DocumentèŠ‚ç‚¹å…³è”èµ·æ¥ï¼Œè¡¨ç¤ºè¯¥æ–‡æœ¬å—å±äºå“ªä¸ªæ–‡æ¡£ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;å› æ­¤ï¼ŒæŠŠä¸Šè¿°çš„ç­–ç•¥è½¬åŒ–æˆä»£ç ã€‚å°±å¦‚ä¸‹æ‰€ç¤ºï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_chunk_constraints():\n",
    "    \"\"\"åˆ›å»ºChunkæ ‡ç­¾çš„çº¦æŸ\"\"\"\n",
    "    with driver.session(database=NEO4J_DATABASE) as session:\n",
    "        try:\n",
    "            # åˆ›å»ºChunk.idå”¯ä¸€æ€§çº¦æŸ\n",
    "            session.run(\"CREATE CONSTRAINT IF NOT EXISTS FOR (c:__Chunk__) REQUIRE c.id IS UNIQUE\")\n",
    "            print(\"å·²åˆ›å»ºChunk.idå”¯ä¸€æ€§çº¦æŸ\")\n",
    "        except Exception as e:\n",
    "            print(f\"åˆ›å»º__Chunk__çº¦æŸæ—¶å‡ºé”™ (å¯èƒ½å·²å­˜åœ¨): {e}\")\n",
    "            # å°è¯•æ—§ç‰ˆæœ¬Neo4jçš„è¯­æ³•\n",
    "            try:\n",
    "                session.run(\"CREATE CONSTRAINT ON (c:__Chunk__) ASSERT c.id IS UNIQUE\")\n",
    "                print(\"å·²ä½¿ç”¨æ—§è¯­æ³•åˆ›å»º__Chunk__.idå”¯ä¸€æ€§çº¦æŸ\")\n",
    "            except Exception as e2:\n",
    "                print(f\"ä½¿ç”¨æ—§è¯­æ³•åˆ›å»ºçº¦æŸä¹Ÿå¤±è´¥: {e2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_chunks(df_chunks, batch_size=100, max_workers=8):\n",
    "    \"\"\"\n",
    "    å¯¼å…¥æ–‡æ¡£å—(Chunk)åˆ°Neo4j\n",
    "    \n",
    "    å‚æ•°:\n",
    "    - df_chunks: åŒ…å«æ–‡æ¡£å—æ•°æ®çš„DataFrame\n",
    "    - batch_size: æ¯æ‰¹å¤„ç†çš„è¡Œæ•°\n",
    "    - max_workers: å¹¶è¡Œçº¿ç¨‹æ•°\n",
    "    \n",
    "    è¿”å›:\n",
    "    - å¯¼å…¥ç»Ÿè®¡ä¿¡æ¯çš„å­—å…¸\n",
    "    \"\"\"\n",
    "    # 1. åˆ›å»ºChunkçš„çº¦æŸ\n",
    "    setup_chunk_constraints()\n",
    "    \n",
    "    # 2. åˆ›å»ºChunkèŠ‚ç‚¹\n",
    "    print(\"å¼€å§‹å¯¼å…¥ChunkèŠ‚ç‚¹...\")\n",
    "    chunk_statement = \"\"\"\n",
    "    MERGE (c:__Chunk__ {id: value.id})\n",
    "    SET c.text = value.text,\n",
    "        c.n_tokens = value.n_tokens,\n",
    "        c.human_readable_id = value.human_readable_id,\n",
    "        // è®¾ç½®æ˜¾ç¤ºåç§°ä¸ºhuman_readable_id\n",
    "        c.name = value.human_readable_id\n",
    "    \"\"\"\n",
    "    \n",
    "    chunk_result = parallel_batched_import(chunk_statement, df_chunks, batch_size, max_workers)\n",
    "    \n",
    "    # 3. å‡†å¤‡å…³ç³»æ•°æ® - æ­£ç¡®å¤„ç†åµŒå¥—çš„document_idså¹¶è¿‡æ»¤æ— æ•ˆæ•°æ®\n",
    "    print(\"å‡†å¤‡Chunk-Documentå…³ç³»æ•°æ®...\")\n",
    "    relations_data = []\n",
    "    \n",
    "    for idx, row in df_chunks.iterrows():\n",
    "        chunk_id = row['id']\n",
    "        doc_ids_container = row['document_ids']\n",
    "        \n",
    "        # å¤„ç†åµŒå¥—ç»“æ„\n",
    "        flat_doc_ids = []\n",
    "        \n",
    "        # å¦‚æœæ˜¯åˆ—è¡¨ï¼Œå±•å¹³å®ƒ\n",
    "        if isinstance(doc_ids_container, list):\n",
    "            for item in doc_ids_container:\n",
    "                # å¦‚æœæ˜¯NumPyæ•°ç»„\n",
    "                if hasattr(item, 'dtype') and hasattr(item, 'tolist'):\n",
    "                    flat_doc_ids.extend(item.tolist())\n",
    "                # å¦‚æœæ˜¯åˆ—è¡¨\n",
    "                elif isinstance(item, list):\n",
    "                    flat_doc_ids.extend(item)\n",
    "                # å¦‚æœæ˜¯å•ä¸ªå€¼\n",
    "                else:\n",
    "                    flat_doc_ids.append(item)\n",
    "        # å¦‚æœä¸æ˜¯åˆ—è¡¨ï¼Œç›´æ¥æ·»åŠ \n",
    "        elif doc_ids_container is not None:\n",
    "            flat_doc_ids.append(doc_ids_container)\n",
    "        \n",
    "        # è®°å½•å¤„ç†åçš„document_ids\n",
    "        if idx < 5:  # åªè®°å½•å‰å‡ è¡Œï¼Œé¿å…æ—¥å¿—è¿‡å¤§\n",
    "            print(f\"è¡Œ {idx} å¤„ç†åçš„document_ids: {flat_doc_ids}\")\n",
    "        \n",
    "        # ä¸ºæ¯ä¸ªæ–‡æ¡£IDåˆ›å»ºå…³ç³»ï¼Œè¿‡æ»¤æ‰æ— æ•ˆçš„ID\n",
    "        for doc_id in flat_doc_ids:\n",
    "            if doc_id is not None and str(doc_id).strip() != '':\n",
    "                # ç¡®ä¿doc_idæ˜¯å­—ç¬¦ä¸²å¹¶è¿‡æ»¤æ‰ç‰¹æ®Šæ ¼å¼\n",
    "                doc_id_str = str(doc_id).strip()\n",
    "                \n",
    "                # è¿‡æ»¤æ‰ä¸ç¬¦åˆé¢„æœŸæ ¼å¼çš„ID\n",
    "                if doc_id_str.startswith('<elementId>') or doc_id_str.startswith('<id>'):\n",
    "                    print(f\"è·³è¿‡æ— æ•ˆçš„document_id: {doc_id_str}\")\n",
    "                    continue\n",
    "                \n",
    "                # å¦‚æœæ˜¯åˆ—è¡¨å½¢å¼çš„å­—ç¬¦ä¸²ï¼Œæå–å®é™…ID\n",
    "                if doc_id_str.startswith('[') and doc_id_str.endswith(']'):\n",
    "                    try:\n",
    "                        # å°è¯•è§£æåˆ—è¡¨å­—ç¬¦ä¸²\n",
    "                        import ast\n",
    "                        id_list = ast.literal_eval(doc_id_str)\n",
    "                        if isinstance(id_list, list) and len(id_list) > 0:\n",
    "                            doc_id_str = str(id_list[0])\n",
    "                    except:\n",
    "                        print(f\"æ— æ³•è§£æåˆ—è¡¨æ ¼å¼çš„document_id: {doc_id_str}\")\n",
    "                        continue\n",
    "                \n",
    "                relations_data.append({\n",
    "                    'chunk_id': chunk_id,\n",
    "                    'document_id': doc_id_str\n",
    "                })\n",
    "    \n",
    "    # 4. ç¡®ä¿DocumentèŠ‚ç‚¹å­˜åœ¨\n",
    "    if relations_data:\n",
    "        unique_doc_ids = set(item['document_id'] for item in relations_data)\n",
    "        print(f\"å‘ç° {len(unique_doc_ids)} ä¸ªå”¯ä¸€çš„document_id\")\n",
    "        \n",
    "        # åˆ›å»ºDocumentèŠ‚ç‚¹\n",
    "        docs_df = pd.DataFrame({'id': list(unique_doc_ids)})\n",
    "        document_statement = \"\"\"\n",
    "        MERGE (d:__Document__ {id: value.id})\n",
    "        // è®¾ç½®æ˜¾ç¤ºåç§°\n",
    "        SET d.name = value.id\n",
    "        \"\"\"\n",
    "        doc_result = parallel_batched_import(document_statement, docs_df, batch_size, max_workers)\n",
    "        print(f\"å·²åˆ›å»º {doc_result['successful_rows']} ä¸ªDocumentèŠ‚ç‚¹\")\n",
    "        \n",
    "        # 5. åˆ›å»ºå…³ç³»\n",
    "        print(f\"å¼€å§‹åˆ›å»º {len(relations_data)} ä¸ªChunk-Documentå…³ç³»...\")\n",
    "        df_relations = pd.DataFrame(relations_data)\n",
    "        \n",
    "        relation_statement = \"\"\"\n",
    "        MATCH (c:__Chunk__ {id: value.chunk_id})\n",
    "        MATCH (d:__Document__ {id: value.document_id})\n",
    "        MERGE (c)-[:PART_OF]->(d)\n",
    "        \"\"\"\n",
    "        \n",
    "        relation_result = parallel_batched_import(relation_statement, df_relations, batch_size, max_workers)\n",
    "        print(f\"å·²åˆ›å»º {relation_result['successful_rows']} ä¸ªChunk-Documentå…³ç³»\")\n",
    "    else:\n",
    "        print(\"æ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆçš„Chunk-Documentå…³ç³»æ•°æ®\")\n",
    "    \n",
    "    # 6. éªŒè¯ç»“æœ\n",
    "    with driver.session(database=NEO4J_DATABASE) as session:\n",
    "        # æ£€æŸ¥ChunkèŠ‚ç‚¹æ•°é‡\n",
    "        result = session.run(\"MATCH (c:__Chunk__) RETURN count(c) as count\")\n",
    "        chunk_count = result.single()[\"count\"]\n",
    "        \n",
    "        # æ£€æŸ¥DocumentèŠ‚ç‚¹æ•°é‡\n",
    "        result = session.run(\"MATCH (d:__Document__) RETURN count(d) as count\")\n",
    "        doc_count = result.single()[\"count\"]\n",
    "        \n",
    "        # æ£€æŸ¥PART_OFå…³ç³»æ•°é‡\n",
    "        result = session.run(\"MATCH ()-[r:PART_OF]->() RETURN count(r) as count\")\n",
    "        relation_count = result.single()[\"count\"]\n",
    "        \n",
    "        print(f\"éªŒè¯ç»“æœ: {chunk_count} ä¸ªChunkèŠ‚ç‚¹, {doc_count} ä¸ªDocumentèŠ‚ç‚¹, {relation_count} ä¸ªPART_OFå…³ç³»\")\n",
    "    \n",
    "    return chunk_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;æ¥ä¸‹æ¥ï¼Œè¿æ¥åˆ°`Neo4j`æ•°æ®åº“ï¼Œå¹¶è°ƒç”¨`import_chunks`å‡½æ•°ï¼Œå¯¼å…¥æ–‡æœ¬å•å…ƒã€‚ä»£ç å¦‚ä¸‹ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NEO4J_URI=\"bolt://localhost\"\n",
    "NEO4J_USERNAME=\"neo4j\"\n",
    "NEO4J_PASSWORD=\"Han9510!\"\n",
    "NEO4J_DATABASE=\"neo4j\"\n",
    "\n",
    "driver = GraphDatabase.driver(\n",
    "    NEO4J_URI, \n",
    "    auth=(NEO4J_USERNAME, NEO4J_PASSWORD)\n",
    "    )\n",
    "\n",
    "# æ‰§è¡Œ text_units.parquet æ–‡ä»¶çš„å¯¼å…¥\n",
    "import_chunks(df_text_units)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;åŒæ ·ç¬¬ï¼Œæ‰§è¡Œå®Œæˆåå¯ä»¥åœ¨`localhost:7474`çš„`Neo4j`æµè§ˆå™¨ä¸­ï¼Œå¯ä»¥çœ‹åˆ°`__Chunk__`æ ‡ç­¾çš„èŠ‚ç‚¹å·²ç»åˆ›å»ºå®Œæˆï¼Œä»¥åŠ`__Chunk__`ä¸`__Document__`ä¹‹é—´çš„å…³ç³»ä¹Ÿå·²ç»åˆ›å»ºå®Œæˆã€‚å¦‚ä¸‹å›¾æ‰€ç¤ºï¼š"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://muyu20241105.oss-cn-beijing.aliyuncs.com/images/202503121844987.png\" width=80%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;è‡³æ­¤ï¼Œæˆ‘ä»¬å°±å®Œæˆäº†`text_units.parquet`æ–‡ä»¶çš„å¯¼å…¥ã€‚æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬å¼€å§‹å¯¼å…¥`entities.parquet`æ–‡ä»¶ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4 å¯¼å…¥å®ä½“"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;`entities.parquet`æ–‡ä»¶ä¸­ä¸»è¦å­˜å‚¨çš„é€šè¿‡æç¤ºè¯ï¼Œå€ŸåŠ©å¤§æ¨¡å‹ä»`text_units`ä¸­æå–å‡ºæ¥çš„å®ä½“ã€‚è¯»å–è¯¥æ–‡ä»¶çš„ä»£ç å¦‚ä¸‹æ‰€ç¤ºï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ä½¿ç”¨ç»å¯¹è·¯å¾„è¯»å– Parquet æ–‡ä»¶\n",
    "df_entities = pd.read_parquet('./data/output/entities.parquet')  # æ›¿æ¢ä¸ºå®é™…è·¯å¾„\n",
    "\n",
    "# å‡è®¾ df æ˜¯ä½ çš„ DataFrame\n",
    "print(tabulate(df_entities, headers='keys', tablefmt='pretty', showindex=False, stralign='left', maxcolwidths=[20, 20, 20, 20, 20]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;å„ä¸ªå­—æ®µçš„è§£é‡Šå¦‚ä¸‹æ‰€ç¤ºï¼š"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<style>\n",
    ".center \n",
    "{\n",
    "  width: auto;\n",
    "  display: table;\n",
    "  margin-left: auto;\n",
    "  margin-right: auto;\n",
    "}\n",
    "</style>\n",
    "\n",
    "<p align=\"center\"><font face=\"é»‘ä½“\" size=4>entities DataFrame å­—æ®µè§£é‡Š</font></p>\n",
    "<div class=\"center\">\n",
    "\n",
    "| å­—æ®µå              | ç±»å‹               | è¯´æ˜                                                         |\n",
    "|---------------------|--------------------|--------------------------------------------------------------|\n",
    "| id                  | å­—ç¬¦ä¸²             | å”¯ä¸€æ ‡è¯†ç¬¦ï¼Œç”¨äºå”¯ä¸€æ ‡è¯†æ¯ä¸ªå®ä½“è®°å½•ã€‚                           |\n",
    "| human_readable_id   | å­—ç¬¦ä¸²             | å¯è¯»çš„æ ‡è¯†ç¬¦ï¼Œç”¨äºç”¨æˆ·ç•Œé¢æ˜¾ç¤ºï¼Œä¾¿äºç”¨æˆ·ç†è§£å’Œè¯†åˆ«ã€‚   |\n",
    "| title               | å­—ç¬¦ä¸²             | å®ä½“çš„åç§°æˆ–ä¸»é¢˜ã€‚                   |\n",
    "| type                | å­—ç¬¦ä¸²             | å®ä½“çš„ç±»å‹ï¼Œä¾‹å¦‚ `GEO` è¡¨ç¤ºåœ°ç†ä½ç½®ã€‚                       |\n",
    "| description         | å­—ç¬¦ä¸²             | å¯¹å®ä½“çš„è¯¦ç»†æè¿°ï¼Œæä¾›æ›´å¤šä¸Šä¸‹æ–‡ä¿¡æ¯ã€‚                     |\n",
    "| text_unit_ids       | åˆ—è¡¨ï¼ˆå­—ç¬¦ä¸²ï¼‰     | å…³è”çš„æ–‡æœ¬å•å…ƒçš„å”¯ä¸€æ ‡è¯†ç¬¦åˆ—è¡¨ï¼Œç”¨äºå°†å®ä½“ä¸æ–‡æœ¬å—å…³è”ã€‚ |\n",
    "| frequency           | æ•´æ•°               | å®ä½“å‡ºç°çš„é¢‘ç‡ï¼Œè¡¨ç¤ºè¯¥å®ä½“åœ¨æ•°æ®ä¸­çš„é‡è¦æ€§æˆ–å¸¸è§ç¨‹åº¦ã€‚     |\n",
    "| degree              | æ•´æ•°               | å®ä½“çš„åº¦æ•°ï¼Œé€šå¸¸è¡¨ç¤ºä¸å…¶ä»–å®ä½“çš„è¿æ¥æ•°é‡ã€‚                 |\n",
    "| x                   | æµ®ç‚¹æ•°             | å®ä½“åœ¨äºŒç»´ç©ºé—´ä¸­çš„ x åæ ‡ï¼Œé€šå¸¸ç”¨äºå¯è§†åŒ–ã€‚                |\n",
    "| y                   | æµ®ç‚¹æ•°             | å®ä½“åœ¨äºŒç»´ç©ºé—´ä¸­çš„ y åæ ‡ï¼Œé€šå¸¸ç”¨äºå¯è§†åŒ–ã€‚                |\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;åœ¨çŸ¥è¯†å›¾è°±æ„å»ºè¿‡ç¨‹ä¸­ï¼Œå…¶å¯¼å…¥ç­–ç•¥å¯ä»¥è€ƒè™‘ä»¥ä¸‹åŸåˆ™ï¼š\n",
    "\n",
    "- **èŠ‚ç‚¹æ ‡è¯†**ï¼šéœ€è¦ä½¿ç”¨`id`å­—æ®µä½œä¸ºEntityèŠ‚ç‚¹çš„å”¯ä¸€æ ‡è¯†ç¬¦ï¼Œç¡®ä¿å›¾è°±ä¸­å®ä½“èŠ‚ç‚¹ä¸€è‡´æ€§ã€‚åŒæ—¶ä¸ºäº†é¿å…é‡å¤ï¼Œ`name`å­—æ®µä¹Ÿéœ€è¦ä½œä¸ºEntityèŠ‚ç‚¹çš„å”¯ä¸€æ ‡è¯†ç¬¦ã€‚\n",
    "- **çº¦æŸç­–ç•¥**ï¼šå”¯ä¸€æ€§çº¦æŸï¼Œç¡®ä¿å®ä½“çš„idæ˜¯å”¯ä¸€çš„ã€‚\n",
    "- **å±æ€§é€‰æ‹©**ï¼šæ¯”å¦‚å®ä½“çš„åç§°ï¼Œæè¿°ï¼Œé¢‘ç‡ï¼Œåº¦æ•°ç­‰ï¼Œæ ¹æ®éœ€æ±‚é€‰æ‹©ã€‚\n",
    "- **æ ‡ç­¾ç­–ç•¥**ï¼šç»™èŠ‚ç‚¹æ·»åŠ åŠ¨æ€æ ‡ç­¾ï¼ˆæ ¹æ® å®ä½“çš„ type æ·»åŠ ï¼‰\n",
    "- **å…³ç³»ç­–ç•¥**ï¼šåˆ›å»º`HAS_ENTITY`å…³ç³»ï¼Œå°†EntityèŠ‚ç‚¹ä¸ChunkèŠ‚ç‚¹å…³è”èµ·æ¥ï¼Œè¡¨ç¤ºè¯¥å®ä½“å±äºå“ªä¸ªæ–‡æœ¬å—ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;å› æ­¤ï¼ŒæŠŠä¸Šè¿°çš„ç­–ç•¥è½¬åŒ–æˆä»£ç ã€‚å°±å¦‚ä¸‹æ‰€ç¤ºï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_entity_constraints():\n",
    "    \"\"\"åˆ›å»ºEntityæ ‡ç­¾çš„çº¦æŸ\"\"\"\n",
    "    with driver.session(database=NEO4J_DATABASE) as session:\n",
    "        try:\n",
    "            # åˆ›å»ºEntity.idå”¯ä¸€æ€§çº¦æŸ\n",
    "            session.run(\"CREATE CONSTRAINT IF NOT EXISTS FOR (e:__Entity__) REQUIRE e.id IS UNIQUE\")\n",
    "            session.run(\"CREATE CONSTRAINT IF NOT EXISTS FOR (e:__Entity__) REQUIRE e.name IS UNIQUE\")\n",
    "            print(\"å·²åˆ›å»º__Entity__.idå”¯ä¸€æ€§çº¦æŸ\")\n",
    "        except Exception as e:\n",
    "            print(f\"åˆ›å»º__Entity__çº¦æŸæ—¶å‡ºé”™ (å¯èƒ½å·²å­˜åœ¨): {e}\")\n",
    "            # å°è¯•æ—§ç‰ˆæœ¬Neo4jçš„è¯­æ³•\n",
    "            try:\n",
    "                session.run(\"CREATE CONSTRAINT ON (e:__Entity__) ASSERT e.id IS UNIQUE\")\n",
    "                print(\"å·²ä½¿ç”¨æ—§è¯­æ³•åˆ›å»º__Entity__.idå”¯ä¸€æ€§çº¦æŸ\")\n",
    "            except Exception as e2:\n",
    "                print(f\"ä½¿ç”¨æ—§è¯­æ³•åˆ›å»ºçº¦æŸä¹Ÿå¤±è´¥: {e2}\")\n",
    "\n",
    "def import_entities(df_entities, batch_size=100, max_workers=8):\n",
    "    \"\"\"\n",
    "    å¯¼å…¥å®ä½“(Entity)åˆ°Neo4j\n",
    "    \n",
    "    å‚æ•°:\n",
    "    - df_entities: åŒ…å«å®ä½“æ•°æ®çš„DataFrame\n",
    "    - batch_size: æ¯æ‰¹å¤„ç†çš„è¡Œæ•°\n",
    "    - max_workers: å¹¶è¡Œçº¿ç¨‹æ•°\n",
    "    \n",
    "    è¿”å›:\n",
    "    - å¯¼å…¥ç»Ÿè®¡ä¿¡æ¯çš„å­—å…¸\n",
    "    \"\"\"\n",
    "    # 1. åˆ›å»ºEntityçš„çº¦æŸ\n",
    "    setup_entity_constraints()\n",
    "    \n",
    "    # 2. é¢„å¤„ç†text_unit_ids - ç¡®ä¿æ˜¯åˆ—è¡¨æ ¼å¼\n",
    "    print(\"é¢„å¤„ç†text_unit_ids...\")\n",
    "    \n",
    "    # åˆ›å»ºDataFrameçš„å‰¯æœ¬\n",
    "    df_entities = df_entities.copy()\n",
    "    \n",
    "    # å¤„ç†text_unit_idså­—æ®µ\n",
    "    for idx, row in df_entities.iterrows():\n",
    "        text_unit_ids = row.get('text_unit_ids')\n",
    "        \n",
    "        # å¦‚æœä¸æ˜¯åˆ—è¡¨ï¼Œè½¬æ¢ä¸ºåˆ—è¡¨\n",
    "        if not isinstance(text_unit_ids, list):\n",
    "            if isinstance(text_unit_ids, str):\n",
    "                try:\n",
    "                    # å°è¯•è§£æJSONå­—ç¬¦ä¸²\n",
    "                    import json\n",
    "                    text_unit_ids = json.loads(text_unit_ids)\n",
    "                except:\n",
    "                    # å¦‚æœè§£æå¤±è´¥ï¼Œå°†å…¶ä½œä¸ºå•ä¸ªå…ƒç´ çš„åˆ—è¡¨\n",
    "                    text_unit_ids = [text_unit_ids]\n",
    "            elif hasattr(text_unit_ids, 'dtype') and hasattr(text_unit_ids, 'tolist'):\n",
    "                # å¤„ç†NumPyæ•°ç»„\n",
    "                text_unit_ids = text_unit_ids.tolist()\n",
    "            else:\n",
    "                # å…¶ä»–ç±»å‹ï¼Œè½¬ä¸ºåˆ—è¡¨\n",
    "                text_unit_ids = [text_unit_ids] if text_unit_ids is not None else []\n",
    "        \n",
    "        # å¤„ç†åµŒå¥—åˆ—è¡¨\n",
    "        flat_text_unit_ids = []\n",
    "        for item in text_unit_ids:\n",
    "            if isinstance(item, list) or (hasattr(item, 'dtype') and hasattr(item, 'tolist')):\n",
    "                if hasattr(item, 'tolist'):\n",
    "                    flat_text_unit_ids.extend(item.tolist())\n",
    "                else:\n",
    "                    flat_text_unit_ids.extend(item)\n",
    "            else:\n",
    "                flat_text_unit_ids.append(item)\n",
    "        \n",
    "        # ç¡®ä¿æ‰€æœ‰IDéƒ½æ˜¯å­—ç¬¦ä¸²ä¸”éç©º\n",
    "        flat_text_unit_ids = [str(id) for id in flat_text_unit_ids if id is not None and str(id).strip() != '']\n",
    "        \n",
    "        # æ›´æ–°DataFrame\n",
    "        df_entities.at[idx, 'text_unit_ids'] = flat_text_unit_ids\n",
    "    \n",
    "    # 3. æ£€æŸ¥Neo4jåŠŸèƒ½æ”¯æŒ\n",
    "    print(\"æ£€æŸ¥Neo4jåŠŸèƒ½æ”¯æŒ...\")\n",
    "    has_apoc = False\n",
    "    has_vector = False\n",
    "    \n",
    "    try:\n",
    "        with driver.session(database=NEO4J_DATABASE) as session:\n",
    "            # æ£€æŸ¥APOC\n",
    "            try:\n",
    "                result = session.run(\"RETURN apoc.version() AS version\")\n",
    "                version = result.single()[\"version\"]\n",
    "                has_apoc = True\n",
    "                print(f\"APOCæ’ä»¶å·²å®‰è£…ï¼Œç‰ˆæœ¬: {version}\")\n",
    "            except Exception as e:\n",
    "                print(f\"æ£€æŸ¥APOCæ’ä»¶æ—¶å‡ºé”™ (å¯èƒ½æœªå®‰è£…): {e}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"æ£€æŸ¥Neo4jåŠŸèƒ½æ”¯æŒæ—¶å‡ºé”™: {e}\")\n",
    "    \n",
    "    # 4. å¯¼å…¥EntityèŠ‚ç‚¹å¹¶åˆ›å»ºå…³ç³»\n",
    "    print(\"å¼€å§‹å¯¼å…¥__Entity__èŠ‚ç‚¹å¹¶åˆ›å»ºå…³ç³»...\")\n",
    "    \n",
    "    # æ ¹æ®åŠŸèƒ½æ”¯æŒæ„å»ºCypherè¯­å¥\n",
    "    if has_apoc and has_vector:\n",
    "        # å®Œæ•´åŠŸèƒ½æ”¯æŒ\n",
    "        entity_statement = \"\"\"\n",
    "        MERGE (e:__Entity__ {id:value.id})\n",
    "        SET e += value {.human_readable_id, .description, .frequency, .degree, .x, .y}\n",
    "        SET e.name = replace(coalesce(value.title, value.human_readable_id, ''), '\"', '')\n",
    "        \n",
    "        WITH e, value\n",
    "        CALL db.create.setNodeVectorProperty(e, \"description_embedding\", value.description_embedding)\n",
    "        \n",
    "        WITH e, value\n",
    "        CALL apoc.create.addLabels(e, \n",
    "            CASE WHEN coalesce(value.type,\"\") = \"\" \n",
    "            THEN [] \n",
    "            ELSE [apoc.text.upperCamelCase(replace(value.type,'\"',''))] \n",
    "            END\n",
    "        ) YIELD node\n",
    "        \n",
    "        WITH node as e, value\n",
    "        UNWIND value.text_unit_ids AS text_unit\n",
    "        MATCH (c:__Chunk__ {id:text_unit})\n",
    "        MERGE (c)-[:HAS_ENTITY]->(e)\n",
    "        \"\"\"\n",
    "    elif has_apoc:\n",
    "        # åªæœ‰APOCæ”¯æŒï¼Œæ²¡æœ‰å‘é‡æ”¯æŒ\n",
    "        entity_statement = \"\"\"\n",
    "        MERGE (e:__Entity__ {id:value.id})\n",
    "        SET e += value {.human_readable_id, .description, .frequency, .degree, .x, .y}\n",
    "        SET e.name = replace(coalesce(value.title, value.human_readable_id, ''), '\"', '')\n",
    "        \n",
    "        WITH e, value\n",
    "        CALL apoc.create.addLabels(e, \n",
    "            CASE WHEN coalesce(value.type,\"\") = \"\" \n",
    "            THEN [] \n",
    "            ELSE [apoc.text.upperCamelCase(replace(value.type,'\"',''))] \n",
    "            END\n",
    "        ) YIELD node\n",
    "        \n",
    "        WITH node as e, value\n",
    "        UNWIND value.text_unit_ids AS text_unit\n",
    "        MATCH (c:__Chunk__ {id:text_unit})\n",
    "        MERGE (c)-[:HAS_ENTITY]->(e)\n",
    "        \"\"\"\n",
    "    elif has_vector:\n",
    "        # åªæœ‰å‘é‡æ”¯æŒï¼Œæ²¡æœ‰APOCæ”¯æŒ\n",
    "        entity_statement = \"\"\"\n",
    "        MERGE (e:__Entity__ {id:value.id})\n",
    "        SET e += value {.human_readable_id, .description, .frequency, .degree, .x, .y}\n",
    "        SET e.name = replace(coalesce(value.title, value.human_readable_id, ''), '\"', '')\n",
    "        \n",
    "        WITH e, value\n",
    "        CALL db.create.setNodeVectorProperty(e, \"description_embedding\", value.description_embedding)\n",
    "        \n",
    "        WITH e, value\n",
    "        UNWIND value.text_unit_ids AS text_unit\n",
    "        MATCH (c:__Chunk__ {id:text_unit})\n",
    "        MERGE (c)-[:HAS_ENTITY]->(e)\n",
    "        \"\"\"\n",
    "    else:\n",
    "        # åŸºæœ¬åŠŸèƒ½ï¼Œæ— APOCå’Œå‘é‡æ”¯æŒ\n",
    "        entity_statement = \"\"\"\n",
    "        MERGE (e:__Entity__ {id:value.id})\n",
    "        SET e += value {.human_readable_id, .description, .frequency, .degree, .x, .y}\n",
    "        SET e.name = replace(coalesce(value.title, value.human_readable_id, ''), '\"', '')\n",
    "        \n",
    "        WITH e, value\n",
    "        UNWIND value.text_unit_ids AS text_unit\n",
    "        MATCH (c:__Chunk__ {id:text_unit})\n",
    "        MERGE (c)-[:HAS_ENTITY]->(e)\n",
    "        \"\"\"\n",
    "    \n",
    "    # æ‰§è¡Œå¯¼å…¥\n",
    "    entity_result = parallel_batched_import(entity_statement, df_entities, batch_size, max_workers)\n",
    "    \n",
    "    # 5. éªŒè¯ç»“æœ\n",
    "    with driver.session(database=NEO4J_DATABASE) as session:\n",
    "        # æ£€æŸ¥EntityèŠ‚ç‚¹æ•°é‡\n",
    "        result = session.run(\"MATCH (e:__Entity__) RETURN count(e) as count\")\n",
    "        entity_count = result.single()[\"count\"]\n",
    "        \n",
    "        # æ£€æŸ¥HAS_ENTITYå…³ç³»æ•°é‡\n",
    "        result = session.run(\"MATCH (c:__Chunk__)-[r:HAS_ENTITY]->(e:__Entity__) RETURN count(r) as count\")\n",
    "        relation_count = result.single()[\"count\"]\n",
    "        \n",
    "        # æ£€æŸ¥åŠ¨æ€æ ‡ç­¾\n",
    "        result = session.run(\"CALL db.labels() YIELD label WHERE label <> '__Entity__' AND label <> '__Chunk__' AND label <> '__Document__' RETURN collect(label) as labels\")\n",
    "        dynamic_labels = result.single()[\"labels\"]\n",
    "        \n",
    "        print(f\"éªŒè¯ç»“æœ: {entity_count} ä¸ª__Entity__èŠ‚ç‚¹, {relation_count} ä¸ªHAS_ENTITYå…³ç³»\")\n",
    "        print(f\"åŠ¨æ€æ ‡ç­¾: {dynamic_labels}\")\n",
    "    \n",
    "    return entity_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;å¦‚æœéœ€è¦å®‰è£…`apoc`æ’ä»¶ï¼Œå¯ä»¥è¿›å…¥è¯¥åœ°å€ï¼šhttps://github.com/neo4j/apoc/releasesï¼Œ ä¸‹è½½å¯¹åº”çš„ç‰ˆæœ¬ï¼Œç„¶åå°†å…¶æ”¾ç½®åœ¨`Neo4j`çš„`plugins`æ–‡ä»¶å¤¹ä¸‹ï¼Œé‡å¯`Neo4j`å³å¯ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://muyu20241105.oss-cn-beijing.aliyuncs.com/images/202503131146422.png\" width=80%></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NEO4J_URI=\"bolt://localhost\"\n",
    "NEO4J_USERNAME=\"neo4j\"\n",
    "NEO4J_PASSWORD=\"Han9510!\"\n",
    "NEO4J_DATABASE=\"neo4j\"\n",
    "\n",
    "driver = GraphDatabase.driver(\n",
    "    NEO4J_URI, \n",
    "    auth=(NEO4J_USERNAME, NEO4J_PASSWORD)\n",
    "    )\n",
    "\n",
    "\n",
    "# å¯¼å…¥å®ä½“\n",
    "import_entities(df_entities, batch_size=100, max_workers=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;æ‰§è¡Œå®Œæˆåï¼Œå¯ä»¥åœ¨`localhost:7474`çš„`Neo4j`æµè§ˆå™¨ä¸­ï¼Œå¯ä»¥çœ‹åˆ°ä¼šæ ¹æ®`type`å­—æ®µï¼Œåˆ›å»ºäº†ä¸åŒçš„æ ‡ç­¾ã€‚åŒæ—¶ï¼Œ`__Entity__`èŠ‚ç‚¹ä¸`__Chunk__`èŠ‚ç‚¹ä¹‹é—´ï¼Œä¹Ÿåˆ›å»ºäº†`HAS_ENTITY`å…³ç³»ã€‚å¦‚ä¸‹å›¾æ‰€ç¤ºï¼š\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://muyu20241105.oss-cn-beijing.aliyuncs.com/images/202503121911563.png\" width=80%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;è‡³æ­¤ï¼Œæˆ‘ä»¬å°±å®Œæˆäº†`entities.parquet`æ–‡ä»¶çš„å¯¼å…¥ã€‚æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬å¼€å§‹å¯¼å…¥`relationships.parquet`æ–‡ä»¶ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.5 å¯¼å…¥å…³ç³»"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;åœ¨`relationships.parquet`æ–‡ä»¶ä¸­ï¼Œä¸»è¦å­˜å‚¨çš„æ˜¯é€šè¿‡æç¤ºè¯ï¼Œå€ŸåŠ©å¤§æ¨¡å‹ä»`text_units`ä¸­æå–å‡ºæ¥çš„å…³ç³»ã€‚è¯»å–è¯¥æ–‡ä»¶çš„ä»£ç å¦‚ä¸‹æ‰€ç¤ºï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ä½¿ç”¨ç»å¯¹è·¯å¾„è¯»å– Parquet æ–‡ä»¶\n",
    "df_relations = pd.read_parquet('./data/output/relationships.parquet')  # æ›¿æ¢ä¸ºå®é™…è·¯å¾„\n",
    "\n",
    "# å‡è®¾ df æ˜¯ä½ çš„ DataFrame\n",
    "print(tabulate(df_relations, headers='keys', tablefmt='pretty', showindex=False, stralign='left', maxcolwidths=[20, 20, 20, 20, 20]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;å„ä¸ªå­—æ®µçš„è§£é‡Šå¦‚ä¸‹æ‰€ç¤ºï¼š"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<style>\n",
    ".center \n",
    "{\n",
    "  width: auto;\n",
    "  display: table;\n",
    "  margin-left: auto;\n",
    "  margin-right: auto;\n",
    "}\n",
    "</style>\n",
    "\n",
    "<p align=\"center\"><font face=\"é»‘ä½“\" size=4>relationships DataFrame å­—æ®µè§£é‡Š</font></p>\n",
    "<div class=\"center\">\n",
    "\n",
    "| å­—æ®µå              | ç±»å‹               | è¯´æ˜                                                         |\n",
    "|---------------------|--------------------|--------------------------------------------------------------|\n",
    "| id                  | å­—ç¬¦ä¸²             | å”¯ä¸€æ ‡è¯†ç¬¦ï¼Œç”¨äºå”¯ä¸€æ ‡è¯†æ¯ä¸ªå…³ç³»è®°å½•ã€‚                       |\n",
    "| human_readable_id   | å­—ç¬¦ä¸²             | å¯è¯»çš„æ ‡è¯†ç¬¦ï¼Œé€šå¸¸ç”¨äºç”¨æˆ·ç•Œé¢æ˜¾ç¤ºï¼Œä¾¿äºç”¨æˆ·ç†è§£å’Œè¯†åˆ«ã€‚   |\n",
    "| source              | å­—ç¬¦ä¸²             | å…³ç³»çš„æºå®ä½“ï¼Œè¡¨ç¤ºå…³ç³»çš„èµ·å§‹èŠ‚ç‚¹ã€‚                         |\n",
    "| target              | å­—ç¬¦ä¸²             | å…³ç³»çš„ç›®æ ‡å®ä½“ï¼Œè¡¨ç¤ºå…³ç³»çš„ç»“æŸèŠ‚ç‚¹ã€‚                       |\n",
    "| description         | å­—ç¬¦ä¸²             | å¯¹å…³ç³»çš„è¯¦ç»†æè¿°ï¼Œæä¾›æ›´å¤šä¸Šä¸‹æ–‡ä¿¡æ¯ã€‚                     |\n",
    "| weight              | æµ®ç‚¹æ•°             | å…³ç³»çš„æƒé‡ï¼Œé€šå¸¸ç”¨äºè¡¨ç¤ºå…³ç³»çš„é‡è¦æ€§æˆ–å¼ºåº¦ã€‚               |\n",
    "| combined_degree     | æ•´æ•°               | å…³ç³»çš„ç»„åˆåº¦ï¼Œè¡¨ç¤ºä¸å…¶ä»–å®ä½“çš„è¿æ¥æ•°é‡ã€‚                   |\n",
    "| text_unit_ids       | åˆ—è¡¨ï¼ˆå­—ç¬¦ä¸²ï¼‰     | å…³è”çš„æ–‡æœ¬å•å…ƒçš„å”¯ä¸€æ ‡è¯†ç¬¦åˆ—è¡¨ï¼Œé€šå¸¸ç”¨äºå°†å…³ç³»ä¸æ–‡æœ¬å…³è”ã€‚ |\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;åœ¨çŸ¥è¯†å›¾è°±æ„å»ºè¿‡ç¨‹ä¸­ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨å·²ç»åˆ›å»ºå¥½çš„`__Entity__`èŠ‚ç‚¹ï¼Œç„¶åæ ¹æ®`source`å’Œ`target`å­—æ®µï¼Œåˆ›å»ºå…³ç³»ã€‚å…¶å¯¼å…¥ç­–ç•¥å¯ä»¥è€ƒè™‘ä»¥ä¸‹åŸåˆ™ï¼š\n",
    "\n",
    "- **èŠ‚ç‚¹æ ‡è¯†**ï¼šéœ€è¦ä½¿ç”¨`id`å­—æ®µä½œä¸ºRelationshipèŠ‚ç‚¹çš„å”¯ä¸€æ ‡è¯†ç¬¦ï¼Œç¡®ä¿å›¾è°±ä¸­å…³ç³»èŠ‚ç‚¹ä¸€è‡´æ€§ã€‚\n",
    "- **çº¦æŸç­–ç•¥**ï¼šå”¯ä¸€æ€§çº¦æŸï¼Œç¡®ä¿å…³ç³»çš„idæ˜¯å”¯ä¸€çš„ã€‚\n",
    "- **å±æ€§é€‰æ‹©**ï¼šæ¯”å¦‚å…³ç³»çš„æè¿°ï¼Œæƒé‡ï¼Œç»„åˆåº¦ç­‰ï¼Œæ ¹æ®éœ€æ±‚é€‰æ‹©ã€‚\n",
    "- **å…³ç³»ç­–ç•¥**ï¼šæŸ¥æ‰¾ä¸¤ä¸ªå®ä½“èŠ‚ç‚¹ï¼ˆsource å’Œ targetï¼‰ï¼Œåˆ›å»ºæˆ–æ›´æ–°è¿™ä¸¤ä¸ªå®ä½“ä¹‹é—´çš„ RELATED å…³ç³»ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;å› æ­¤ï¼ŒæŠŠä¸Šè¿°çš„ç­–ç•¥è½¬åŒ–æˆä»£ç ã€‚å°±å¦‚ä¸‹æ‰€ç¤ºï¼šå…¶ä¸­æ¯”è¾ƒå…³é”®çš„æ˜¯ï¼š\n",
    "\n",
    "- RELATEDå…³ç³»ï¼šè¿æ¥ä¸¤ä¸ª__Entity__èŠ‚ç‚¹ï¼Œè¡¨ç¤ºå®ä½“ä¹‹é—´çš„ç›´æ¥è¯­ä¹‰å…³ç³»ï¼Œä¾‹å¦‚ï¼š(Person:Entity)-[:RELATED]->(Company:Entity)\n",
    "- HAS_RELATIONSHIPå…³ç³»ï¼šè¿æ¥__Chunk__èŠ‚ç‚¹å’Œ__Relationship__èŠ‚ç‚¹ï¼Œè¡¨ç¤ºæŸä¸ªæ–‡æœ¬å—ä¸­æåˆ°äº†æŸç§å…³ç³»ï¼Œä¾‹å¦‚ï¼š(TextChunk:Chunk)-[:HAS_RELATIONSHIP]->(EntityRelationship:Relationship)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_relationship_constraints():\n",
    "    \"\"\"åˆ›å»ºRelationshipæ ‡ç­¾çš„çº¦æŸ\"\"\"\n",
    "    with driver.session(database=NEO4J_DATABASE) as session:\n",
    "        try:\n",
    "            # åˆ›å»ºRelationship.idå”¯ä¸€æ€§çº¦æŸ\n",
    "            session.run(\"CREATE CONSTRAINT IF NOT EXISTS FOR (r:__Relationship__) REQUIRE r.id IS UNIQUE\")\n",
    "            print(\"å·²åˆ›å»º__Relationship__.idå”¯ä¸€æ€§çº¦æŸ\")\n",
    "        except Exception as e:\n",
    "            print(f\"åˆ›å»º__Relationship__çº¦æŸæ—¶å‡ºé”™ (å¯èƒ½å·²å­˜åœ¨): {e}\")\n",
    "            # å°è¯•æ—§ç‰ˆæœ¬Neo4jçš„è¯­æ³•\n",
    "            try:\n",
    "                session.run(\"CREATE CONSTRAINT ON (r:__Relationship__) ASSERT r.id IS UNIQUE\")\n",
    "                print(\"å·²ä½¿ç”¨æ—§è¯­æ³•åˆ›å»º__Relationship__.idå”¯ä¸€æ€§çº¦æŸ\")\n",
    "            except Exception as e2:\n",
    "                print(f\"ä½¿ç”¨æ—§è¯­æ³•åˆ›å»ºçº¦æŸä¹Ÿå¤±è´¥: {e2}\")\n",
    "\n",
    "def import_relationships(df_relationships, batch_size=100, max_workers=8):\n",
    "    \"\"\"\n",
    "    å¯¼å…¥å…³ç³»æ•°æ®åˆ°Neo4j\n",
    "    \n",
    "    å‚æ•°:\n",
    "    - df_relationships: åŒ…å«å…³ç³»æ•°æ®çš„DataFrame\n",
    "    - batch_size: æ¯æ‰¹å¤„ç†çš„è¡Œæ•°\n",
    "    - max_workers: å¹¶è¡Œçº¿ç¨‹æ•°\n",
    "    \n",
    "    è¿”å›:\n",
    "    - å¯¼å…¥ç»Ÿè®¡ä¿¡æ¯çš„å­—å…¸\n",
    "    \"\"\"\n",
    "    # 1. åˆ›å»ºRelationshipçš„çº¦æŸ\n",
    "    setup_relationship_constraints()\n",
    "    \n",
    "    # 2. æ£€æŸ¥æ ‡ç­¾å’ŒèŠ‚ç‚¹æ˜¯å¦å­˜åœ¨\n",
    "    with driver.session(database=NEO4J_DATABASE) as session:\n",
    "        # æ£€æŸ¥Entityå’ŒChunkèŠ‚ç‚¹æ•°é‡\n",
    "        result = session.run(\"MATCH (e:__Entity__) RETURN count(e) as count\")\n",
    "        entity_count = result.single()[\"count\"]\n",
    "        \n",
    "        result = session.run(\"MATCH (c:__Chunk__) RETURN count(c) as count\")\n",
    "        chunk_count = result.single()[\"count\"]\n",
    "        \n",
    "        print(f\"èŠ‚ç‚¹æ•°é‡: {entity_count} ä¸ª__Entity__èŠ‚ç‚¹, {chunk_count} ä¸ª__Chunk__èŠ‚ç‚¹\")\n",
    "        \n",
    "        if entity_count == 0:\n",
    "            print(\"æ²¡æœ‰__Entity__èŠ‚ç‚¹ï¼Œè¯·å…ˆå¯¼å…¥Entityæ•°æ®\")\n",
    "        \n",
    "        if chunk_count == 0:\n",
    "            print(\"æ²¡æœ‰__Chunk__èŠ‚ç‚¹ï¼Œè¯·å…ˆå¯¼å…¥Chunkæ•°æ®\")\n",
    "    \n",
    "    # 3. é¢„å¤„ç†text_unit_ids - ç¡®ä¿æ˜¯åˆ—è¡¨æ ¼å¼\n",
    "    print(\"é¢„å¤„ç†text_unit_ids...\")\n",
    "    \n",
    "    # åˆ›å»ºDataFrameçš„å‰¯æœ¬\n",
    "    df_relationships = df_relationships.copy()\n",
    "    \n",
    "    # å¤„ç†text_unit_idså­—æ®µ\n",
    "    for idx, row in df_relationships.iterrows():\n",
    "        text_unit_ids = row.get('text_unit_ids')\n",
    "        \n",
    "        # å¦‚æœä¸æ˜¯åˆ—è¡¨ï¼Œè½¬æ¢ä¸ºåˆ—è¡¨\n",
    "        if not isinstance(text_unit_ids, list):\n",
    "            if isinstance(text_unit_ids, str):\n",
    "                try:\n",
    "                    # å°è¯•è§£æJSONå­—ç¬¦ä¸²\n",
    "                    import json\n",
    "                    text_unit_ids = json.loads(text_unit_ids)\n",
    "                except:\n",
    "                    # å¦‚æœè§£æå¤±è´¥ï¼Œå°†å…¶ä½œä¸ºå•ä¸ªå…ƒç´ çš„åˆ—è¡¨\n",
    "                    text_unit_ids = [text_unit_ids]\n",
    "            elif hasattr(text_unit_ids, 'dtype') and hasattr(text_unit_ids, 'tolist'):\n",
    "                # å¤„ç†NumPyæ•°ç»„\n",
    "                text_unit_ids = text_unit_ids.tolist()\n",
    "            else:\n",
    "                # å…¶ä»–ç±»å‹ï¼Œè½¬ä¸ºåˆ—è¡¨\n",
    "                text_unit_ids = [text_unit_ids] if text_unit_ids is not None else []\n",
    "        \n",
    "        # å¤„ç†åµŒå¥—åˆ—è¡¨\n",
    "        flat_text_unit_ids = []\n",
    "        for item in text_unit_ids:\n",
    "            if isinstance(item, list) or (hasattr(item, 'dtype') and hasattr(item, 'tolist')):\n",
    "                if hasattr(item, 'tolist'):\n",
    "                    flat_text_unit_ids.extend(item.tolist())\n",
    "                else:\n",
    "                    flat_text_unit_ids.extend(item)\n",
    "            else:\n",
    "                flat_text_unit_ids.append(item)\n",
    "        \n",
    "        # ç¡®ä¿æ‰€æœ‰IDéƒ½æ˜¯å­—ç¬¦ä¸²ä¸”éç©º\n",
    "        flat_text_unit_ids = [str(id) for id in flat_text_unit_ids if id is not None and str(id).strip() != '']\n",
    "        \n",
    "        # æ›´æ–°DataFrame\n",
    "        df_relationships.at[idx, 'text_unit_ids'] = flat_text_unit_ids\n",
    "    \n",
    "    # 4. éªŒè¯sourceå’Œtargetæ˜¯å¦å­˜åœ¨\n",
    "    print(\"éªŒè¯sourceå’Œtargetå®ä½“...\")\n",
    "    sample_rows = df_relationships.head(min(5, len(df_relationships)))  # å–å‰5è¡Œè¿›è¡ŒéªŒè¯\n",
    "    \n",
    "    with driver.session(database=NEO4J_DATABASE) as session:\n",
    "        for _, row in sample_rows.iterrows():\n",
    "            source_id = row['source']\n",
    "            target_id = row['target']\n",
    "            \n",
    "            # æ£€æŸ¥sourceå®ä½“\n",
    "            result = session.run(\"MATCH (e:__Entity__ {id: $id}) RETURN count(e) as count\", id=source_id)\n",
    "            source_exists = result.single()[\"count\"] > 0\n",
    "            \n",
    "            # æ£€æŸ¥targetå®ä½“\n",
    "            result = session.run(\"MATCH (e:__Entity__ {id: $id}) RETURN count(e) as count\", id=target_id)\n",
    "            target_exists = result.single()[\"count\"] > 0\n",
    "            \n",
    "            print(f\"å®ä½“æ£€æŸ¥: source={source_id} {'å­˜åœ¨' if source_exists else 'ä¸å­˜åœ¨'}, target={target_id} {'å­˜åœ¨' if target_exists else 'ä¸å­˜åœ¨'}\")\n",
    "            \n",
    "            if not source_exists or not target_exists:\n",
    "                print(\"éƒ¨åˆ†å®ä½“ä¸å­˜åœ¨ï¼Œå°†åœ¨å¯¼å…¥è¿‡ç¨‹ä¸­åˆ›å»º\")\n",
    "    \n",
    "    # 5. å¯¼å…¥å…³ç³»æ•°æ®\n",
    "    print(\"å¼€å§‹å¯¼å…¥å…³ç³»æ•°æ®...\")\n",
    "    \n",
    "    # åˆ†ä¸¤æ­¥æ‰§è¡Œï¼Œå…ˆåˆ›å»ºå…³ç³»èŠ‚ç‚¹å’Œå®ä½“é—´å…³ç³»ï¼Œå†åˆ›å»ºä¸Chunkçš„å…³ç³»\n",
    "    # æ­¥éª¤1: åˆ›å»ºå…³ç³»èŠ‚ç‚¹å’Œå®ä½“é—´å…³ç³»\n",
    "    relationship_statement = \"\"\"\n",
    "    // åˆ›å»ºå…³ç³»èŠ‚ç‚¹\n",
    "    MERGE (r:__Relationship__ {id: value.id})\n",
    "    SET r.human_readable_id = value.human_readable_id,\n",
    "        r.description = value.description,\n",
    "        r.weight = value.weight,\n",
    "        r.combined_degree = value.combined_degree,\n",
    "        r.name = value.human_readable_id\n",
    "    \n",
    "    // æŸ¥æ‰¾æˆ–åˆ›å»ºæºå®ä½“å’Œç›®æ ‡å®ä½“\n",
    "    WITH r, value\n",
    "    MERGE (source:__Entity__ {id: value.source})\n",
    "    MERGE (target:__Entity__ {id: value.target})\n",
    "    \n",
    "    // åˆ›å»ºRELATEDå…³ç³»\n",
    "    MERGE (source)-[rel:RELATED]->(target)\n",
    "    SET rel.relationship_id = value.id,\n",
    "        rel.description = value.description,\n",
    "        rel.weight = value.weight\n",
    "    \n",
    "    RETURN r.id as relationship_id\n",
    "    \"\"\"\n",
    "    \n",
    "    # æ‰§è¡Œå¯¼å…¥å…³ç³»èŠ‚ç‚¹å’Œå®ä½“é—´å…³ç³»\n",
    "    relationship_result = parallel_batched_import(relationship_statement, df_relationships, batch_size, max_workers)\n",
    "    print(f\"å·²åˆ›å»º {relationship_result['successful_rows']} ä¸ª__Relationship__èŠ‚ç‚¹å’ŒRELATEDå…³ç³»\")\n",
    "    \n",
    "    # æ­¥éª¤2: åˆ›å»ºä¸Chunkçš„å…³ç³»\n",
    "    # å‡†å¤‡Chunkå…³ç³»æ•°æ®\n",
    "    chunk_relations = []\n",
    "    for _, row in df_relationships.iterrows():\n",
    "        rel_id = row['id']\n",
    "        for chunk_id in row['text_unit_ids']:\n",
    "            chunk_relations.append({\n",
    "                'relationship_id': rel_id,\n",
    "                'chunk_id': chunk_id\n",
    "            })\n",
    "    \n",
    "    if chunk_relations:\n",
    "        df_chunk_relations = pd.DataFrame(chunk_relations)\n",
    "        \n",
    "        # åˆ›å»ºChunkåˆ°Relationshipçš„å…³ç³»\n",
    "        chunk_rel_statement = \"\"\"\n",
    "        MATCH (r:__Relationship__ {id: value.relationship_id})\n",
    "        MATCH (c:__Chunk__ {id: value.chunk_id})\n",
    "        MERGE (c)-[:HAS_RELATIONSHIP]->(r)\n",
    "        \"\"\"\n",
    "        \n",
    "        # æ‰§è¡Œå¯¼å…¥Chunkå…³ç³»\n",
    "        chunk_rel_result = parallel_batched_import(chunk_rel_statement, df_chunk_relations, batch_size, max_workers)\n",
    "        print(f\"å·²åˆ›å»º {chunk_rel_result['successful_rows']} ä¸ªChunk-Relationshipå…³ç³»\")\n",
    "    else:\n",
    "        print(\"æ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆçš„Chunk-Relationshipå…³ç³»æ•°æ®\")\n",
    "    \n",
    "    # 6. éªŒè¯ç»“æœ\n",
    "    with driver.session(database=NEO4J_DATABASE) as session:\n",
    "        # æ£€æŸ¥RelationshipèŠ‚ç‚¹æ•°é‡\n",
    "        result = session.run(\"MATCH (r:__Relationship__) RETURN count(r) as count\")\n",
    "        relationship_count = result.single()[\"count\"]\n",
    "        \n",
    "        # æ£€æŸ¥RELATEDå…³ç³»æ•°é‡\n",
    "        result = session.run(\"MATCH ()-[r:RELATED]->() RETURN count(r) as count\")\n",
    "        related_count = result.single()[\"count\"]\n",
    "        \n",
    "        # æ£€æŸ¥HAS_RELATIONSHIPå…³ç³»æ•°é‡\n",
    "        try:\n",
    "            result = session.run(\"MATCH (c:__Chunk__)-[r:HAS_RELATIONSHIP]->() RETURN count(r) as count\")\n",
    "            has_relationship_count = result.single()[\"count\"]\n",
    "        except Exception as e:\n",
    "            print(f\"æŸ¥è¯¢HAS_RELATIONSHIPå…³ç³»æ—¶å‡ºé”™: {e}\")\n",
    "            has_relationship_count = \"æœªçŸ¥\"\n",
    "        \n",
    "        print(f\"éªŒè¯ç»“æœ: {relationship_count} ä¸ª__Relationship__èŠ‚ç‚¹, {related_count} ä¸ªRELATEDå…³ç³», {has_relationship_count} ä¸ªHAS_RELATIONSHIPå…³ç³»\")\n",
    "    \n",
    "    return relationship_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¯¼å…¥å…³ç³»\n",
    "import_relationships(df_relations, batch_size=100, max_workers=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;æ‰§è¡Œå®Œæˆåï¼Œå¯ä»¥åœ¨`localhost:7474`çš„`Neo4j`æµè§ˆå™¨ä¸­ï¼Œå¯ä»¥çœ‹åˆ°ä¼šç”Ÿæˆ`__Relationship__`èŠ‚ç‚¹ï¼ŒåŒæ—¶ï¼Œ`__Entity__`èŠ‚ç‚¹ä¸`__Chunk__`èŠ‚ç‚¹ä¹‹é—´ï¼Œä¹Ÿåˆ›å»ºäº†`HAS_RELATIONSHIP`å…³ç³»ï¼Œä»¥åŠ`__Relationship__`èŠ‚ç‚¹ä¸`__Entity__`èŠ‚ç‚¹ä¹‹é—´ï¼Œä¹Ÿåˆ›å»ºäº†`RELATED`å…³ç³»ã€‚å¦‚ä¸‹å›¾æ‰€ç¤ºï¼š\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://muyu20241105.oss-cn-beijing.aliyuncs.com/images/202503121928544.png\" width=80%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;è‡³æ­¤ï¼Œæˆ‘ä»¬å°±å®Œæˆäº†`relationships.parquet`æ–‡ä»¶çš„å¯¼å…¥ã€‚æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬å¼€å§‹å¯¼å…¥`communities.parquet`æ–‡ä»¶ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.6 å¯¼å…¥ç¤¾åŒº"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;åœ¨`communities.parquet`æ–‡ä»¶ä¸­ï¼Œä¸»è¦å­˜å‚¨çš„é€šè¿‡è±é¡¿ç¤¾åŒºå‘ç°ç®—æ³•ï¼Œæ ¹æ®`settings.yaml` æ–‡ä»¶ä¸­`cluster_graph`é…ç½®åˆ’åˆ†å‡ºçš„ç¤¾åŒºå±‚çº§ï¼ŒåŒæ—¶é€šè¿‡åå¤„ç†ï¼Œå¯¹æ¯ä¸ªç¤¾åŒºä¸­åŒ…å«çš„å®ä½“ï¼Œå…³ç³»ï¼Œæ–‡æœ¬å•å…ƒç­‰è¿›è¡Œå…³è”ã€‚è¯»å–è¯¥æ–‡ä»¶çš„ä»£ç å¦‚ä¸‹æ‰€ç¤ºï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ä½¿ç”¨ç»å¯¹è·¯å¾„è¯»å– Parquet æ–‡ä»¶\n",
    "df_communities = pd.read_parquet('./data/output/communities.parquet')  # æ›¿æ¢ä¸ºå®é™…è·¯å¾„\n",
    "\n",
    "# å‡è®¾ df æ˜¯ä½ çš„ DataFrame\n",
    "print(tabulate(df_communities, headers='keys', tablefmt='pretty', showindex=False, stralign='left', maxcolwidths=[20, 20, 20, 20, 20]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;å„ä¸ªå­—æ®µçš„è§£é‡Šå¦‚ä¸‹æ‰€ç¤ºï¼š"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<style>\n",
    ".center \n",
    "{\n",
    "  width: auto;\n",
    "  display: table;\n",
    "  margin-left: auto;\n",
    "  margin-right: auto;\n",
    "}\n",
    "</style>\n",
    "\n",
    "<p align=\"center\"><font face=\"é»‘ä½“\" size=4>communities DataFrame å­—æ®µè§£é‡Š</font></p>\n",
    "<div class=\"center\">\n",
    "\n",
    "| å­—æ®µå              | ç±»å‹               | è¯´æ˜                                                         |\n",
    "|---------------------|--------------------|--------------------------------------------------------------|\n",
    "| id                  | å­—ç¬¦ä¸²             | å”¯ä¸€æ ‡è¯†ç¬¦ï¼Œç”¨äºå”¯ä¸€æ ‡è¯†æ¯ä¸ªç¤¾åŒºè®°å½•ã€‚                       |\n",
    "| human_readable_id   | å­—ç¬¦ä¸²             | å¯è¯»çš„æ ‡è¯†ç¬¦ï¼Œé€šå¸¸ç”¨äºç”¨æˆ·ç•Œé¢æ˜¾ç¤ºï¼Œä¾¿äºç”¨æˆ·ç†è§£å’Œè¯†åˆ«ã€‚   |\n",
    "| community           | æ•´æ•°               | ç¤¾åŒºçš„æ ‡è¯†ç¬¦ï¼Œè¡¨ç¤ºè¯¥è®°å½•æ‰€å±çš„ç¤¾åŒºç¼–å·ã€‚                   |\n",
    "| level               | æ•´æ•°               | ç¤¾åŒºçš„å±‚çº§ï¼Œè¡¨ç¤ºè¯¥ç¤¾åŒºåœ¨å±‚çº§ç»“æ„ä¸­çš„ä½ç½®ã€‚                 |\n",
    "| parent              | æ•´æ•°               | çˆ¶ç¤¾åŒºçš„æ ‡è¯†ç¬¦ï¼Œè¡¨ç¤ºè¯¥ç¤¾åŒºçš„ä¸Šçº§ç¤¾åŒºï¼Œ-1 è¡¨ç¤ºæ²¡æœ‰çˆ¶ç¤¾åŒºã€‚  |\n",
    "| children            | åˆ—è¡¨ï¼ˆå­—ç¬¦ä¸²ï¼‰     | å­ç¤¾åŒºçš„æ ‡è¯†ç¬¦åˆ—è¡¨ï¼Œè¡¨ç¤ºè¯¥ç¤¾åŒºä¸‹å±çš„å­ç¤¾åŒºã€‚               |\n",
    "| title               | å­—ç¬¦ä¸²             | ç¤¾åŒºçš„åç§°æˆ–æ ‡é¢˜                  |\n",
    "| entity_ids          | åˆ—è¡¨ï¼ˆå­—ç¬¦ä¸²ï¼‰     | å…³è”çš„å®ä½“çš„å”¯ä¸€æ ‡è¯†ç¬¦åˆ—è¡¨ï¼Œé€šå¸¸ç”¨äºå°†ç¤¾åŒºä¸å®ä½“å…³è”ã€‚     |\n",
    "| relationship_ids    | åˆ—è¡¨ï¼ˆå­—ç¬¦ä¸²ï¼‰     | å…³è”çš„å…³ç³»çš„å”¯ä¸€æ ‡è¯†ç¬¦åˆ—è¡¨ï¼Œè¡¨ç¤ºè¯¥ç¤¾åŒºä¸­æ¶‰åŠçš„å…³ç³»ã€‚       |\n",
    "| text_unit_ids       | åˆ—è¡¨ï¼ˆå­—ç¬¦ä¸²ï¼‰     | å…³è”çš„æ–‡æœ¬å•å…ƒçš„å”¯ä¸€æ ‡è¯†ç¬¦åˆ—è¡¨ï¼Œé€šå¸¸ç”¨äºå°†ç¤¾åŒºä¸æ–‡æœ¬å…³è”ã€‚ |\n",
    "| period              | æ—¥æœŸ               | ç¤¾åŒºçš„æ—¶é—´æ®µï¼Œè¡¨ç¤ºè¯¥ç¤¾åŒºçš„æœ‰æ•ˆæ—¶é—´èŒƒå›´ã€‚                   |\n",
    "| size                | æ•´æ•°               | ç¤¾åŒºçš„è§„æ¨¡ï¼Œé€šå¸¸è¡¨ç¤ºç¤¾åŒºä¸­åŒ…å«çš„å®ä½“æˆ–æˆå‘˜æ•°é‡ã€‚           |\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;æ€è€ƒç°åœ¨å·²ç»å®Œæˆçš„èŠ‚ç‚¹å’Œå…³ç³»ï¼Œæˆ‘ä»¬å…¶å®åªéœ€è¦æŠŠå…³ç³»ä¸ç¤¾åŒºè¿›è¡Œå…³è”å°±è¶³å¤Ÿäº†ã€‚å› æ­¤ï¼Œå¯¼å…¥çš„ç­–ç•¥å¯ä»¥è€ƒè™‘ä»¥ä¸‹åŸåˆ™ï¼š\n",
    "\n",
    "- **èŠ‚ç‚¹æ ‡è¯†**ï¼šéœ€è¦ä½¿ç”¨`id`å­—æ®µä½œä¸ºCommunityèŠ‚ç‚¹çš„å”¯ä¸€æ ‡è¯†ç¬¦ï¼Œç¡®ä¿å›¾è°±ä¸­èŠ‚ç‚¹ä¸€è‡´æ€§ã€‚\n",
    "- **çº¦æŸç­–ç•¥**ï¼šå”¯ä¸€æ€§çº¦æŸï¼Œç¡®ä¿å…³ç³»çš„idæ˜¯å”¯ä¸€çš„ã€‚\n",
    "- **å±æ€§é€‰æ‹©**ï¼šæ¯”å¦‚ç¤¾åŒºçš„åç§°ï¼Œçº§åˆ«ï¼Œè§„æ¨¡ç­‰ï¼Œæ ¹æ®éœ€æ±‚é€‰æ‹©ã€‚\n",
    "- **å…³ç³»ç­–ç•¥**ï¼šä¸è¯¥ç¤¾åŒºç›¸å…³çš„å®ä½“èŠ‚ç‚¹ï¼ˆé€šè¿‡ relationship_idsï¼‰ä¸ç¤¾åŒºå»ºç«‹ IN_COMMUNITY å…³ç³»ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;å› æ­¤ï¼ŒæŠŠä¸Šè¿°çš„ç­–ç•¥è½¬åŒ–æˆä»£ç ã€‚å°±å¦‚ä¸‹æ‰€ç¤ºï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_community_constraints():\n",
    "    \"\"\"åˆ›å»ºCommunityæ ‡ç­¾çš„çº¦æŸ\"\"\"\n",
    "    with driver.session(database=NEO4J_DATABASE) as session:\n",
    "        try:\n",
    "            # åˆ›å»ºCommunity.idå”¯ä¸€æ€§çº¦æŸ\n",
    "            session.run(\"CREATE CONSTRAINT IF NOT EXISTS FOR (c:__Community__) REQUIRE c.id IS UNIQUE\")\n",
    "            print(\"å·²åˆ›å»º__Community__.idå”¯ä¸€æ€§çº¦æŸ\")\n",
    "        except Exception as e:\n",
    "            print(f\"åˆ›å»º__Community__çº¦æŸæ—¶å‡ºé”™ (å¯èƒ½å·²å­˜åœ¨): {e}\")\n",
    "            # å°è¯•æ—§ç‰ˆæœ¬Neo4jçš„è¯­æ³•\n",
    "            try:\n",
    "                session.run(\"CREATE CONSTRAINT ON (c:__Community__) ASSERT c.id IS UNIQUE\")\n",
    "                print(\"å·²ä½¿ç”¨æ—§è¯­æ³•åˆ›å»º__Community__.idå”¯ä¸€æ€§çº¦æŸ\")\n",
    "            except Exception as e2:\n",
    "                print(f\"ä½¿ç”¨æ—§è¯­æ³•åˆ›å»ºçº¦æŸä¹Ÿå¤±è´¥: {e2}\")\n",
    "\n",
    "def import_communities(df_communities, batch_size=100, max_workers=8):\n",
    "    \"\"\"\n",
    "    å¯¼å…¥ç¤¾åŒº(Community)æ•°æ®åˆ°Neo4j\n",
    "    \n",
    "    å‚æ•°:\n",
    "    - df_communities: åŒ…å«ç¤¾åŒºæ•°æ®çš„DataFrame\n",
    "    - batch_size: æ¯æ‰¹å¤„ç†çš„è¡Œæ•°\n",
    "    - max_workers: å¹¶è¡Œçº¿ç¨‹æ•°\n",
    "    \n",
    "    è¿”å›:\n",
    "    - å¯¼å…¥ç»Ÿè®¡ä¿¡æ¯çš„å­—å…¸\n",
    "    \"\"\"\n",
    "    # 1. åˆ›å»ºCommunityçš„çº¦æŸ\n",
    "    setup_community_constraints()\n",
    "    \n",
    "    # 2. é¢„å¤„ç†åˆ—è¡¨å­—æ®µ - ç¡®ä¿æ˜¯åˆ—è¡¨æ ¼å¼\n",
    "    print(\"é¢„å¤„ç†åˆ—è¡¨å­—æ®µ...\")\n",
    "    \n",
    "    # åˆ›å»ºDataFrameçš„å‰¯æœ¬\n",
    "    df_communities = df_communities.copy()\n",
    "    \n",
    "    # éœ€è¦å¤„ç†çš„åˆ—è¡¨å­—æ®µ\n",
    "    list_fields = ['children', 'entity_ids', 'relationship_ids', 'text_unit_ids']\n",
    "    \n",
    "    for field in list_fields:\n",
    "        if field in df_communities.columns:\n",
    "            for idx, row in df_communities.iterrows():\n",
    "                field_value = row.get(field)\n",
    "                \n",
    "                # å¦‚æœä¸æ˜¯åˆ—è¡¨ï¼Œè½¬æ¢ä¸ºåˆ—è¡¨\n",
    "                if not isinstance(field_value, list):\n",
    "                    if isinstance(field_value, str):\n",
    "                        try:\n",
    "                            # å°è¯•è§£æJSONå­—ç¬¦ä¸²\n",
    "                            import json\n",
    "                            field_value = json.loads(field_value)\n",
    "                        except:\n",
    "                            # å¦‚æœè§£æå¤±è´¥ï¼Œå°†å…¶ä½œä¸ºå•ä¸ªå…ƒç´ çš„åˆ—è¡¨\n",
    "                            field_value = [field_value]\n",
    "                    elif hasattr(field_value, 'dtype') and hasattr(field_value, 'tolist'):\n",
    "                        # å¤„ç†NumPyæ•°ç»„\n",
    "                        field_value = field_value.tolist()\n",
    "                    else:\n",
    "                        # å…¶ä»–ç±»å‹ï¼Œè½¬ä¸ºåˆ—è¡¨\n",
    "                        field_value = [field_value] if field_value is not None else []\n",
    "                \n",
    "                # å¤„ç†åµŒå¥—åˆ—è¡¨\n",
    "                flat_field_value = []\n",
    "                for item in field_value:\n",
    "                    if isinstance(item, list) or (hasattr(item, 'dtype') and hasattr(item, 'tolist')):\n",
    "                        if hasattr(item, 'tolist'):\n",
    "                            flat_field_value.extend(item.tolist())\n",
    "                        else:\n",
    "                            flat_field_value.extend(item)\n",
    "                    else:\n",
    "                        flat_field_value.append(item)\n",
    "                \n",
    "                # ç¡®ä¿æ‰€æœ‰IDéƒ½æ˜¯å­—ç¬¦ä¸²ä¸”éç©º\n",
    "                if field in ['entity_ids', 'relationship_ids', 'text_unit_ids']:\n",
    "                    flat_field_value = [str(id) for id in flat_field_value if id is not None and str(id).strip() != '']\n",
    "                \n",
    "                # æ›´æ–°DataFrame\n",
    "                df_communities.at[idx, field] = flat_field_value\n",
    "    \n",
    "    # 3. å¯¼å…¥ç¤¾åŒºèŠ‚ç‚¹\n",
    "    print(\"å¼€å§‹å¯¼å…¥ç¤¾åŒºèŠ‚ç‚¹...\")\n",
    "    \n",
    "    community_statement = \"\"\"\n",
    "    // åˆ›å»ºCommunityèŠ‚ç‚¹\n",
    "    MERGE (c:__Community__ {id: value.id})\n",
    "    SET c.human_readable_id = value.human_readable_id,\n",
    "        c.community = value.community,\n",
    "        c.level = value.level,\n",
    "        c.parent = value.parent,\n",
    "        c.children = value.children,\n",
    "        c.title = value.title,\n",
    "        c.period = value.period,\n",
    "        c.size = value.size,\n",
    "        c.name = coalesce(value.title, value.human_readable_id, 'Community_' + value.id)\n",
    "    \n",
    "    RETURN c.id as community_id\n",
    "    \"\"\"\n",
    "    \n",
    "    # æ‰§è¡Œå¯¼å…¥ç¤¾åŒºèŠ‚ç‚¹\n",
    "    community_result = parallel_batched_import(community_statement, df_communities, batch_size, max_workers)\n",
    "    print(f\"å·²åˆ›å»º {community_result['successful_rows']} ä¸ª__Community__èŠ‚ç‚¹\")\n",
    "    \n",
    "    # 4. åˆ›å»ºä¸Entityçš„å…³ç³»\n",
    "    print(\"å¼€å§‹åˆ›å»ºç¤¾åŒºä¸å®ä½“çš„å…³ç³»...\")\n",
    "    \n",
    "    # å‡†å¤‡Entityå…³ç³»æ•°æ®\n",
    "    entity_relations = []\n",
    "    for _, row in df_communities.iterrows():\n",
    "        community_id = row['id']\n",
    "        entity_ids = row.get('entity_ids', [])\n",
    "        \n",
    "        for entity_id in entity_ids:\n",
    "            entity_relations.append({\n",
    "                'community_id': community_id,\n",
    "                'entity_id': entity_id\n",
    "            })\n",
    "    \n",
    "    if entity_relations:\n",
    "        df_entity_relations = pd.DataFrame(entity_relations)\n",
    "        \n",
    "        entity_rel_statement = \"\"\"\n",
    "        MATCH (c:__Community__ {id: value.community_id})\n",
    "        MATCH (e:__Entity__ {id: value.entity_id})\n",
    "        MERGE (e)-[:IN_COMMUNITY]->(c)\n",
    "        \"\"\"\n",
    "        \n",
    "        entity_rel_result = parallel_batched_import(entity_rel_statement, df_entity_relations, batch_size, max_workers)\n",
    "        print(f\"å·²åˆ›å»º {entity_rel_result['successful_rows']} ä¸ªEntity-Communityå…³ç³»\")\n",
    "    else:\n",
    "        print(\"æ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆçš„Entity-Communityå…³ç³»æ•°æ®\")\n",
    "    \n",
    "    # 5. åˆ›å»ºä¸Relationshipçš„å…³ç³»\n",
    "    print(\"å¼€å§‹åˆ›å»ºç¤¾åŒºä¸å…³ç³»çš„å…³ç³»...\")\n",
    "    \n",
    "    # å‡†å¤‡Relationshipå…³ç³»æ•°æ®\n",
    "    rel_relations = []\n",
    "    for _, row in df_communities.iterrows():\n",
    "        community_id = row['id']\n",
    "        relationship_ids = row.get('relationship_ids', [])\n",
    "        \n",
    "        for rel_id in relationship_ids:\n",
    "            rel_relations.append({\n",
    "                'community_id': community_id,\n",
    "                'relationship_id': rel_id\n",
    "            })\n",
    "    \n",
    "    if rel_relations:\n",
    "        df_rel_relations = pd.DataFrame(rel_relations)\n",
    "        \n",
    "        rel_rel_statement = \"\"\"\n",
    "        MATCH (c:__Community__ {id: value.community_id})\n",
    "        MATCH (r:__Relationship__ {id: value.relationship_id})\n",
    "        MERGE (r)-[:IN_COMMUNITY]->(c)\n",
    "        \"\"\"\n",
    "        \n",
    "        rel_rel_result = parallel_batched_import(rel_rel_statement, df_rel_relations, batch_size, max_workers)\n",
    "        print(f\"å·²åˆ›å»º {rel_rel_result['successful_rows']} ä¸ªRelationship-Communityå…³ç³»\")\n",
    "    else:\n",
    "        print(\"æ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆçš„Relationship-Communityå…³ç³»æ•°æ®\")\n",
    "    \n",
    "    # 6. éªŒè¯ç»“æœ\n",
    "    with driver.session(database=NEO4J_DATABASE) as session:\n",
    "        # æ£€æŸ¥CommunityèŠ‚ç‚¹æ•°é‡\n",
    "        result = session.run(\"MATCH (c:__Community__) RETURN count(c) as count\")\n",
    "        community_count = result.single()[\"count\"]\n",
    "        \n",
    "        # æ£€æŸ¥IN_COMMUNITYå…³ç³»æ•°é‡\n",
    "        result = session.run(\"MATCH ()-[r:IN_COMMUNITY]->() RETURN count(r) as count\")\n",
    "        in_community_count = result.single()[\"count\"]\n",
    "        \n",
    "        print(f\"éªŒè¯ç»“æœ: {community_count} ä¸ª__Community__èŠ‚ç‚¹, {in_community_count} ä¸ªIN_COMMUNITYå…³ç³»\")\n",
    "    \n",
    "    return community_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¯¼å…¥ç¤¾åŒº\n",
    "import_communities(df_communities, batch_size=100, max_workers=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;æ‰§è¡Œå®Œæˆåï¼Œå¯ä»¥åœ¨`localhost:7474`çš„`Neo4j`æµè§ˆå™¨ä¸­ï¼Œå¯ä»¥çœ‹åˆ°ä¼šç”Ÿæˆ`__Community__`èŠ‚ç‚¹ï¼ŒåŒæ—¶ï¼Œ`__Entity__`èŠ‚ç‚¹ä¸`__Community__`èŠ‚ç‚¹ä¹‹é—´ï¼Œä¹Ÿåˆ›å»ºäº†`IN_COMMUNITY`å…³ç³»ï¼Œä»¥åŠ`__Relationship__`èŠ‚ç‚¹ä¸`__Community__`èŠ‚ç‚¹ä¹‹é—´ï¼Œä¹Ÿåˆ›å»ºäº†`IN_COMMUNITY`å…³ç³»ã€‚å¦‚ä¸‹å›¾æ‰€ç¤ºï¼š"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://muyu20241105.oss-cn-beijing.aliyuncs.com/images/202503121942902.png\" width=80%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;è‡³æ­¤ï¼Œæˆ‘ä»¬å°±å®Œæˆäº†`communities.parquet`æ–‡ä»¶çš„å¯¼å…¥ã€‚æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬å¼€å§‹å¯¼å…¥`community_reports.parquet`æ–‡ä»¶ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.7 å¯¼å…¥ç¤¾åŒºæŠ¥å‘Š"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;åœ¨`community_reports.parquet`æ–‡ä»¶ä¸­ï¼Œä¸»è¦å­˜å‚¨çš„å†…å®¹æ˜¯è®©å¤§æ¨¡å‹é€šè¿‡æç¤ºå·¥ç¨‹ï¼Œå¯¹æ¯ä¸ªç¤¾åŒºä¸­çš„å®ä½“å’Œå…³ç³»è¿›è¡Œæ€»ç»“ï¼Œå¹¶ç”Ÿæˆç¤¾åŒºçš„æŠ¥å‘Šã€‚è¯»å–è¯¥æ–‡ä»¶çš„ä»£ç å¦‚ä¸‹æ‰€ç¤ºï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ä½¿ç”¨ç»å¯¹è·¯å¾„è¯»å– Parquet æ–‡ä»¶\n",
    "df_communities_reports = pd.read_parquet('./data/output/community_reports.parquet')  # æ›¿æ¢ä¸ºå®é™…è·¯å¾„\n",
    "\n",
    "# å‡è®¾ df æ˜¯ä½ çš„ DataFrame\n",
    "print(tabulate(df_communities_reports, headers='keys', tablefmt='pretty', showindex=False, stralign='left', maxcolwidths=[20, 20, 20, 20, 20]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;å„ä¸ªå­—æ®µçš„è§£é‡Šå¦‚ä¸‹æ‰€ç¤ºï¼š"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<style>\n",
    ".center \n",
    "{\n",
    "  width: auto;\n",
    "  display: table;\n",
    "  margin-left: auto;\n",
    "  margin-right: auto;\n",
    "}\n",
    "</style>\n",
    "\n",
    "<p align=\"center\"><font face=\"é»‘ä½“\" size=4>community_reports DataFrame å­—æ®µè§£é‡Š</font></p>\n",
    "<div class=\"center\">\n",
    "\n",
    "| å­—æ®µå              | ç±»å‹               | è¯´æ˜                                                         |\n",
    "|---------------------|--------------------|--------------------------------------------------------------|\n",
    "| id                  | å­—ç¬¦ä¸²             | å”¯ä¸€æ ‡è¯†ç¬¦ï¼Œç”¨äºå”¯ä¸€æ ‡è¯†æ¯ä¸ªè®°å½•ã€‚                           |\n",
    "| human_readable_id   | å­—ç¬¦ä¸²             | å¯è¯»çš„æ ‡è¯†ç¬¦ï¼Œé€šå¸¸ç”¨äºç”¨æˆ·ç•Œé¢æ˜¾ç¤ºï¼Œä¾¿äºç”¨æˆ·ç†è§£å’Œè¯†åˆ«ã€‚   |\n",
    "| community           | æ•´æ•°               | ç¤¾åŒºçš„æ ‡è¯†ç¬¦ï¼Œè¡¨ç¤ºè¯¥è®°å½•æ‰€å±çš„ç¤¾åŒºç¼–å·ã€‚                   |\n",
    "| level               | æ•´æ•°               | ç¤¾åŒºçš„å±‚çº§ï¼Œè¡¨ç¤ºè¯¥ç¤¾åŒºåœ¨å±‚çº§ç»“æ„ä¸­çš„ä½ç½®ã€‚                 |\n",
    "| parent              | æ•´æ•°               | çˆ¶ç¤¾åŒºçš„æ ‡è¯†ç¬¦ï¼Œè¡¨ç¤ºè¯¥ç¤¾åŒºçš„ä¸Šçº§ç¤¾åŒºï¼Œ-1 è¡¨ç¤ºæ²¡æœ‰çˆ¶ç¤¾åŒºã€‚  |\n",
    "| children            | åˆ—è¡¨ï¼ˆå­—ç¬¦ä¸²ï¼‰     | å­ç¤¾åŒºçš„æ ‡è¯†ç¬¦åˆ—è¡¨ï¼Œè¡¨ç¤ºè¯¥ç¤¾åŒºä¸‹å±çš„å­ç¤¾åŒºã€‚               |\n",
    "| title               | å­—ç¬¦ä¸²             | ç¤¾åŒºçš„åç§°æˆ–æ ‡é¢˜ï¼Œç®€è¦æè¿°è¯¥ç¤¾åŒºçš„ä¸»é¢˜ã€‚                   |\n",
    "| summary             | å­—ç¬¦ä¸²             | å¯¹ç¤¾åŒºçš„ç®€è¦æè¿°ï¼Œæä¾›æ›´å¤šä¸Šä¸‹æ–‡ä¿¡æ¯ã€‚                     |\n",
    "| full_content        | å­—ç¬¦ä¸²             | ç¤¾åŒºçš„è¯¦ç»†å†…å®¹ï¼ŒåŒ…å«æ›´å…¨é¢çš„ä¿¡æ¯å’ŒèƒŒæ™¯ã€‚                   |\n",
    "| rank                | æµ®ç‚¹æ•°             | ç¤¾åŒºçš„æ’åï¼Œé€šå¸¸ç”¨äºè¡¨ç¤ºç¤¾åŒºçš„é‡è¦æ€§æˆ–å½±å“åŠ›ã€‚             |\n",
    "| rating_explanation   | å­—ç¬¦ä¸²             | å¯¹ç¤¾åŒºè¯„åˆ†çš„è§£é‡Šï¼Œè¯´æ˜è¯„åˆ†çš„ä¾æ®å’ŒåŸå› ã€‚                   |\n",
    "| findings            | åˆ—è¡¨ï¼ˆå­—å…¸ï¼‰       | ç›¸å…³å‘ç°çš„åˆ—è¡¨ï¼Œæ¯ä¸ªå‘ç°åŒ…å«è§£é‡Šå’Œæ‘˜è¦ã€‚                   |\n",
    "| full_content_json   | JSON               | ç¤¾åŒºçš„å®Œæ•´å†…å®¹ï¼Œä»¥ JSON æ ¼å¼å­˜å‚¨ï¼Œä¾¿äºæ•°æ®äº¤æ¢å’Œå¤„ç†ã€‚     |\n",
    "| period              | æ—¥æœŸ               | ç¤¾åŒºçš„æ—¶é—´æ®µï¼Œè¡¨ç¤ºè¯¥ç¤¾åŒºçš„æœ‰æ•ˆæ—¶é—´èŒƒå›´ã€‚                   |\n",
    "| size                | æ•´æ•°               | ç¤¾åŒºçš„è§„æ¨¡ï¼Œé€šå¸¸è¡¨ç¤ºç¤¾åŒºä¸­åŒ…å«çš„å®ä½“æˆ–æˆå‘˜æ•°é‡ã€‚           |\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;å¯¹äºç¤¾åŒºæŠ¥å‘Šï¼Œæ˜¯ä¸æ˜¯éœ€è¦å°†å®ƒä»¬è¿æ¥åˆ°å®ƒä»¬æ‰€æ¶‰åŠçš„å®ä½“ï¼Œå¹¶ä¸”ä¸ºç¤¾åŒºæ›´æ–°å±æ€§ã€‚å› æ­¤ï¼Œå¯¼å…¥çš„ç­–ç•¥å¯ä»¥è€ƒè™‘ä»¥ä¸‹åŸåˆ™ï¼š\n",
    "\n",
    "- **å±æ€§ç­–ç•¥**ï¼šæ›´æ–°ç¤¾åŒºçš„å±æ€§ï¼ŒåŒ…æ‹¬ levelã€titleã€rankã€rank_explanationã€full_content å’Œ summaryã€‚\n",
    "- **å…³ç³»ç­–ç•¥**ï¼šéå†ä¸è¯¥ç¤¾åŒºç›¸å…³çš„å‘ç°ï¼ˆfindingsï¼‰ï¼Œä¸ºæ¯ä¸ªå‘ç°åˆ›å»ºä¸€ä¸ªæ–°çš„ Finding èŠ‚ç‚¹ï¼Œå¹¶å°†å…¶ä¸ç¤¾åŒºå»ºç«‹ HAS_FINDING å…³ç³»ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_community_reports(df_reports, batch_size=20, max_workers=2):\n",
    "    \"\"\"\n",
    "    å¯¼å…¥ç¤¾åŒºæŠ¥å‘Šæ•°æ®åˆ°Neo4j\n",
    "    \n",
    "    å‚æ•°:\n",
    "    - df_reports: åŒ…å«ç¤¾åŒºæŠ¥å‘Šæ•°æ®çš„DataFrame\n",
    "    - batch_size: æ¯æ‰¹å¤„ç†çš„è¡Œæ•°\n",
    "    - max_workers: å¹¶è¡Œçº¿ç¨‹æ•°\n",
    "    \n",
    "    è¿”å›:\n",
    "    - å¯¼å…¥ç»Ÿè®¡ä¿¡æ¯çš„å­—å…¸\n",
    "    \"\"\"\n",
    "    # 1. é¢„å¤„ç†ç¤¾åŒºæŠ¥å‘Šæ•°æ®\n",
    "    print(\"é¢„å¤„ç†ç¤¾åŒºæŠ¥å‘Šæ•°æ®...\")\n",
    "    df_reports = df_reports.copy()\n",
    "    \n",
    "    # å…ˆåˆ›å»ºæ–°åˆ—ï¼Œé¿å…KeyError\n",
    "    df_reports['community_str'] = None\n",
    "    df_reports['processed_findings'] = None\n",
    "    \n",
    "    # æ£€æŸ¥findingså­—æ®µå¹¶æ‰“å°æ ·æœ¬æ•°æ®ä»¥ä¾¿è°ƒè¯•\n",
    "    sample_findings = []\n",
    "    \n",
    "    for idx, row in df_reports.iterrows():\n",
    "        # å¤„ç†communityå­—æ®µ - å…ˆè½¬æ¢ä¸ºå­—ç¬¦ä¸²å†èµ‹å€¼\n",
    "        if 'community' in row:\n",
    "            community_str = str(row['community'])\n",
    "            df_reports.at[idx, 'community_str'] = community_str\n",
    "        \n",
    "        # å¤„ç†findingså­—æ®µ - ç‰¹åˆ«å¤„ç†NumPyæ•°ç»„\n",
    "        findings = row.get('findings')\n",
    "        \n",
    "        # å¤„ç†NumPyæ•°ç»„\n",
    "        if hasattr(findings, 'dtype') and hasattr(findings, 'tolist'):\n",
    "            print(f\"è¡Œ {idx}: å°†NumPyæ•°ç»„è½¬æ¢ä¸ºåˆ—è¡¨ï¼Œå½¢çŠ¶: {findings.shape if hasattr(findings, 'shape') else 'unknown'}\")\n",
    "            try:\n",
    "                findings = findings.tolist()\n",
    "            except Exception as e:\n",
    "                print(f\"è¡Œ {idx}: è½¬æ¢NumPyæ•°ç»„å¤±è´¥: {e}\")\n",
    "                findings = []\n",
    "        # å¤„ç†å…¶ä»–ç±»å‹\n",
    "        elif not isinstance(findings, list):\n",
    "            if isinstance(findings, str):\n",
    "                try:\n",
    "                    import json\n",
    "                    findings = json.loads(findings)\n",
    "                    print(f\"è¡Œ {idx}: ä»å­—ç¬¦ä¸²è§£æfindingsæˆåŠŸ\")\n",
    "                except Exception as e:\n",
    "                    print(f\"è¡Œ {idx}: è§£æfindingså­—ç¬¦ä¸²å¤±è´¥: {e}\")\n",
    "                    findings = []\n",
    "            else:\n",
    "                print(f\"è¡Œ {idx}: findingsä¸æ˜¯åˆ—è¡¨ã€NumPyæ•°ç»„æˆ–å­—ç¬¦ä¸²ï¼Œè€Œæ˜¯ {type(findings)}\")\n",
    "                findings = []\n",
    "        \n",
    "        # ç¡®ä¿findingsæ˜¯æœ‰æ•ˆçš„åˆ—è¡¨\n",
    "        if not isinstance(findings, list):\n",
    "            print(f\"è¡Œ {idx}: å¤„ç†åfindingsä»ä¸æ˜¯åˆ—è¡¨ï¼Œå¼ºåˆ¶è®¾ä¸ºç©ºåˆ—è¡¨\")\n",
    "            findings = []\n",
    "        \n",
    "        # æ‰“å°findingsçš„å†…å®¹ä»¥ä¾¿è°ƒè¯•\n",
    "        if len(findings) > 0:\n",
    "            print(f\"è¡Œ {idx}: æ‰¾åˆ° {len(findings)} ä¸ªfindings\")\n",
    "            if idx < 3:  # åªæ‰“å°å‰3è¡Œçš„è¯¦ç»†å†…å®¹\n",
    "                print(f\"  ç¤ºä¾‹: {findings[0]}\")\n",
    "                sample_findings.append((idx, findings))\n",
    "        else:\n",
    "            print(f\"è¡Œ {idx}: æ²¡æœ‰æ‰¾åˆ°findings\")\n",
    "        \n",
    "        # ç¡®ä¿æ¯ä¸ªfindingæ˜¯å­—å…¸\n",
    "        valid_findings = []\n",
    "        for i, finding in enumerate(findings):\n",
    "            if isinstance(finding, dict):\n",
    "                # ç¡®ä¿å¿…è¦çš„å­—æ®µå­˜åœ¨\n",
    "                if 'summary' not in finding:\n",
    "                    finding['summary'] = f\"Finding_{i}\"\n",
    "                if 'explanation' not in finding:\n",
    "                    finding['explanation'] = \"\"\n",
    "                valid_findings.append(finding)\n",
    "            else:\n",
    "                print(f\"è¡Œ {idx}: è·³è¿‡æ— æ•ˆçš„findingç±»å‹: {type(finding)}\")\n",
    "                # å°è¯•è½¬æ¢ä¸ºå­—å…¸\n",
    "                if isinstance(finding, (list, tuple)) and len(finding) >= 2:\n",
    "                    try:\n",
    "                        valid_findings.append({\n",
    "                            'summary': str(finding[0]),\n",
    "                            'explanation': str(finding[1])\n",
    "                        })\n",
    "                        print(f\"  æˆåŠŸè½¬æ¢ä¸ºå­—å…¸: {finding[0]}\")\n",
    "                    except Exception as e:\n",
    "                        print(f\"  è½¬æ¢å¤±è´¥: {e}\")\n",
    "        \n",
    "        # æ›´æ–°DataFrame - ä½¿ç”¨atè€Œä¸æ˜¯loc\n",
    "        df_reports.at[idx, 'processed_findings'] = valid_findings\n",
    "    \n",
    "    # æ‰“å°æ ·æœ¬æ•°æ®\n",
    "    print(f\"æ”¶é›†äº† {len(sample_findings)} ä¸ªæ ·æœ¬findings:\")\n",
    "    for idx, findings in sample_findings:\n",
    "        print(f\"è¡Œ {idx}: {len(findings)} ä¸ªfindings\")\n",
    "    \n",
    "    # 2. å‡†å¤‡Findingæ•°æ® - ç›´æ¥ä»å¤„ç†åçš„æ•°æ®åˆ›å»º\n",
    "    print(\"å‡†å¤‡Findingæ•°æ®...\")\n",
    "    findings_data = []\n",
    "    \n",
    "    for idx, row in df_reports.iterrows():\n",
    "        community_str = row['community_str']\n",
    "        processed_findings = row['processed_findings']\n",
    "        \n",
    "        if not isinstance(processed_findings, list):\n",
    "            print(f\"è¡Œ {idx}: processed_findingsä¸æ˜¯åˆ—è¡¨ï¼Œè·³è¿‡\")\n",
    "            continue\n",
    "            \n",
    "        for i, finding in enumerate(processed_findings):\n",
    "            if isinstance(finding, dict):\n",
    "                finding_id = f\"{community_str}_{i}\"\n",
    "                findings_data.append({\n",
    "                    'finding_id': finding_id,\n",
    "                    'community_id': community_str,\n",
    "                    'summary': finding.get('summary', f\"Finding_{i}\"),\n",
    "                    'explanation': finding.get('explanation', \"\")\n",
    "                })\n",
    "    \n",
    "    print(f\"å‡†å¤‡äº† {len(findings_data)} ä¸ªFindingæ•°æ®\")\n",
    "    \n",
    "    # 3. å¯¼å…¥ç¤¾åŒºèŠ‚ç‚¹\n",
    "    print(\"æ­¥éª¤1: å¯¼å…¥ç¤¾åŒºèŠ‚ç‚¹...\")\n",
    "    \n",
    "    # ç¤¾åŒºèŠ‚ç‚¹åˆ›å»ºè¯­å¥\n",
    "    community_statement = \"\"\"\n",
    "    MERGE (c:__Community__ {community: value.community_str})\n",
    "    SET c.level = value.level,\n",
    "        c.title = value.title,\n",
    "        c.rank = value.rank,\n",
    "        c.rating_explanation = value.rating_explanation,\n",
    "        c.full_content = value.full_content,\n",
    "        c.summary = value.summary,\n",
    "        c.name = coalesce(value.title, 'Community_' + value.community_str)\n",
    "    RETURN c.community as community_id\n",
    "    \"\"\"\n",
    "    \n",
    "    # æ‰§è¡Œå¯¼å…¥ç¤¾åŒºèŠ‚ç‚¹\n",
    "    community_result = parallel_batched_import(community_statement, df_reports, batch_size, max_workers)\n",
    "    print(f\"å·²åˆ›å»º/æ›´æ–° {community_result['successful_rows']} ä¸ªç¤¾åŒºèŠ‚ç‚¹\")\n",
    "    \n",
    "    # 4. å¦‚æœæœ‰Findingæ•°æ®ï¼Œåˆ›å»ºFindingèŠ‚ç‚¹å’Œå…³ç³»\n",
    "    if findings_data:\n",
    "        print(\"æ­¥éª¤2: å¯¼å…¥FindingèŠ‚ç‚¹å’Œå…³ç³»...\")\n",
    "        df_findings = pd.DataFrame(findings_data)\n",
    "        \n",
    "        finding_statement = \"\"\"\n",
    "        // åˆ›å»ºFindingèŠ‚ç‚¹\n",
    "        MERGE (f:__Finding__ {id: value.finding_id})\n",
    "        SET f.summary = value.summary,\n",
    "            f.explanation = value.explanation,\n",
    "            f.name = value.summary\n",
    "        \n",
    "        // åˆ›å»ºä¸Communityçš„å…³ç³»\n",
    "        WITH f, value\n",
    "        MATCH (c:__Community__ {community: value.community_id})\n",
    "        MERGE (c)-[:HAS_FINDING]->(f)\n",
    "        \"\"\"\n",
    "        \n",
    "        # æ‰§è¡Œå¯¼å…¥FindingèŠ‚ç‚¹å’Œå…³ç³»\n",
    "        finding_result = parallel_batched_import(finding_statement, df_findings, batch_size, max_workers)\n",
    "        print(f\"å·²åˆ›å»º {finding_result['successful_rows']} ä¸ªFindingèŠ‚ç‚¹å’ŒHAS_FINDINGå…³ç³»\")\n",
    "    else:\n",
    "        print(\"æ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆçš„Findingæ•°æ®ï¼Œè·³è¿‡åˆ›å»ºFindingèŠ‚ç‚¹å’Œå…³ç³»\")\n",
    "    \n",
    "    # 5. éªŒè¯ç»“æœ\n",
    "    with driver.session(database=NEO4J_DATABASE) as session:\n",
    "        # æ£€æŸ¥CommunityèŠ‚ç‚¹æ•°é‡\n",
    "        result = session.run(\"MATCH (c:__Community__) RETURN count(c) as count\")\n",
    "        community_count = result.single()[\"count\"]\n",
    "        \n",
    "        # æ£€æŸ¥FindingèŠ‚ç‚¹æ•°é‡ - ä½¿ç”¨try-exceptå¤„ç†å¯èƒ½çš„é”™è¯¯\n",
    "        try:\n",
    "            result = session.run(\"MATCH (f:__Finding__) RETURN count(f) as count\")\n",
    "            finding_count = result.single()[\"count\"]\n",
    "        except Exception as e:\n",
    "            print(f\"æŸ¥è¯¢FindingèŠ‚ç‚¹æ—¶å‡ºé”™: {e}\")\n",
    "            finding_count = 0\n",
    "        \n",
    "        # æ£€æŸ¥HAS_FINDINGå…³ç³»æ•°é‡ - ä½¿ç”¨try-exceptå¤„ç†å¯èƒ½çš„é”™è¯¯\n",
    "        try:\n",
    "            result = session.run(\"MATCH ()-[r:HAS_FINDING]->() RETURN count(r) as count\")\n",
    "            has_finding_count = result.single()[\"count\"]\n",
    "        except Exception as e:\n",
    "            print(f\"æŸ¥è¯¢HAS_FINDINGå…³ç³»æ—¶å‡ºé”™: {e}\")\n",
    "            has_finding_count = 0\n",
    "        \n",
    "        print(f\"éªŒè¯ç»“æœ: {community_count} ä¸ª__Community__èŠ‚ç‚¹, {finding_count} ä¸ª__Finding__èŠ‚ç‚¹, {has_finding_count} ä¸ªHAS_FINDINGå…³ç³»\")\n",
    "    \n",
    "    return community_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¯¼å…¥ç¤¾åŒºæŠ¥å‘Š\n",
    "import_community_reports(df_communities_reports, batch_size=100, max_workers=8)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;åœ¨å®Œæˆåï¼Œå¯ä»¥åœ¨`localhost:7474`çš„`Neo4j`æµè§ˆå™¨ä¸­ï¼Œå¯ä»¥çœ‹åˆ°ä¼šç”Ÿæˆ`__Community__`èŠ‚ç‚¹ï¼ŒåŒæ—¶ï¼Œ`__Finding__`èŠ‚ç‚¹ä¸`__Community__`èŠ‚ç‚¹ä¹‹é—´ï¼Œä¹Ÿåˆ›å»ºäº†`HAS_FINDING`å…³ç³»ã€‚å¦‚ä¸‹å›¾æ‰€ç¤ºï¼š"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://muyu20241105.oss-cn-beijing.aliyuncs.com/images/202503121957586.png\" width=80%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;è‡³æ­¤ï¼Œæˆ‘ä»¬å°±å®Œæˆäº†`community_reports.parquet`æ–‡ä»¶çš„å¯¼å…¥ã€‚\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;å®Œæˆäº†æ‰€æœ‰æ–‡ä»¶çš„å¯¼å…¥åï¼Œä¸€ä¸ªå®Œæ•´çš„çŸ¥è¯†å›¾è°±å°±æ„å»ºå®Œæˆäº†ã€‚ç°é˜¶æ®µå°±å·²ç»å¯ä»¥å¼€å§‹ä½¿ç”¨`Neo4j`çš„`Cypher`è¯­å¥ï¼ŒæŸ¥è¯¢çŸ¥è¯†å›¾è°±ä¸­çš„æ•°æ®ã€‚æ¯”å¦‚ä¸€äº›å¸¸è§çš„æŸ¥è¯¢ï¼Œå¦‚ä¸‹æ‰€ç¤ºï¼š\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;æ˜¾ç¤ºä¸€äº›__Entity__èŠ‚ç‚¹åŠå…¶å…³ç³»:\n",
    "\n",
    "```bash\n",
    "    MATCH path = (:__Entity__)-[:RELATED]->(:__Entity__)\n",
    "    RETURN path LIMIT 200\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://muyu20241105.oss-cn-beijing.aliyuncs.com/images/202503131154423.png\" width=80%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;æ˜¾ç¤ºå—å’Œæ–‡æ¡£ï¼ˆè¯æ±‡å›¾ï¼‰ï¼š\n",
    "\n",
    "```bash\n",
    "    MATCH (d:__Document__) WITH d LIMIT 1\n",
    "    MATCH path = (d)<-[:PART_OF]-(c:__Chunk__)\n",
    "    RETURN path LIMIT 100\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://muyu20241105.oss-cn-beijing.aliyuncs.com/images/202503131154424.png\" width=80%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;è¿”å›æœ€å¤š 25 ä¸ªå®ä½“ä¹‹é—´çš„ç¤¾åŒºå…³ç³»è·¯å¾„ï¼š\n",
    "\n",
    "```bash\n",
    "    MATCH p=()-[r:IN_COMMUNITY]->() \n",
    "    RETURN p LIMIT 25\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://muyu20241105.oss-cn-beijing.aliyuncs.com/images/202503131154425.png\" width=80%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;è‡³æ­¤ï¼Œæˆ‘ä»¬å®Œæˆäº†`Microsoft GraphRAG` ç”Ÿæˆç´¢å¼•çš„å®Œæ•´çŸ¥è¯†å›¾è°±æ„å»ºä¸å¯è§†åŒ–ã€‚è¯¦ç»†äº†è§£äº†çŸ¥è¯†å›¾è°±çš„å…¨è²Œåï¼Œæ¥ä¸‹æ¥çš„è¯¾ç¨‹ï¼Œæˆ‘ä»¬è¿›è¡Œ`Microsoft GraphRAG` å®ç°çš„`Query` é˜¶æ®µçš„å®æ“ä»¥åŠåº•å±‚åŸç†çš„è®²è§£ã€‚\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hhc_base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
